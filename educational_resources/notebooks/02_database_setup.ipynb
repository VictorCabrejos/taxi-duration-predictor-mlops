{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59144392",
   "metadata": {},
   "source": [
    "# üóÑÔ∏è AWS PostgreSQL Database Setup\n",
    "## FASE 2: Conexi√≥n y Migraci√≥n de Datos\n",
    "\n",
    "Este notebook configura la conexi√≥n a AWS PostgreSQL y migra los datos del CSV.\n",
    "\n",
    "### üéØ **Objetivos:**\n",
    "1. **Probar conexi√≥n** a AWS PostgreSQL\n",
    "2. **Crear esquema** de base de datos\n",
    "3. **Migrar datos** desde CSV\n",
    "4. **Validar** integridad de datos\n",
    "5. **Probar adaptador** PostgreSQL\n",
    "\n",
    "### üìã **Credenciales necesarias:**\n",
    "- **Endpoint**: (se obtendr√° de AWS)\n",
    "- **Usuario**: `taxiuser`\n",
    "- **Password**: `TaxiDB2025!`\n",
    "- **Base de datos**: `taxi_db`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfc22a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Setup completado!\n",
      "üìÖ Fecha: 2025-07-19 10:05:56\n"
     ]
    }
   ],
   "source": [
    "# üì¶ Setup e imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import asyncio\n",
    "import asyncpg\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Agregar el directorio del proyecto al path\n",
    "sys.path.append(os.path.join(os.getcwd(), 'taxi_duration_predictor'))\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"üöÄ Setup completado!\")\n",
    "print(f\"üìÖ Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbc4632",
   "metadata": {},
   "source": [
    "## üîß **Paso 1: Configurar Conexi√≥n a AWS PostgreSQL**\n",
    "\n",
    "**‚ö†Ô∏è IMPORTANTE**: Una vez que tu base de datos est√© lista en AWS, necesitar√°s:\n",
    "1. Ir a la base de datos en la consola AWS\n",
    "2. Hacer clic en \"View connection details\"\n",
    "3. Copiar el **Endpoint** (algo como: taxi-duration-db.xxxxx.us-east-1.rds.amazonaws.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eee353a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Configuraci√≥n de conexi√≥n preparada\n",
      "üì° Endpoint: taxi-duration-db.ckj7uy651uld.us-east-1.rds.amazonaws.com\n",
      "üîê Usuario: taxiuser\n",
      "üóÑÔ∏è Base de datos: postgres\n",
      "‚úÖ Endpoint configurado correctamente!\n"
     ]
    }
   ],
   "source": [
    "# üîê Configuraci√≥n de conexi√≥n AWS PostgreSQL\n",
    "# ‚úÖ ENDPOINT CONFIGURADO CORRECTAMENTE\n",
    "AWS_ENDPOINT = \"taxi-duration-db.ckj7uy651uld.us-east-1.rds.amazonaws.com\"\n",
    "DB_PORT = 5432\n",
    "DB_NAME = \"postgres\"  # Aurora usa 'postgres' como base de datos por defecto\n",
    "DB_USER = \"taxiuser\"\n",
    "DB_PASSWORD = \"TaxiDB2025!\"\n",
    "\n",
    "# String de conexi√≥n\n",
    "CONNECTION_STRING = f\"postgresql://{DB_USER}:{DB_PASSWORD}@{AWS_ENDPOINT}:{DB_PORT}/{DB_NAME}\"\n",
    "\n",
    "print(\"üîó Configuraci√≥n de conexi√≥n preparada\")\n",
    "print(f\"üì° Endpoint: {AWS_ENDPOINT}\")\n",
    "print(f\"üîê Usuario: {DB_USER}\")\n",
    "print(f\"üóÑÔ∏è Base de datos: {DB_NAME}\")\n",
    "print(\"‚úÖ Endpoint configurado correctamente!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "759da2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Esperando que la base de datos est√© lista...\n",
      "üí° Ejecuta 'await test_connection()' cuando veas 'Available' en AWS\n"
     ]
    }
   ],
   "source": [
    "# üß™ Funci√≥n para probar conexi√≥n\n",
    "async def test_connection():\n",
    "    \"\"\"Prueba la conexi√≥n a PostgreSQL\"\"\"\n",
    "    try:\n",
    "        print(\"üîÑ Probando conexi√≥n a AWS PostgreSQL...\")\n",
    "\n",
    "        conn = await asyncpg.connect(\n",
    "            host=AWS_ENDPOINT,\n",
    "            port=DB_PORT,\n",
    "            database=DB_NAME,\n",
    "            user=DB_USER,\n",
    "            password=DB_PASSWORD\n",
    "        )\n",
    "\n",
    "        # Ejecutar consulta simple\n",
    "        version = await conn.fetchval('SELECT version()')\n",
    "        print(f\"‚úÖ ¬°Conexi√≥n exitosa!\")\n",
    "        print(f\"üìä Versi√≥n PostgreSQL: {version}\")\n",
    "\n",
    "        await conn.close()\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error de conexi√≥n: {e}\")\n",
    "        print(\"üîß Verifica que:\")\n",
    "        print(\"   - La base de datos est√© 'Available' en AWS\")\n",
    "        print(\"   - El endpoint sea correcto\")\n",
    "        print(\"   - Las reglas de seguridad permitan conexiones\")\n",
    "        return False\n",
    "\n",
    "# ‚ö†Ô∏è EJECUTAR SOLO CUANDO LA BASE DE DATOS EST√â LISTA\n",
    "# await test_connection()\n",
    "print(\"‚è≥ Esperando que la base de datos est√© lista...\")\n",
    "print(\"üí° Ejecuta 'await test_connection()' cuando veas 'Available' en AWS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cff6a5",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è **ANTES DE CONTINUAR - VERIFICAR AWS**\n",
    "\n",
    "### üîç **Pasos obligatorios:**\n",
    "\n",
    "1. **Ve a AWS Console ‚Üí RDS ‚Üí Databases**\n",
    "2. **Busca `taxi-duration-db`**\n",
    "3. **Verifica que el estado sea \"Available\" (verde)**\n",
    "4. **Si dice \"Creating\" o \"Modifying\", espera 5-10 minutos**\n",
    "\n",
    "### ‚úÖ **Cuando veas \"Available\", ejecuta:**\n",
    "```python\n",
    "await test_connection()\n",
    "```\n",
    "\n",
    "### üö® **Si hay errores de conexi√≥n:**\n",
    "- Verifica que el Security Group tenga regla PostgreSQL (puerto 5432)\n",
    "- Confirma que tu IP actual est√© en las reglas\n",
    "- Aseg√∫rate que el endpoint sea correcto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4ec2a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Probando conexi√≥n a AWS PostgreSQL...\n",
      "‚úÖ ¬°Conexi√≥n exitosa!\n",
      "üìä Versi√≥n PostgreSQL: PostgreSQL 17.4 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 12.4.0, 64-bit\n",
      "‚úÖ ¬°Conexi√≥n exitosa!\n",
      "üìä Versi√≥n PostgreSQL: PostgreSQL 17.4 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 12.4.0, 64-bit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await test_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15273f43",
   "metadata": {},
   "source": [
    "## üèóÔ∏è **Paso 2: Crear Esquema de Base de Datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef829487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí° Ejecuta 'await create_database_schema()' despu√©s de probar la conexi√≥n\n"
     ]
    }
   ],
   "source": [
    "# üèóÔ∏è Funci√≥n para crear esquema\n",
    "async def create_database_schema():\n",
    "    \"\"\"Crea las tablas necesarias\"\"\"\n",
    "    try:\n",
    "        print(\"üîÑ Creando esquema de base de datos...\")\n",
    "\n",
    "        conn = await asyncpg.connect(\n",
    "            host=AWS_ENDPOINT,\n",
    "            port=DB_PORT,\n",
    "            database=DB_NAME,\n",
    "            user=DB_USER,\n",
    "            password=DB_PASSWORD\n",
    "        )\n",
    "\n",
    "        # SQL para crear tablas\n",
    "        create_tables_sql = \"\"\"\n",
    "        -- Tabla principal de viajes\n",
    "        CREATE TABLE IF NOT EXISTS taxi_trips (\n",
    "            id VARCHAR(50) PRIMARY KEY,\n",
    "            vendor_id INTEGER NOT NULL,\n",
    "            pickup_datetime TIMESTAMP NOT NULL,\n",
    "            dropoff_datetime TIMESTAMP NOT NULL,\n",
    "            passenger_count INTEGER NOT NULL,\n",
    "            pickup_longitude DECIMAL(10, 7) NOT NULL,\n",
    "            pickup_latitude DECIMAL(10, 7) NOT NULL,\n",
    "            dropoff_longitude DECIMAL(10, 7) NOT NULL,\n",
    "            dropoff_latitude DECIMAL(10, 7) NOT NULL,\n",
    "            store_and_fwd_flag VARCHAR(1) NOT NULL,\n",
    "            trip_duration_seconds DECIMAL(10, 2) NOT NULL,\n",
    "            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "        );\n",
    "\n",
    "        -- √çndices para optimizar consultas\n",
    "        CREATE INDEX IF NOT EXISTS idx_pickup_datetime ON taxi_trips(pickup_datetime);\n",
    "        CREATE INDEX IF NOT EXISTS idx_vendor_id ON taxi_trips(vendor_id);\n",
    "        CREATE INDEX IF NOT EXISTS idx_trip_duration ON taxi_trips(trip_duration_seconds);\n",
    "        CREATE INDEX IF NOT EXISTS idx_coordinates ON taxi_trips(pickup_longitude, pickup_latitude);\n",
    "\n",
    "        -- Tabla de predicciones\n",
    "        CREATE TABLE IF NOT EXISTS predictions (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            trip_id VARCHAR(50) NOT NULL,\n",
    "            predicted_duration_seconds DECIMAL(10, 2) NOT NULL,\n",
    "            confidence_score DECIMAL(5, 4) NOT NULL,\n",
    "            model_version VARCHAR(50) NOT NULL,\n",
    "            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "            features_json JSONB\n",
    "        );\n",
    "\n",
    "        CREATE INDEX IF NOT EXISTS idx_predictions_trip_id ON predictions(trip_id);\n",
    "        CREATE INDEX IF NOT EXISTS idx_predictions_created_at ON predictions(created_at);\n",
    "        \"\"\"\n",
    "\n",
    "        await conn.execute(create_tables_sql)\n",
    "        print(\"‚úÖ Esquema creado exitosamente!\")\n",
    "\n",
    "        # Verificar que las tablas se crearon\n",
    "        tables = await conn.fetch(\"\"\"\n",
    "            SELECT table_name FROM information_schema.tables\n",
    "            WHERE table_schema = 'public'\n",
    "        \"\"\")\n",
    "\n",
    "        print(\"üìã Tablas creadas:\")\n",
    "        for table in tables:\n",
    "            print(f\"   - {table['table_name']}\")\n",
    "\n",
    "        await conn.close()\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error creando esquema: {e}\")\n",
    "        return False\n",
    "\n",
    "# ‚ö†Ô∏è EJECUTAR DESPU√âS DE PROBAR LA CONEXI√ìN\n",
    "# await create_database_schema()\n",
    "print(\"üí° Ejecuta 'await create_database_schema()' despu√©s de probar la conexi√≥n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cc6f69",
   "metadata": {},
   "source": [
    "## üì§ **Paso 3: Migrar Datos desde CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c97f83d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí° Ejecuta 'await migrate_csv_data(50000)' despu√©s de crear el esquema\n"
     ]
    }
   ],
   "source": [
    "# üì§ Funci√≥n para migrar datos\n",
    "async def migrate_csv_data(sample_size: int = 50000):\n",
    "    \"\"\"Migra datos desde CSV a PostgreSQL\"\"\"\n",
    "    try:\n",
    "        print(f\"üîÑ Migrando {sample_size} filas desde CSV...\")\n",
    "\n",
    "        # Cargar muestra del CSV\n",
    "        df = pd.read_csv('train.csv', nrows=sample_size)\n",
    "        print(f\"üìä CSV cargado: {df.shape}\")\n",
    "\n",
    "        # Limpiar datos b√°sico\n",
    "        df = df.dropna()\n",
    "\n",
    "        # Filtrar datos v√°lidos (NYC bounds)\n",
    "        df = df[\n",
    "            (df['pickup_longitude'] >= -74.3) & (df['pickup_longitude'] <= -73.7) &\n",
    "            (df['pickup_latitude'] >= 40.5) & (df['pickup_latitude'] <= 40.9) &\n",
    "            (df['dropoff_longitude'] >= -74.3) & (df['dropoff_longitude'] <= -73.7) &\n",
    "            (df['dropoff_latitude'] >= 40.5) & (df['dropoff_latitude'] <= 40.9) &\n",
    "            (df['trip_duration'] >= 30) & (df['trip_duration'] <= 21600) &  # 30 seg a 6 horas\n",
    "            (df['passenger_count'] >= 1) & (df['passenger_count'] <= 6)\n",
    "        ]\n",
    "\n",
    "        print(f\"üßπ Datos limpios: {df.shape}\")\n",
    "\n",
    "        # Conectar a la base de datos\n",
    "        conn = await asyncpg.connect(\n",
    "            host=AWS_ENDPOINT,\n",
    "            port=DB_PORT,\n",
    "            database=DB_NAME,\n",
    "            user=DB_USER,\n",
    "            password=DB_PASSWORD\n",
    "        )\n",
    "\n",
    "        # Insertar datos en lotes\n",
    "        batch_size = 1000\n",
    "        total_inserted = 0\n",
    "\n",
    "        for i in range(0, len(df), batch_size):\n",
    "            batch = df.iloc[i:i+batch_size]\n",
    "\n",
    "            # Preparar datos para inserci√≥n\n",
    "            trip_data = []\n",
    "            for _, row in batch.iterrows():\n",
    "                trip_data.append((\n",
    "                    str(row['id']),\n",
    "                    int(row['vendor_id']),\n",
    "                    pd.to_datetime(row['pickup_datetime']),\n",
    "                    pd.to_datetime(row['dropoff_datetime']),\n",
    "                    int(row['passenger_count']),\n",
    "                    float(row['pickup_longitude']),\n",
    "                    float(row['pickup_latitude']),\n",
    "                    float(row['dropoff_longitude']),\n",
    "                    float(row['dropoff_latitude']),\n",
    "                    str(row['store_and_fwd_flag']),\n",
    "                    float(row['trip_duration'])\n",
    "                ))\n",
    "\n",
    "            # Insertar lote\n",
    "            await conn.executemany(\"\"\"\n",
    "                INSERT INTO taxi_trips (\n",
    "                    id, vendor_id, pickup_datetime, dropoff_datetime,\n",
    "                    passenger_count, pickup_longitude, pickup_latitude,\n",
    "                    dropoff_longitude, dropoff_latitude, store_and_fwd_flag,\n",
    "                    trip_duration_seconds\n",
    "                ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11)\n",
    "                ON CONFLICT (id) DO NOTHING\n",
    "            \"\"\", trip_data)\n",
    "\n",
    "            total_inserted += len(trip_data)\n",
    "            print(f\"üì§ Insertadas {total_inserted} filas...\")\n",
    "\n",
    "        await conn.close()\n",
    "        print(f\"‚úÖ Migraci√≥n completa: {total_inserted} viajes\")\n",
    "        return total_inserted\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error en migraci√≥n: {e}\")\n",
    "        return 0\n",
    "\n",
    "# ‚ö†Ô∏è EJECUTAR DESPU√âS DE CREAR EL ESQUEMA\n",
    "# total = await migrate_csv_data(50000)\n",
    "print(\"üí° Ejecuta 'await migrate_csv_data(50000)' despu√©s de crear el esquema\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aafd21",
   "metadata": {},
   "source": [
    "## üîç **Paso 4: Validar Datos Migrados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9e26c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí° Ejecuta 'await validate_migrated_data()' despu√©s de la migraci√≥n\n"
     ]
    }
   ],
   "source": [
    "# üîç Funci√≥n para validar datos\n",
    "async def validate_migrated_data():\n",
    "    \"\"\"Valida que los datos se migraron correctamente\"\"\"\n",
    "    try:\n",
    "        print(\"üîÑ Validando datos migrados...\")\n",
    "\n",
    "        conn = await asyncpg.connect(\n",
    "            host=AWS_ENDPOINT,\n",
    "            port=DB_PORT,\n",
    "            database=DB_NAME,\n",
    "            user=DB_USER,\n",
    "            password=DB_PASSWORD\n",
    "        )\n",
    "\n",
    "        # Estad√≠sticas b√°sicas\n",
    "        stats = await conn.fetchrow(\"\"\"\n",
    "            SELECT\n",
    "                COUNT(*) as total_trips,\n",
    "                MIN(pickup_datetime) as earliest_trip,\n",
    "                MAX(pickup_datetime) as latest_trip,\n",
    "                AVG(trip_duration_seconds) as avg_duration_seconds,\n",
    "                AVG(passenger_count) as avg_passengers,\n",
    "                COUNT(DISTINCT vendor_id) as unique_vendors\n",
    "            FROM taxi_trips\n",
    "        \"\"\")\n",
    "\n",
    "        print(\"üìä **ESTAD√çSTICAS DE LA BASE DE DATOS:**\")\n",
    "        print(f\"   Total de viajes: {stats['total_trips']:,}\")\n",
    "        print(f\"   Primer viaje: {stats['earliest_trip']}\")\n",
    "        print(f\"   √öltimo viaje: {stats['latest_trip']}\")\n",
    "        print(f\"   Duraci√≥n promedio: {stats['avg_duration_seconds']/60:.1f} minutos\")\n",
    "        print(f\"   Pasajeros promedio: {stats['avg_passengers']:.1f}\")\n",
    "        print(f\"   Vendors √∫nicos: {stats['unique_vendors']}\")\n",
    "\n",
    "        # Muestra de datos\n",
    "        sample = await conn.fetch(\"SELECT * FROM taxi_trips LIMIT 5\")\n",
    "        print(f\"\\nüîç **MUESTRA DE DATOS:**\")\n",
    "        for i, row in enumerate(sample, 1):\n",
    "            print(f\"   {i}. Viaje {row['id']}: {row['trip_duration_seconds']/60:.1f} min, {row['passenger_count']} pasajeros\")\n",
    "\n",
    "        await conn.close()\n",
    "        print(\"‚úÖ Validaci√≥n completa!\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error en validaci√≥n: {e}\")\n",
    "        return False\n",
    "\n",
    "# ‚ö†Ô∏è EJECUTAR DESPU√âS DE LA MIGRACI√ìN\n",
    "# await validate_migrated_data()\n",
    "print(\"üí° Ejecuta 'await validate_migrated_data()' despu√©s de la migraci√≥n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a3e03d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Creando esquema de base de datos...\n",
      "‚úÖ Esquema creado exitosamente!\n",
      "‚úÖ Esquema creado exitosamente!\n",
      "üìã Tablas creadas:\n",
      "   - taxi_trips\n",
      "   - predictions\n",
      "üìã Tablas creadas:\n",
      "   - taxi_trips\n",
      "   - predictions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await create_database_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b507e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Migrando 50000 filas desde CSV...\n",
      "üìä CSV cargado: (50000, 11)\n",
      "üßπ Datos limpios: (49719, 11)\n",
      "üì§ Insertadas 1000 filas...\n",
      "üì§ Insertadas 1000 filas...\n",
      "üì§ Insertadas 2000 filas...\n",
      "üì§ Insertadas 2000 filas...\n",
      "üì§ Insertadas 3000 filas...\n",
      "üì§ Insertadas 3000 filas...\n",
      "üì§ Insertadas 4000 filas...\n",
      "üì§ Insertadas 4000 filas...\n",
      "üì§ Insertadas 5000 filas...\n",
      "üì§ Insertadas 5000 filas...\n",
      "üì§ Insertadas 6000 filas...\n",
      "üì§ Insertadas 6000 filas...\n",
      "üì§ Insertadas 7000 filas...\n",
      "üì§ Insertadas 7000 filas...\n",
      "üì§ Insertadas 8000 filas...\n",
      "üì§ Insertadas 8000 filas...\n",
      "üì§ Insertadas 9000 filas...\n",
      "üì§ Insertadas 9000 filas...\n",
      "üì§ Insertadas 10000 filas...\n",
      "üì§ Insertadas 10000 filas...\n",
      "üì§ Insertadas 11000 filas...\n",
      "üì§ Insertadas 11000 filas...\n",
      "üì§ Insertadas 12000 filas...\n",
      "üì§ Insertadas 12000 filas...\n",
      "üì§ Insertadas 13000 filas...\n",
      "üì§ Insertadas 13000 filas...\n",
      "üì§ Insertadas 14000 filas...\n",
      "üì§ Insertadas 14000 filas...\n",
      "üì§ Insertadas 15000 filas...\n",
      "üì§ Insertadas 15000 filas...\n",
      "üì§ Insertadas 16000 filas...\n",
      "üì§ Insertadas 16000 filas...\n",
      "üì§ Insertadas 17000 filas...\n",
      "üì§ Insertadas 17000 filas...\n",
      "üì§ Insertadas 18000 filas...\n",
      "üì§ Insertadas 18000 filas...\n",
      "üì§ Insertadas 19000 filas...\n",
      "üì§ Insertadas 19000 filas...\n",
      "üì§ Insertadas 20000 filas...\n",
      "üì§ Insertadas 20000 filas...\n",
      "üì§ Insertadas 21000 filas...\n",
      "üì§ Insertadas 21000 filas...\n",
      "üì§ Insertadas 22000 filas...\n",
      "üì§ Insertadas 22000 filas...\n",
      "üì§ Insertadas 23000 filas...\n",
      "üì§ Insertadas 23000 filas...\n",
      "üì§ Insertadas 24000 filas...\n",
      "üì§ Insertadas 24000 filas...\n",
      "üì§ Insertadas 25000 filas...\n",
      "üì§ Insertadas 25000 filas...\n",
      "üì§ Insertadas 26000 filas...\n",
      "üì§ Insertadas 26000 filas...\n",
      "üì§ Insertadas 27000 filas...\n",
      "üì§ Insertadas 27000 filas...\n",
      "üì§ Insertadas 28000 filas...\n",
      "üì§ Insertadas 28000 filas...\n",
      "üì§ Insertadas 29000 filas...\n",
      "üì§ Insertadas 29000 filas...\n",
      "üì§ Insertadas 30000 filas...\n",
      "üì§ Insertadas 30000 filas...\n",
      "üì§ Insertadas 31000 filas...\n",
      "üì§ Insertadas 31000 filas...\n",
      "üì§ Insertadas 32000 filas...\n",
      "üì§ Insertadas 32000 filas...\n",
      "üì§ Insertadas 33000 filas...\n",
      "üì§ Insertadas 33000 filas...\n",
      "üì§ Insertadas 34000 filas...\n",
      "üì§ Insertadas 34000 filas...\n",
      "üì§ Insertadas 35000 filas...\n",
      "üì§ Insertadas 35000 filas...\n",
      "üì§ Insertadas 36000 filas...\n",
      "üì§ Insertadas 36000 filas...\n",
      "üì§ Insertadas 37000 filas...\n",
      "üì§ Insertadas 37000 filas...\n",
      "üì§ Insertadas 38000 filas...\n",
      "üì§ Insertadas 38000 filas...\n",
      "üì§ Insertadas 39000 filas...\n",
      "üì§ Insertadas 39000 filas...\n",
      "üì§ Insertadas 40000 filas...\n",
      "üì§ Insertadas 40000 filas...\n",
      "üì§ Insertadas 41000 filas...\n",
      "üì§ Insertadas 41000 filas...\n",
      "üì§ Insertadas 42000 filas...\n",
      "üì§ Insertadas 42000 filas...\n",
      "üì§ Insertadas 43000 filas...\n",
      "üì§ Insertadas 43000 filas...\n",
      "üì§ Insertadas 44000 filas...\n",
      "üì§ Insertadas 44000 filas...\n",
      "üì§ Insertadas 45000 filas...\n",
      "üì§ Insertadas 45000 filas...\n",
      "üì§ Insertadas 46000 filas...\n",
      "üì§ Insertadas 46000 filas...\n",
      "üì§ Insertadas 47000 filas...\n",
      "üì§ Insertadas 47000 filas...\n",
      "üì§ Insertadas 48000 filas...\n",
      "üì§ Insertadas 48000 filas...\n",
      "üì§ Insertadas 49000 filas...\n",
      "üì§ Insertadas 49000 filas...\n",
      "üì§ Insertadas 49719 filas...\n",
      "‚úÖ Migraci√≥n completa: 49719 viajes\n",
      "üì§ Insertadas 49719 filas...\n",
      "‚úÖ Migraci√≥n completa: 49719 viajes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49719"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await migrate_csv_data(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25e72725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Validando datos migrados...\n",
      "üìä **ESTAD√çSTICAS DE LA BASE DE DATOS:**\n",
      "   Total de viajes: 49,719\n",
      "   Primer viaje: 2016-01-01 00:08:07\n",
      "   √öltimo viaje: 2016-06-30 23:45:21\n",
      "   Duraci√≥n promedio: 13.9 minutos\n",
      "   Pasajeros promedio: 1.7\n",
      "   Vendors √∫nicos: 2\n",
      "\n",
      "üîç **MUESTRA DE DATOS:**\n",
      "   1. Viaje id2875421: 7.6 min, 1 pasajeros\n",
      "   2. Viaje id2377394: 11.0 min, 1 pasajeros\n",
      "   3. Viaje id3858529: 35.4 min, 1 pasajeros\n",
      "   4. Viaje id3504673: 7.2 min, 1 pasajeros\n",
      "   5. Viaje id2181028: 7.2 min, 1 pasajeros\n",
      "üìä **ESTAD√çSTICAS DE LA BASE DE DATOS:**\n",
      "   Total de viajes: 49,719\n",
      "   Primer viaje: 2016-01-01 00:08:07\n",
      "   √öltimo viaje: 2016-06-30 23:45:21\n",
      "   Duraci√≥n promedio: 13.9 minutos\n",
      "   Pasajeros promedio: 1.7\n",
      "   Vendors √∫nicos: 2\n",
      "\n",
      "üîç **MUESTRA DE DATOS:**\n",
      "   1. Viaje id2875421: 7.6 min, 1 pasajeros\n",
      "   2. Viaje id2377394: 11.0 min, 1 pasajeros\n",
      "   3. Viaje id3858529: 35.4 min, 1 pasajeros\n",
      "   4. Viaje id3504673: 7.2 min, 1 pasajeros\n",
      "   5. Viaje id2181028: 7.2 min, 1 pasajeros\n",
      "‚úÖ Validaci√≥n completa!\n",
      "‚úÖ Validaci√≥n completa!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await validate_migrated_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958484f2",
   "metadata": {},
   "source": [
    "## üìã **Resumen de FASE 2**\n",
    "\n",
    "### ‚úÖ **Pasos completados:**\n",
    "1. **Configuraci√≥n de conexi√≥n** a AWS PostgreSQL\n",
    "2. **Creaci√≥n de esquema** con tablas optimizadas\n",
    "3. **Migraci√≥n de datos** desde CSV\n",
    "4. **Validaci√≥n** de integridad\n",
    "\n",
    "### üîó **String de conexi√≥n para usar en el proyecto:**\n",
    "```python\n",
    "CONNECTION_STRING = \"postgresql://taxiuser:TaxiDB2025!@[ENDPOINT]:5432/taxi_db\"\n",
    "```\n",
    "\n",
    "### üéØ **Pr√≥ximos pasos (FASE 3):**\n",
    "1. **Implementar MLflow** tracking\n",
    "2. **Crear adaptador ML** \n",
    "3. **Pipeline de entrenamiento**\n",
    "4. **API FastAPI**\n",
    "\n",
    "### üí° **Para las diapositivas:**\n",
    "*\"Implementamos el primer adaptador de nuestra arquitectura hexagonal: PostgreSQLAdapter que conecta con AWS RDS, demostrando c√≥mo los puertos y adaptadores nos permiten cambiar de CSV a base de datos real sin afectar el dominio del negocio.\"*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
