{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59144392",
   "metadata": {},
   "source": [
    "# ðŸ—„ï¸ AWS PostgreSQL Database Setup\n",
    "## FASE 2: ConexiÃ³n y MigraciÃ³n de Datos\n",
    "\n",
    "Este notebook configura la conexiÃ³n a AWS PostgreSQL y migra los datos del CSV.\n",
    "\n",
    "### ðŸŽ¯ **Objetivos:**\n",
    "1. **Probar conexiÃ³n** a AWS PostgreSQL\n",
    "2. **Crear esquema** de base de datos\n",
    "3. **Migrar datos** desde CSV\n",
    "4. **Validar** integridad de datos\n",
    "5. **Probar adaptador** PostgreSQL\n",
    "\n",
    "### ðŸ“‹ **Credenciales necesarias:**\n",
    "- **Endpoint**: (se obtendrÃ¡ de AWS)\n",
    "- **Usuario**: `taxiuser`\n",
    "- **Password**: `TaxiDB2025!`\n",
    "- **Base de datos**: `taxi_db`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfc22a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Setup completado!\n",
      "ðŸ“… Fecha: 2025-07-19 10:05:56\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“¦ Setup e imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import asyncio\n",
    "import asyncpg\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Agregar el directorio del proyecto al path\n",
    "sys.path.append(os.path.join(os.getcwd(), 'taxi_duration_predictor'))\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"ðŸš€ Setup completado!\")\n",
    "print(f\"ðŸ“… Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbc4632",
   "metadata": {},
   "source": [
    "## ðŸ”§ **Paso 1: Configurar ConexiÃ³n a AWS PostgreSQL**\n",
    "\n",
    "**âš ï¸ IMPORTANTE**: Una vez que tu base de datos estÃ© lista en AWS, necesitarÃ¡s:\n",
    "1. Ir a la base de datos en la consola AWS\n",
    "2. Hacer clic en \"View connection details\"\n",
    "3. Copiar el **Endpoint** (algo como: taxi-duration-db.xxxxx.us-east-1.rds.amazonaws.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eee353a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”— ConfiguraciÃ³n de conexiÃ³n preparada\n",
      "ðŸ“¡ Endpoint: taxi-duration-db.ckj7uy651uld.us-east-1.rds.amazonaws.com\n",
      "ðŸ” Usuario: taxiuser\n",
      "ðŸ—„ï¸ Base de datos: postgres\n",
      "âœ… Endpoint configurado correctamente!\n"
     ]
    }
   ],
   "source": [
    "# ðŸ” ConfiguraciÃ³n de conexiÃ³n AWS PostgreSQL\n",
    "# âœ… ENDPOINT CONFIGURADO CORRECTAMENTE\n",
    "AWS_ENDPOINT = \"taxi-duration-db.ckj7uy651uld.us-east-1.rds.amazonaws.com\"\n",
    "DB_PORT = 5432\n",
    "DB_NAME = \"postgres\"  # Aurora usa 'postgres' como base de datos por defecto\n",
    "DB_USER = \"taxiuser\"\n",
    "DB_PASSWORD = \"TaxiDB2025!\"\n",
    "\n",
    "# String de conexiÃ³n\n",
    "CONNECTION_STRING = f\"postgresql://{DB_USER}:{DB_PASSWORD}@{AWS_ENDPOINT}:{DB_PORT}/{DB_NAME}\"\n",
    "\n",
    "print(\"ðŸ”— ConfiguraciÃ³n de conexiÃ³n preparada\")\n",
    "print(f\"ðŸ“¡ Endpoint: {AWS_ENDPOINT}\")\n",
    "print(f\"ðŸ” Usuario: {DB_USER}\")\n",
    "print(f\"ðŸ—„ï¸ Base de datos: {DB_NAME}\")\n",
    "print(\"âœ… Endpoint configurado correctamente!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "759da2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ Esperando que la base de datos estÃ© lista...\n",
      "ðŸ’¡ Ejecuta 'await test_connection()' cuando veas 'Available' en AWS\n"
     ]
    }
   ],
   "source": [
    "# ðŸ§ª FunciÃ³n para probar conexiÃ³n\n",
    "async def test_connection():\n",
    "    \"\"\"Prueba la conexiÃ³n a PostgreSQL\"\"\"\n",
    "    try:\n",
    "        print(\"ðŸ”„ Probando conexiÃ³n a AWS PostgreSQL...\")\n",
    "\n",
    "        conn = await asyncpg.connect(\n",
    "            host=AWS_ENDPOINT,\n",
    "            port=DB_PORT,\n",
    "            database=DB_NAME,\n",
    "            user=DB_USER,\n",
    "            password=DB_PASSWORD\n",
    "        )\n",
    "\n",
    "        # Ejecutar consulta simple\n",
    "        version = await conn.fetchval('SELECT version()')\n",
    "        print(f\"âœ… Â¡ConexiÃ³n exitosa!\")\n",
    "        print(f\"ðŸ“Š VersiÃ³n PostgreSQL: {version}\")\n",
    "\n",
    "        await conn.close()\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error de conexiÃ³n: {e}\")\n",
    "        print(\"ðŸ”§ Verifica que:\")\n",
    "        print(\"   - La base de datos estÃ© 'Available' en AWS\")\n",
    "        print(\"   - El endpoint sea correcto\")\n",
    "        print(\"   - Las reglas de seguridad permitan conexiones\")\n",
    "        return False\n",
    "\n",
    "# âš ï¸ EJECUTAR SOLO CUANDO LA BASE DE DATOS ESTÃ‰ LISTA\n",
    "# await test_connection()\n",
    "print(\"â³ Esperando que la base de datos estÃ© lista...\")\n",
    "print(\"ðŸ’¡ Ejecuta 'await test_connection()' cuando veas 'Available' en AWS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cff6a5",
   "metadata": {},
   "source": [
    "## âš ï¸ **ANTES DE CONTINUAR - VERIFICAR AWS**\n",
    "\n",
    "### ðŸ” **Pasos obligatorios:**\n",
    "\n",
    "1. **Ve a AWS Console â†’ RDS â†’ Databases**\n",
    "2. **Busca `taxi-duration-db`**\n",
    "3. **Verifica que el estado sea \"Available\" (verde)**\n",
    "4. **Si dice \"Creating\" o \"Modifying\", espera 5-10 minutos**\n",
    "\n",
    "### âœ… **Cuando veas \"Available\", ejecuta:**\n",
    "```python\n",
    "await test_connection()\n",
    "```\n",
    "\n",
    "### ðŸš¨ **Si hay errores de conexiÃ³n:**\n",
    "- Verifica que el Security Group tenga regla PostgreSQL (puerto 5432)\n",
    "- Confirma que tu IP actual estÃ© en las reglas\n",
    "- AsegÃºrate que el endpoint sea correcto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4ec2a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Probando conexiÃ³n a AWS PostgreSQL...\n",
      "âœ… Â¡ConexiÃ³n exitosa!\n",
      "ðŸ“Š VersiÃ³n PostgreSQL: PostgreSQL 17.4 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 12.4.0, 64-bit\n",
      "âœ… Â¡ConexiÃ³n exitosa!\n",
      "ðŸ“Š VersiÃ³n PostgreSQL: PostgreSQL 17.4 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 12.4.0, 64-bit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await test_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15273f43",
   "metadata": {},
   "source": [
    "## ðŸ—ï¸ **Paso 2: Crear Esquema de Base de Datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef829487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Ejecuta 'await create_database_schema()' despuÃ©s de probar la conexiÃ³n\n"
     ]
    }
   ],
   "source": [
    "# ðŸ—ï¸ FunciÃ³n para crear esquema\n",
    "async def create_database_schema():\n",
    "    \"\"\"Crea las tablas necesarias\"\"\"\n",
    "    try:\n",
    "        print(\"ðŸ”„ Creando esquema de base de datos...\")\n",
    "\n",
    "        conn = await asyncpg.connect(\n",
    "            host=AWS_ENDPOINT,\n",
    "            port=DB_PORT,\n",
    "            database=DB_NAME,\n",
    "            user=DB_USER,\n",
    "            password=DB_PASSWORD\n",
    "        )\n",
    "\n",
    "        # SQL para crear tablas\n",
    "        create_tables_sql = \"\"\"\n",
    "        -- Tabla principal de viajes\n",
    "        CREATE TABLE IF NOT EXISTS taxi_trips (\n",
    "            id VARCHAR(50) PRIMARY KEY,\n",
    "            vendor_id INTEGER NOT NULL,\n",
    "            pickup_datetime TIMESTAMP NOT NULL,\n",
    "            dropoff_datetime TIMESTAMP NOT NULL,\n",
    "            passenger_count INTEGER NOT NULL,\n",
    "            pickup_longitude DECIMAL(10, 7) NOT NULL,\n",
    "            pickup_latitude DECIMAL(10, 7) NOT NULL,\n",
    "            dropoff_longitude DECIMAL(10, 7) NOT NULL,\n",
    "            dropoff_latitude DECIMAL(10, 7) NOT NULL,\n",
    "            store_and_fwd_flag VARCHAR(1) NOT NULL,\n",
    "            trip_duration_seconds DECIMAL(10, 2) NOT NULL,\n",
    "            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "        );\n",
    "\n",
    "        -- Ãndices para optimizar consultas\n",
    "        CREATE INDEX IF NOT EXISTS idx_pickup_datetime ON taxi_trips(pickup_datetime);\n",
    "        CREATE INDEX IF NOT EXISTS idx_vendor_id ON taxi_trips(vendor_id);\n",
    "        CREATE INDEX IF NOT EXISTS idx_trip_duration ON taxi_trips(trip_duration_seconds);\n",
    "        CREATE INDEX IF NOT EXISTS idx_coordinates ON taxi_trips(pickup_longitude, pickup_latitude);\n",
    "\n",
    "        -- Tabla de predicciones\n",
    "        CREATE TABLE IF NOT EXISTS predictions (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            trip_id VARCHAR(50) NOT NULL,\n",
    "            predicted_duration_seconds DECIMAL(10, 2) NOT NULL,\n",
    "            confidence_score DECIMAL(5, 4) NOT NULL,\n",
    "            model_version VARCHAR(50) NOT NULL,\n",
    "            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "            features_json JSONB\n",
    "        );\n",
    "\n",
    "        CREATE INDEX IF NOT EXISTS idx_predictions_trip_id ON predictions(trip_id);\n",
    "        CREATE INDEX IF NOT EXISTS idx_predictions_created_at ON predictions(created_at);\n",
    "        \"\"\"\n",
    "\n",
    "        await conn.execute(create_tables_sql)\n",
    "        print(\"âœ… Esquema creado exitosamente!\")\n",
    "\n",
    "        # Verificar que las tablas se crearon\n",
    "        tables = await conn.fetch(\"\"\"\n",
    "            SELECT table_name FROM information_schema.tables\n",
    "            WHERE table_schema = 'public'\n",
    "        \"\"\")\n",
    "\n",
    "        print(\"ðŸ“‹ Tablas creadas:\")\n",
    "        for table in tables:\n",
    "            print(f\"   - {table['table_name']}\")\n",
    "\n",
    "        await conn.close()\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error creando esquema: {e}\")\n",
    "        return False\n",
    "\n",
    "# âš ï¸ EJECUTAR DESPUÃ‰S DE PROBAR LA CONEXIÃ“N\n",
    "# await create_database_schema()\n",
    "print(\"ðŸ’¡ Ejecuta 'await create_database_schema()' despuÃ©s de probar la conexiÃ³n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cc6f69",
   "metadata": {},
   "source": [
    "## ðŸ“¤ **Paso 3: Migrar Datos desde CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c97f83d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Ejecuta 'await migrate_csv_data(50000)' despuÃ©s de crear el esquema\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“¤ FunciÃ³n para migrar datos\n",
    "async def migrate_csv_data(sample_size: int = 50000):\n",
    "    \"\"\"Migra datos desde CSV a PostgreSQL\"\"\"\n",
    "    try:\n",
    "        print(f\"ðŸ”„ Migrando {sample_size} filas desde CSV...\")\n",
    "\n",
    "        # Cargar muestra del CSV\n",
    "        df = pd.read_csv('train.csv', nrows=sample_size)\n",
    "        print(f\"ðŸ“Š CSV cargado: {df.shape}\")\n",
    "\n",
    "        # Limpiar datos bÃ¡sico\n",
    "        df = df.dropna()\n",
    "\n",
    "        # Filtrar datos vÃ¡lidos (NYC bounds)\n",
    "        df = df[\n",
    "            (df['pickup_longitude'] >= -74.3) & (df['pickup_longitude'] <= -73.7) &\n",
    "            (df['pickup_latitude'] >= 40.5) & (df['pickup_latitude'] <= 40.9) &\n",
    "            (df['dropoff_longitude'] >= -74.3) & (df['dropoff_longitude'] <= -73.7) &\n",
    "            (df['dropoff_latitude'] >= 40.5) & (df['dropoff_latitude'] <= 40.9) &\n",
    "            (df['trip_duration'] >= 30) & (df['trip_duration'] <= 21600) &  # 30 seg a 6 horas\n",
    "            (df['passenger_count'] >= 1) & (df['passenger_count'] <= 6)\n",
    "        ]\n",
    "\n",
    "        print(f\"ðŸ§¹ Datos limpios: {df.shape}\")\n",
    "\n",
    "        # Conectar a la base de datos\n",
    "        conn = await asyncpg.connect(\n",
    "            host=AWS_ENDPOINT,\n",
    "            port=DB_PORT,\n",
    "            database=DB_NAME,\n",
    "            user=DB_USER,\n",
    "            password=DB_PASSWORD\n",
    "        )\n",
    "\n",
    "        # Insertar datos en lotes\n",
    "        batch_size = 1000\n",
    "        total_inserted = 0\n",
    "\n",
    "        for i in range(0, len(df), batch_size):\n",
    "            batch = df.iloc[i:i+batch_size]\n",
    "\n",
    "            # Preparar datos para inserciÃ³n\n",
    "            trip_data = []\n",
    "            for _, row in batch.iterrows():\n",
    "                trip_data.append((\n",
    "                    str(row['id']),\n",
    "                    int(row['vendor_id']),\n",
    "                    pd.to_datetime(row['pickup_datetime']),\n",
    "                    pd.to_datetime(row['dropoff_datetime']),\n",
    "                    int(row['passenger_count']),\n",
    "                    float(row['pickup_longitude']),\n",
    "                    float(row['pickup_latitude']),\n",
    "                    float(row['dropoff_longitude']),\n",
    "                    float(row['dropoff_latitude']),\n",
    "                    str(row['store_and_fwd_flag']),\n",
    "                    float(row['trip_duration'])\n",
    "                ))\n",
    "\n",
    "            # Insertar lote\n",
    "            await conn.executemany(\"\"\"\n",
    "                INSERT INTO taxi_trips (\n",
    "                    id, vendor_id, pickup_datetime, dropoff_datetime,\n",
    "                    passenger_count, pickup_longitude, pickup_latitude,\n",
    "                    dropoff_longitude, dropoff_latitude, store_and_fwd_flag,\n",
    "                    trip_duration_seconds\n",
    "                ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11)\n",
    "                ON CONFLICT (id) DO NOTHING\n",
    "            \"\"\", trip_data)\n",
    "\n",
    "            total_inserted += len(trip_data)\n",
    "            print(f\"ðŸ“¤ Insertadas {total_inserted} filas...\")\n",
    "\n",
    "        await conn.close()\n",
    "        print(f\"âœ… MigraciÃ³n completa: {total_inserted} viajes\")\n",
    "        return total_inserted\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error en migraciÃ³n: {e}\")\n",
    "        return 0\n",
    "\n",
    "# âš ï¸ EJECUTAR DESPUÃ‰S DE CREAR EL ESQUEMA\n",
    "# total = await migrate_csv_data(50000)\n",
    "print(\"ðŸ’¡ Ejecuta 'await migrate_csv_data(50000)' despuÃ©s de crear el esquema\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aafd21",
   "metadata": {},
   "source": [
    "## ðŸ” **Paso 4: Validar Datos Migrados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9e26c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Ejecuta 'await validate_migrated_data()' despuÃ©s de la migraciÃ³n\n"
     ]
    }
   ],
   "source": [
    "# ðŸ” FunciÃ³n para validar datos\n",
    "async def validate_migrated_data():\n",
    "    \"\"\"Valida que los datos se migraron correctamente\"\"\"\n",
    "    try:\n",
    "        print(\"ðŸ”„ Validando datos migrados...\")\n",
    "\n",
    "        conn = await asyncpg.connect(\n",
    "            host=AWS_ENDPOINT,\n",
    "            port=DB_PORT,\n",
    "            database=DB_NAME,\n",
    "            user=DB_USER,\n",
    "            password=DB_PASSWORD\n",
    "        )\n",
    "\n",
    "        # EstadÃ­sticas bÃ¡sicas\n",
    "        stats = await conn.fetchrow(\"\"\"\n",
    "            SELECT\n",
    "                COUNT(*) as total_trips,\n",
    "                MIN(pickup_datetime) as earliest_trip,\n",
    "                MAX(pickup_datetime) as latest_trip,\n",
    "                AVG(trip_duration_seconds) as avg_duration_seconds,\n",
    "                AVG(passenger_count) as avg_passengers,\n",
    "                COUNT(DISTINCT vendor_id) as unique_vendors\n",
    "            FROM taxi_trips\n",
    "        \"\"\")\n",
    "\n",
    "        print(\"ðŸ“Š **ESTADÃSTICAS DE LA BASE DE DATOS:**\")\n",
    "        print(f\"   Total de viajes: {stats['total_trips']:,}\")\n",
    "        print(f\"   Primer viaje: {stats['earliest_trip']}\")\n",
    "        print(f\"   Ãšltimo viaje: {stats['latest_trip']}\")\n",
    "        print(f\"   DuraciÃ³n promedio: {stats['avg_duration_seconds']/60:.1f} minutos\")\n",
    "        print(f\"   Pasajeros promedio: {stats['avg_passengers']:.1f}\")\n",
    "        print(f\"   Vendors Ãºnicos: {stats['unique_vendors']}\")\n",
    "\n",
    "        # Muestra de datos\n",
    "        sample = await conn.fetch(\"SELECT * FROM taxi_trips LIMIT 5\")\n",
    "        print(f\"\\nðŸ” **MUESTRA DE DATOS:**\")\n",
    "        for i, row in enumerate(sample, 1):\n",
    "            print(f\"   {i}. Viaje {row['id']}: {row['trip_duration_seconds']/60:.1f} min, {row['passenger_count']} pasajeros\")\n",
    "\n",
    "        await conn.close()\n",
    "        print(\"âœ… ValidaciÃ³n completa!\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error en validaciÃ³n: {e}\")\n",
    "        return False\n",
    "\n",
    "# âš ï¸ EJECUTAR DESPUÃ‰S DE LA MIGRACIÃ“N\n",
    "# await validate_migrated_data()\n",
    "print(\"ðŸ’¡ Ejecuta 'await validate_migrated_data()' despuÃ©s de la migraciÃ³n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a3e03d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Creando esquema de base de datos...\n",
      "âœ… Esquema creado exitosamente!\n",
      "âœ… Esquema creado exitosamente!\n",
      "ðŸ“‹ Tablas creadas:\n",
      "   - taxi_trips\n",
      "   - predictions\n",
      "ðŸ“‹ Tablas creadas:\n",
      "   - taxi_trips\n",
      "   - predictions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await create_database_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b507e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Migrando 50000 filas desde CSV...\n",
      "ðŸ“Š CSV cargado: (50000, 11)\n",
      "ðŸ§¹ Datos limpios: (49719, 11)\n",
      "ðŸ“¤ Insertadas 1000 filas...\n",
      "ðŸ“¤ Insertadas 1000 filas...\n",
      "ðŸ“¤ Insertadas 2000 filas...\n",
      "ðŸ“¤ Insertadas 2000 filas...\n",
      "ðŸ“¤ Insertadas 3000 filas...\n",
      "ðŸ“¤ Insertadas 3000 filas...\n",
      "ðŸ“¤ Insertadas 4000 filas...\n",
      "ðŸ“¤ Insertadas 4000 filas...\n",
      "ðŸ“¤ Insertadas 5000 filas...\n",
      "ðŸ“¤ Insertadas 5000 filas...\n",
      "ðŸ“¤ Insertadas 6000 filas...\n",
      "ðŸ“¤ Insertadas 6000 filas...\n",
      "ðŸ“¤ Insertadas 7000 filas...\n",
      "ðŸ“¤ Insertadas 7000 filas...\n",
      "ðŸ“¤ Insertadas 8000 filas...\n",
      "ðŸ“¤ Insertadas 8000 filas...\n",
      "ðŸ“¤ Insertadas 9000 filas...\n",
      "ðŸ“¤ Insertadas 9000 filas...\n",
      "ðŸ“¤ Insertadas 10000 filas...\n",
      "ðŸ“¤ Insertadas 10000 filas...\n",
      "ðŸ“¤ Insertadas 11000 filas...\n",
      "ðŸ“¤ Insertadas 11000 filas...\n",
      "ðŸ“¤ Insertadas 12000 filas...\n",
      "ðŸ“¤ Insertadas 12000 filas...\n",
      "ðŸ“¤ Insertadas 13000 filas...\n",
      "ðŸ“¤ Insertadas 13000 filas...\n",
      "ðŸ“¤ Insertadas 14000 filas...\n",
      "ðŸ“¤ Insertadas 14000 filas...\n",
      "ðŸ“¤ Insertadas 15000 filas...\n",
      "ðŸ“¤ Insertadas 15000 filas...\n",
      "ðŸ“¤ Insertadas 16000 filas...\n",
      "ðŸ“¤ Insertadas 16000 filas...\n",
      "ðŸ“¤ Insertadas 17000 filas...\n",
      "ðŸ“¤ Insertadas 17000 filas...\n",
      "ðŸ“¤ Insertadas 18000 filas...\n",
      "ðŸ“¤ Insertadas 18000 filas...\n",
      "ðŸ“¤ Insertadas 19000 filas...\n",
      "ðŸ“¤ Insertadas 19000 filas...\n",
      "ðŸ“¤ Insertadas 20000 filas...\n",
      "ðŸ“¤ Insertadas 20000 filas...\n",
      "ðŸ“¤ Insertadas 21000 filas...\n",
      "ðŸ“¤ Insertadas 21000 filas...\n",
      "ðŸ“¤ Insertadas 22000 filas...\n",
      "ðŸ“¤ Insertadas 22000 filas...\n",
      "ðŸ“¤ Insertadas 23000 filas...\n",
      "ðŸ“¤ Insertadas 23000 filas...\n",
      "ðŸ“¤ Insertadas 24000 filas...\n",
      "ðŸ“¤ Insertadas 24000 filas...\n",
      "ðŸ“¤ Insertadas 25000 filas...\n",
      "ðŸ“¤ Insertadas 25000 filas...\n",
      "ðŸ“¤ Insertadas 26000 filas...\n",
      "ðŸ“¤ Insertadas 26000 filas...\n",
      "ðŸ“¤ Insertadas 27000 filas...\n",
      "ðŸ“¤ Insertadas 27000 filas...\n",
      "ðŸ“¤ Insertadas 28000 filas...\n",
      "ðŸ“¤ Insertadas 28000 filas...\n",
      "ðŸ“¤ Insertadas 29000 filas...\n",
      "ðŸ“¤ Insertadas 29000 filas...\n",
      "ðŸ“¤ Insertadas 30000 filas...\n",
      "ðŸ“¤ Insertadas 30000 filas...\n",
      "ðŸ“¤ Insertadas 31000 filas...\n",
      "ðŸ“¤ Insertadas 31000 filas...\n",
      "ðŸ“¤ Insertadas 32000 filas...\n",
      "ðŸ“¤ Insertadas 32000 filas...\n",
      "ðŸ“¤ Insertadas 33000 filas...\n",
      "ðŸ“¤ Insertadas 33000 filas...\n",
      "ðŸ“¤ Insertadas 34000 filas...\n",
      "ðŸ“¤ Insertadas 34000 filas...\n",
      "ðŸ“¤ Insertadas 35000 filas...\n",
      "ðŸ“¤ Insertadas 35000 filas...\n",
      "ðŸ“¤ Insertadas 36000 filas...\n",
      "ðŸ“¤ Insertadas 36000 filas...\n",
      "ðŸ“¤ Insertadas 37000 filas...\n",
      "ðŸ“¤ Insertadas 37000 filas...\n",
      "ðŸ“¤ Insertadas 38000 filas...\n",
      "ðŸ“¤ Insertadas 38000 filas...\n",
      "ðŸ“¤ Insertadas 39000 filas...\n",
      "ðŸ“¤ Insertadas 39000 filas...\n",
      "ðŸ“¤ Insertadas 40000 filas...\n",
      "ðŸ“¤ Insertadas 40000 filas...\n",
      "ðŸ“¤ Insertadas 41000 filas...\n",
      "ðŸ“¤ Insertadas 41000 filas...\n",
      "ðŸ“¤ Insertadas 42000 filas...\n",
      "ðŸ“¤ Insertadas 42000 filas...\n",
      "ðŸ“¤ Insertadas 43000 filas...\n",
      "ðŸ“¤ Insertadas 43000 filas...\n",
      "ðŸ“¤ Insertadas 44000 filas...\n",
      "ðŸ“¤ Insertadas 44000 filas...\n",
      "ðŸ“¤ Insertadas 45000 filas...\n",
      "ðŸ“¤ Insertadas 45000 filas...\n",
      "ðŸ“¤ Insertadas 46000 filas...\n",
      "ðŸ“¤ Insertadas 46000 filas...\n",
      "ðŸ“¤ Insertadas 47000 filas...\n",
      "ðŸ“¤ Insertadas 47000 filas...\n",
      "ðŸ“¤ Insertadas 48000 filas...\n",
      "ðŸ“¤ Insertadas 48000 filas...\n",
      "ðŸ“¤ Insertadas 49000 filas...\n",
      "ðŸ“¤ Insertadas 49000 filas...\n",
      "ðŸ“¤ Insertadas 49719 filas...\n",
      "âœ… MigraciÃ³n completa: 49719 viajes\n",
      "ðŸ“¤ Insertadas 49719 filas...\n",
      "âœ… MigraciÃ³n completa: 49719 viajes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49719"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await migrate_csv_data(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25e72725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Validando datos migrados...\n",
      "ðŸ“Š **ESTADÃSTICAS DE LA BASE DE DATOS:**\n",
      "   Total de viajes: 49,719\n",
      "   Primer viaje: 2016-01-01 00:08:07\n",
      "   Ãšltimo viaje: 2016-06-30 23:45:21\n",
      "   DuraciÃ³n promedio: 13.9 minutos\n",
      "   Pasajeros promedio: 1.7\n",
      "   Vendors Ãºnicos: 2\n",
      "\n",
      "ðŸ” **MUESTRA DE DATOS:**\n",
      "   1. Viaje id2875421: 7.6 min, 1 pasajeros\n",
      "   2. Viaje id2377394: 11.0 min, 1 pasajeros\n",
      "   3. Viaje id3858529: 35.4 min, 1 pasajeros\n",
      "   4. Viaje id3504673: 7.2 min, 1 pasajeros\n",
      "   5. Viaje id2181028: 7.2 min, 1 pasajeros\n",
      "ðŸ“Š **ESTADÃSTICAS DE LA BASE DE DATOS:**\n",
      "   Total de viajes: 49,719\n",
      "   Primer viaje: 2016-01-01 00:08:07\n",
      "   Ãšltimo viaje: 2016-06-30 23:45:21\n",
      "   DuraciÃ³n promedio: 13.9 minutos\n",
      "   Pasajeros promedio: 1.7\n",
      "   Vendors Ãºnicos: 2\n",
      "\n",
      "ðŸ” **MUESTRA DE DATOS:**\n",
      "   1. Viaje id2875421: 7.6 min, 1 pasajeros\n",
      "   2. Viaje id2377394: 11.0 min, 1 pasajeros\n",
      "   3. Viaje id3858529: 35.4 min, 1 pasajeros\n",
      "   4. Viaje id3504673: 7.2 min, 1 pasajeros\n",
      "   5. Viaje id2181028: 7.2 min, 1 pasajeros\n",
      "âœ… ValidaciÃ³n completa!\n",
      "âœ… ValidaciÃ³n completa!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await validate_migrated_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958484f2",
   "metadata": {},
   "source": [
    "## ðŸ“‹ **Resumen de FASE 2**\n",
    "\n",
    "### âœ… **Pasos completados:**\n",
    "1. **ConfiguraciÃ³n de conexiÃ³n** a AWS PostgreSQL\n",
    "2. **CreaciÃ³n de esquema** con tablas optimizadas\n",
    "3. **MigraciÃ³n de datos** desde CSV\n",
    "4. **ValidaciÃ³n** de integridad\n",
    "\n",
    "### ðŸ”— **String de conexiÃ³n para usar en el proyecto:**\n",
    "```python\n",
    "CONNECTION_STRING = \"postgresql://taxiuser:TaxiDB2025!@[ENDPOINT]:5432/taxi_db\"\n",
    "```\n",
    "\n",
    "### ðŸŽ¯ **PrÃ³ximos pasos (FASE 3):**\n",
    "1. **Implementar MLflow** tracking\n",
    "2. **Crear adaptador ML** \n",
    "3. **Pipeline de entrenamiento**\n",
    "4. **API FastAPI**\n",
    "\n",
    "### ðŸ’¡ **Para las diapositivas:**\n",
    "*\"Implementamos el primer adaptador de nuestra arquitectura hexagonal: PostgreSQLAdapter que conecta con AWS RDS, demostrando cÃ³mo los puertos y adaptadores nos permiten cambiar de CSV a base de datos real sin afectar el dominio del negocio.\"*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
