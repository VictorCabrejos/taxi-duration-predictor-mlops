---
marp: true
theme: default
paginate: true
header: 'Machine Learning y Big Data - UNMSM'
footer: 'Sesiones 14-15: IntroducciÃ³n a Big Data'
---

# Big Data: From MLOps to Scalable Data Processing ğŸš€

**Sesiones 14-15**
**Machine Learning y Big Data - UNMSM**

**Profesor:** Victor M. Cabrejos Jr.
**Tema:** TransiciÃ³n de MLOps tradicional a procesamiento distribuido

---

# Â¿QuÃ© es Big Data?

**Los 6 Vs del Big Data moderno:**

- **Volume (Volumen) ğŸ“Š**
  - Terabytes, petabytes de datos
  - MÃ¡s allÃ¡ de la capacidad de una sola mÃ¡quina

- **Velocity (Velocidad) âš¡**
  - Datos generados en tiempo real
  - Streaming de datos continuo

---

# Los 6 Vs del Big Data (Parte 2)

- **Variety (Variedad) ğŸ”„**
  - Datos estructurados, semi-estructurados, no estructurados
  - MÃºltiples formatos: JSON, CSV, imÃ¡genes, texto

- **Veracity (Veracidad) âœ…**
  - Calidad y confiabilidad de los datos
  - Manejo de datos incompletos o incorrectos

---

# Los 6 Vs del Big Data (Parte 3)

- **Value (Valor) ğŸ’**
  - Capacidad de extraer insights valiosos
  - ROI del procesamiento de datos

- **Variability (Variabilidad) ğŸŒŠ**
  - Inconsistencia en flujos de datos
  - Patrones cambiantes en el tiempo

**Nivel master:** Estas dimensiones son crÃ­ticas para proyectos empresariales

---

# Ejemplos de Big Data

**Casos reales:**

- **Volume:** Millones de viajes de taxi por dÃ­a en NYC
- **Velocity:** Transacciones bancarias en tiempo real
- **Variety:** Logs + datos de usuarios + mÃ©tricas

**Â¿Por quÃ© importa?**
- Los mÃ©todos tradicionales no escalan
- Necesitamos procesamiento distribuido

---

# Pandas vs. Big Data - Problema

**âŒ Limitaciones con Pandas:**

```python
# Esto NO funciona con datasets grandes:
df = pd.read_csv("10TB_dataset.csv")  # Memory Error!
df.groupby('category').sum()  # Single-threaded
```

**El problema:** Una sola mÃ¡quina, memoria limitada

---

# Pandas vs. Big Data - SoluciÃ³n

**âœ… SoluciÃ³n con PySpark:**

```python
# PySpark distribuye el trabajo:
df = spark.read.csv("10TB_dataset.csv")  # Distributed!
df.groupBy('category').sum()  # Multi-node processing
```

**La diferencia clave:**
Pandas = una mÃ¡quina | PySpark = cluster de mÃ¡quinas

---

# Â¿QuÃ© es Apache Spark?

**Motor de procesamiento distribuido para Big Data:**

- **In-memory computing** â†’ 100x mÃ¡s rÃ¡pido que Hadoop
- **Unified Analytics Engine** â†’ Batch + Streaming + ML + SQL
- **Fault-tolerant** â†’ RecuperaciÃ³n automÃ¡tica de errores

**Â¿Por quÃ© PySpark?**
- Python API para Apache Spark
- Sintaxis familiar similar a pandas

---

# Arquitectura Distribuida de Spark

```
Driver Program â†’ Cluster Manager â†’ Worker Nodes
     â†“               â†“                 â†“
   PySpark        YARN/Mesos      Executors
```

**Ventajas:**
- **Escalabilidad horizontal** (mÃ¡s mÃ¡quinas = mÃ¡s poder)
- **Procesamiento paralelo** automÃ¡tico
- **Cloud-ready** (AWS, GCP, Azure, Databricks)

---

# Â¿QuÃ© es Databricks? ğŸ—ï¸

**Plataforma unificada para analytics y ML:**

- **Apache Spark optimizado** en la nube
- **Collaborative notebooks** para equipos
- **Auto-scaling clusters** segÃºn demanda
- **Integrated MLflow** para MLOps

**Â¿Por quÃ© es importante?**
- Elimina la complejidad de configuraciÃ³n
- Perfecto para equipos de data science

---

# Databricks Community Edition

**ğŸ†“ GRATIS para aprender:**

- **15GB storage** incluido
- **Single-node cluster** automÃ¡tico
- **Notebooks interactivos** pre-configurados
- **Conectividad con AWS/Azure**
- **Ideal para proyectos educativos**

**Perfecto para nuestro curso** âœ…

---

# Workflow tÃ­pico en Databricks

**Proceso paso a paso:**

1. **Upload data** â†’ Databricks FileStore
2. **Create cluster** â†’ Auto-configured Spark
3. **Process data** â†’ PySpark notebooks
4. **Deploy models** â†’ MLflow integration

**Todo en una plataforma integrada** ğŸš€

---

# EvoluciÃ³n: Traditional MLOps â†’ Big Data MLOps

**Pipeline tradicional:**
```
pandas â†’ sklearn â†’ MLflow â†’ FastAPI â†’ Docker
```

**Pipeline Big Data:**
```
PySpark â†’ MLlib â†’ MLflow â†’ Databricks â†’ Cloud
```

**La diferencia:** Escalabilidad automÃ¡tica

---

# Ventajas de Big Data para ML

**ğŸ¤– Scalable Feature Engineering**
- Procesar millones de features en paralelo
- Feature stores distribuidos

**ğŸ“ˆ Distributed Model Training**
- Hyperparameter tuning en cluster
- Ensemble models en paralelo

**âš¡ Real-time Predictions**
- Streaming ML pipelines
- Sub-second inference at scale

---

# SesiÃ³n 14: Databricks Setup + PySpark Basics

**Objetivos prÃ¡cticos:**

- Configurar Databricks Community Edition
- Migrar nuestro dataset de taxis a PySpark
- Comparar performance: pandas vs. PySpark

**Resultado:** Entender las diferencias en la prÃ¡ctica

---

# SesiÃ³n 15: Big Data MLOps Pipeline

**ConstrucciÃ³n del pipeline distribuido:**

- Feature engineering distribuido
- Model training con MLlib
- Integration con nuestro MLOps stack existente

**Objetivo final:**
Convertir **taxi-duration-predictor** en un sistema que maneje **millones de viajes** ğŸš€
