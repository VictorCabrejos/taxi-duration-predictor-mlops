# ğŸ“Š MLOps Dashboard with Streamlit + MLflow
# FASE 4A: Dashboard ProgramÃ¡tico para Monitoreo de Modelos

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import mlflow
from mlflow.tracking import MlflowClient
import asyncio
import asyncpg
from datetime import datetime, timedelta
import requests
import json
import warnings

warnings.filterwarnings("ignore")

# ğŸ”§ ConfiguraciÃ³n de pÃ¡gina
st.set_page_config(
    page_title="ğŸš• Taxi Duration Predictor - MLOps Dashboard",
    page_icon="ğŸš•",
    layout="wide",
    initial_sidebar_state="expanded",
)

# ğŸ¨ CSS personalizado
st.markdown(
    """
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
    }
    .success-metric {
        border-left-color: #28a745;
    }
    .warning-metric {
        border-left-color: #ffc107;
    }
    .error-metric {
        border-left-color: #dc3545;
    }
</style>
""",
    unsafe_allow_html=True,
)


# ğŸš€ Funciones utilitarias
@st.cache_data
def load_mlflow_experiments():
    """Carga experimentos desde MLflow programÃ¡ticamente"""
    try:
        # Configurar MLflow
        mlflow.set_tracking_uri("sqlite:///mlflow.db")
        client = MlflowClient()

        # Obtener experimento
        experiment = client.get_experiment_by_name("taxi_duration_prediction")
        if not experiment:
            return None, "No se encontrÃ³ el experimento taxi_duration_prediction"

        # Obtener todas las runs
        runs = client.search_runs(
            experiment_ids=[experiment.experiment_id], order_by=["start_time DESC"]
        )

        # Convertir a DataFrame
        runs_data = []
        for run in runs:
            run_data = {
                "run_id": run.info.run_id,
                "run_name": run.data.tags.get("mlflow.runName", "Unnamed"),
                "model_type": run.data.params.get("model_type", "Unknown"),
                "rmse": float(run.data.metrics.get("rmse", 0)),
                "mae": float(run.data.metrics.get("mae", 0)),
                "r2_score": float(run.data.metrics.get("r2_score", 0)),
                "training_time": float(
                    run.data.metrics.get("training_time_seconds", 0)
                ),
                "start_time": pd.to_datetime(run.info.start_time, unit="ms"),
                "status": run.info.status,
                "train_size": int(run.data.params.get("train_size", 0)),
                "test_size": int(run.data.params.get("test_size", 0)),
            }
            runs_data.append(run_data)

        df = pd.DataFrame(runs_data)
        return df, None

    except Exception as e:
        return None, f"Error cargando MLflow: {str(e)}"


@st.cache_data
def get_best_model():
    """Obtiene el mejor modelo automÃ¡ticamente"""
    df, error = load_mlflow_experiments()
    if error:
        return None, error

    if df.empty:
        return None, "No hay experimentos disponibles"

    # Ordenar por RMSE (menor es mejor)
    best_run = df.loc[df["rmse"].idxmin()]
    return best_run, None


async def get_database_stats():
    """Obtiene estadÃ­sticas actuales de la base de datos"""
    try:
        conn = await asyncpg.connect(
            host="taxi-duration-db.ckj7uy651uld.us-east-1.rds.amazonaws.com",
            port=5432,
            database="postgres",
            user="taxiuser",
            password="TaxiDB2025!",
        )

        # EstadÃ­sticas generales
        stats = await conn.fetchrow(
            """
            SELECT
                COUNT(*) as total_trips,
                AVG(trip_duration_seconds) as avg_duration,
                MIN(pickup_datetime) as earliest_trip,
                MAX(pickup_datetime) as latest_trip,
                COUNT(DISTINCT vendor_id) as unique_vendors
            FROM taxi_trips
        """
        )

        # DistribuciÃ³n por hora
        hourly_stats = await conn.fetch(
            """
            SELECT
                EXTRACT(HOUR FROM pickup_datetime) as hour,
                COUNT(*) as trip_count,
                AVG(trip_duration_seconds) as avg_duration
            FROM taxi_trips
            GROUP BY EXTRACT(HOUR FROM pickup_datetime)
            ORDER BY hour
        """
        )

        await conn.close()

        return {
            "general": dict(stats),
            "hourly": [dict(row) for row in hourly_stats],
        }, None

    except Exception as e:
        return None, f"Error conectando a base de datos: {str(e)}"


# ï¿½ Funciones para monitoreo del FastAPI
FASTAPI_BASE_URL = "http://localhost:8000"

@st.cache_data(ttl=30)  # Cache por 30 segundos
def check_api_health():
    """Verifica el estado del API FastAPI"""
    try:
        response = requests.get(f"{FASTAPI_BASE_URL}/health", timeout=5)
        if response.status_code == 200:
            return response.json(), None
        else:
            return None, f"API respondiÃ³ con cÃ³digo {response.status_code}"
    except requests.exceptions.ConnectionError:
        return None, "API no disponible - Â¿EstÃ¡ ejecutÃ¡ndose en puerto 8000?"
    except requests.exceptions.Timeout:
        return None, "Timeout conectando al API"
    except Exception as e:
        return None, f"Error verificando API: {str(e)}"

@st.cache_data(ttl=60)  # Cache por 1 minuto
def get_api_model_info():
    """Obtiene informaciÃ³n del modelo desde el API"""
    try:
        response = requests.get(f"{FASTAPI_BASE_URL}/model/info", timeout=5)
        if response.status_code == 200:
            return response.json(), None
        else:
            return None, f"Error obteniendo info del modelo: {response.status_code}"
    except Exception as e:
        return None, f"Error: {str(e)}"

def make_api_prediction(prediction_data):
    """Hace una predicciÃ³n usando el API FastAPI"""
    try:
        response = requests.post(
            f"{FASTAPI_BASE_URL}/predict",
            json=prediction_data,
            timeout=10
        )
        if response.status_code == 200:
            return response.json(), None
        else:
            return None, f"Error en predicciÃ³n: {response.status_code} - {response.text}"
    except Exception as e:
        return None, f"Error haciendo predicciÃ³n: {str(e)}"

@st.cache_data(ttl=300)  # Cache por 5 minutos
def get_api_database_stats():
    """Obtiene estadÃ­sticas de la base de datos desde el API"""
    try:
        response = requests.get(f"{FASTAPI_BASE_URL}/stats/database", timeout=10)
        if response.status_code == 200:
            return response.json(), None
        else:
            return None, f"Error obteniendo estadÃ­sticas: {response.status_code}"
    except Exception as e:
        return None, f"Error: {str(e)}"


# ï¿½ğŸ“Š Header principal
st.markdown(
    '<h1 class="main-header">ğŸš• MLOps Dashboard - Taxi Duration Predictor</h1>',
    unsafe_allow_html=True,
)

# ğŸ”„ Sidebar para controles
st.sidebar.markdown("## ğŸ›ï¸ Controles del Dashboard")

# BotÃ³n de refresh
if st.sidebar.button("ğŸ”„ Actualizar Datos", type="primary"):
    st.cache_data.clear()
    st.rerun()

# Selector de vista
view_mode = st.sidebar.selectbox(
    "ğŸ“Š Seleccionar Vista",
    [
        "ğŸ“ˆ Overview General",
        "ğŸ¤– ComparaciÃ³n de Modelos",
        "ğŸ“Š AnÃ¡lisis de Datos",
        "ğŸš€ API Status & Monitoring",
        "ğŸ¯ Monitoreo en Tiempo Real",
    ],
)

st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ“‹ InformaciÃ³n del Sistema")
st.sidebar.info(
    f"""
**Ãšltima actualizaciÃ³n:** {datetime.now().strftime('%H:%M:%S')}
**MLflow URI:** sqlite:///mlflow.db
**Base de datos:** AWS PostgreSQL
**Estado:** ğŸŸ¢ Activo
"""
)

# ğŸ“Š Vista Overview General
if view_mode == "ğŸ“ˆ Overview General":
    st.markdown("## ğŸ“ˆ Resumen Ejecutivo")

    # Cargar datos de MLflow
    experiments_df, mlflow_error = load_mlflow_experiments()

    if mlflow_error:
        st.error(f"âŒ Error con MLflow: {mlflow_error}")
    else:
        # MÃ©tricas principales
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.markdown(
                '<div class="metric-card success-metric">', unsafe_allow_html=True
            )
            st.metric(
                label="ğŸ¤– Experimentos Totales",
                value=len(experiments_df) if experiments_df is not None else 0,
            )
            st.markdown("</div>", unsafe_allow_html=True)

        with col2:
            if experiments_df is not None and not experiments_df.empty:
                best_rmse = experiments_df["rmse"].min()
                st.markdown(
                    '<div class="metric-card success-metric">', unsafe_allow_html=True
                )
                st.metric(label="ğŸ† Mejor RMSE", value=f"{best_rmse:.2f} min")
                st.markdown("</div>", unsafe_allow_html=True)

        with col3:
            if experiments_df is not None and not experiments_df.empty:
                best_r2 = experiments_df["r2_score"].max()
                st.markdown(
                    '<div class="metric-card success-metric">', unsafe_allow_html=True
                )
                st.metric(label="ğŸ“Š Mejor RÂ²", value=f"{best_r2:.3f}")
                st.markdown("</div>", unsafe_allow_html=True)

        with col4:
            if experiments_df is not None and not experiments_df.empty:
                avg_training_time = experiments_df["training_time"].mean()
                st.markdown('<div class="metric-card">', unsafe_allow_html=True)
                st.metric(label="â±ï¸ Tiempo Promedio", value=f"{avg_training_time:.1f}s")
                st.markdown("</div>", unsafe_allow_html=True)

        # Mejor modelo actual
        best_model, best_error = get_best_model()

        if not best_error and best_model is not None:
            st.markdown("## ğŸ† Modelo en ProducciÃ³n (Recomendado)")

            col1, col2 = st.columns([2, 1])

            with col1:
                st.success(
                    f"""
                **ğŸ¤– Modelo:** {best_model['model_type']}
                **ğŸ“Š RMSE:** {best_model['rmse']:.2f} minutos
                **ğŸ“ˆ MAE:** {best_model['mae']:.2f} minutos
                **ğŸ¯ RÂ²:** {best_model['r2_score']:.3f}
                **â±ï¸ Tiempo de entrenamiento:** {best_model['training_time']:.1f}s
                **ğŸ“… Entrenado:** {best_model['start_time'].strftime('%Y-%m-%d %H:%M')}
                """
                )

            with col2:
                # GrÃ¡fico de mÃ©tricas del mejor modelo
                metrics_data = {
                    "MÃ©trica": ["RMSE", "MAE", "RÂ²"],
                    "Valor": [
                        best_model["rmse"],
                        best_model["mae"],
                        best_model["r2_score"],
                    ],
                    "Objetivo": ["Minimizar", "Minimizar", "Maximizar"],
                }
                metrics_df = pd.DataFrame(metrics_data)

                fig = px.bar(
                    metrics_df,
                    x="MÃ©trica",
                    y="Valor",
                    color="Objetivo",
                    title="MÃ©tricas del Mejor Modelo",
                )
                fig.update_layout(height=300)
                st.plotly_chart(fig, use_container_width=True)

# ğŸ¤– Vista ComparaciÃ³n de Modelos
elif view_mode == "ğŸ¤– ComparaciÃ³n de Modelos":
    st.markdown("## ğŸ¤– ComparaciÃ³n Detallada de Modelos")

    experiments_df, error = load_mlflow_experiments()

    if error:
        st.error(f"âŒ Error: {error}")
    elif experiments_df is None or experiments_df.empty:
        st.warning(
            "âš ï¸ No hay experimentos disponibles. Ejecuta primero el notebook de entrenamiento."
        )
    else:
        # Tabla de comparaciÃ³n
        st.markdown("### ğŸ“Š Tabla de Resultados")

        # Formatear tabla para mostrar
        display_df = experiments_df[
            ["model_type", "rmse", "mae", "r2_score", "training_time", "start_time"]
        ].copy()
        display_df["start_time"] = display_df["start_time"].dt.strftime(
            "%Y-%m-%d %H:%M"
        )
        display_df = display_df.sort_values("rmse")

        # Colorear la tabla
        st.dataframe(
            display_df,
            column_config={
                "model_type": "ğŸ¤– Modelo",
                "rmse": st.column_config.NumberColumn("ğŸ“Š RMSE", format="%.2f"),
                "mae": st.column_config.NumberColumn("ğŸ“ˆ MAE", format="%.2f"),
                "r2_score": st.column_config.NumberColumn("ğŸ¯ RÂ²", format="%.3f"),
                "training_time": st.column_config.NumberColumn(
                    "â±ï¸ Tiempo (s)", format="%.1f"
                ),
                "start_time": "ğŸ“… Fecha",
            },
            use_container_width=True,
        )

        # GrÃ¡ficos de comparaciÃ³n
        col1, col2 = st.columns(2)

        with col1:
            # GrÃ¡fico RMSE vs MAE
            fig1 = px.scatter(
                experiments_df,
                x="rmse",
                y="mae",
                color="model_type",
                size="r2_score",
                title="ğŸ“Š RMSE vs MAE por Modelo",
                hover_data=["training_time"],
            )
            fig1.update_layout(height=400)
            st.plotly_chart(fig1, use_container_width=True)

        with col2:
            # GrÃ¡fico de barras RÂ²
            fig2 = px.bar(
                experiments_df,
                x="model_type",
                y="r2_score",
                color="model_type",
                title="ğŸ¯ RÂ² Score por Modelo",
            )
            fig2.update_layout(height=400)
            st.plotly_chart(fig2, use_container_width=True)

        # AnÃ¡lisis de performance
        st.markdown("### ğŸ AnÃ¡lisis de Performance")

        best_model = experiments_df.loc[experiments_df["rmse"].idxmin()]
        worst_model = experiments_df.loc[experiments_df["rmse"].idxmax()]

        col1, col2, col3 = st.columns(3)

        with col1:
            st.success(
                f"""
            **ğŸ† MEJOR MODELO**
            **Tipo:** {best_model['model_type']}
            **RMSE:** {best_model['rmse']:.2f} min
            **RÂ²:** {best_model['r2_score']:.3f}
            """
            )

        with col2:
            st.error(
                f"""
            **âŒ PEOR MODELO**
            **Tipo:** {worst_model['model_type']}
            **RMSE:** {worst_model['rmse']:.2f} min
            **RÂ²:** {worst_model['r2_score']:.3f}
            """
            )

        with col3:
            improvement = (
                (worst_model["rmse"] - best_model["rmse"]) / worst_model["rmse"]
            ) * 100
            st.info(
                f"""
            **ğŸ“ˆ MEJORA**
            **ReducciÃ³n RMSE:** {improvement:.1f}%
            **Diferencia:** {worst_model['rmse'] - best_model['rmse']:.2f} min
            **Impacto:** Predicciones mÃ¡s precisas
            """
            )

# ğŸ“Š Vista AnÃ¡lisis de Datos
elif view_mode == "ğŸ“Š AnÃ¡lisis de Datos":
    st.markdown("## ğŸ“Š AnÃ¡lisis de Datos de ProducciÃ³n")

    # Cargar estadÃ­sticas de la base de datos
    with st.spinner("Cargando datos de la base de datos..."):
        db_stats, db_error = asyncio.run(get_database_stats())

    if db_error:
        st.error(f"âŒ Error conectando a la base de datos: {db_error}")
    else:
        # EstadÃ­sticas generales
        st.markdown("### ğŸ“‹ EstadÃ­sticas Generales")

        general_stats = db_stats["general"]

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric(
                label="ğŸš• Total de Viajes", value=f"{general_stats['total_trips']:,}"
            )

        with col2:
            avg_duration_min = general_stats["avg_duration"] / 60
            st.metric(label="â±ï¸ DuraciÃ³n Promedio", value=f"{avg_duration_min:.1f} min")

        with col3:
            st.metric(label="ğŸ¢ Vendors Ãšnicos", value=general_stats["unique_vendors"])

        with col4:
            date_range = (
                general_stats["latest_trip"] - general_stats["earliest_trip"]
            ).days
            st.metric(label="ğŸ“… Rango de Datos", value=f"{date_range} dÃ­as")

        # DistribuciÃ³n por hora
        st.markdown("### ğŸ“ˆ DistribuciÃ³n de Viajes por Hora")

        hourly_data = pd.DataFrame(db_stats["hourly"])
        hourly_data["avg_duration_min"] = hourly_data["avg_duration"] / 60

        col1, col2 = st.columns(2)

        with col1:
            fig1 = px.bar(
                hourly_data,
                x="hour",
                y="trip_count",
                title="ğŸš• NÃºmero de Viajes por Hora del DÃ­a",
            )
            fig1.update_xaxes(title="Hora del DÃ­a")
            fig1.update_yaxes(title="NÃºmero de Viajes")
            st.plotly_chart(fig1, use_container_width=True)

        with col2:
            fig2 = px.line(
                hourly_data,
                x="hour",
                y="avg_duration_min",
                title="â±ï¸ DuraciÃ³n Promedio por Hora del DÃ­a",
                markers=True,
            )
            fig2.update_xaxes(title="Hora del DÃ­a")
            fig2.update_yaxes(title="DuraciÃ³n Promedio (minutos)")
            st.plotly_chart(fig2, use_container_width=True)

        # Insights automÃ¡ticos
        st.markdown("### ğŸ§  Insights AutomÃ¡ticos")

        busiest_hour = hourly_data.loc[hourly_data["trip_count"].idxmax()]
        longest_duration_hour = hourly_data.loc[
            hourly_data["avg_duration_min"].idxmax()
        ]

        col1, col2 = st.columns(2)

        with col1:
            st.info(
                f"""
            **ğŸš¦ Hora MÃ¡s Ocupada**
            **Hora:** {int(busiest_hour['hour'])}:00
            **Viajes:** {int(busiest_hour['trip_count']):,}
            **DuraciÃ³n promedio:** {busiest_hour['avg_duration_min']:.1f} min
            """
            )

        with col2:
            st.warning(
                f"""
            **ğŸŒ Hora con Mayor DuraciÃ³n**
            **Hora:** {int(longest_duration_hour['hour'])}:00
            **DuraciÃ³n promedio:** {longest_duration_hour['avg_duration_min']:.1f} min
            **Viajes:** {int(longest_duration_hour['trip_count']):,}
            """
            )

# ğŸš€ Vista API Status & Monitoring
elif view_mode == "ğŸš€ API Status & Monitoring":
    st.markdown("## ğŸš€ API Status & Monitoring")
    st.markdown("*Monitor del FastAPI Server y mÃ©tricas de rendimiento*")

    # Health Check del API
    st.markdown("### ï¿½ Estado del API")

    api_health, health_error = check_api_health()

    if health_error:
        st.error(f"âŒ API No Disponible: {health_error}")
        st.info("ğŸ’¡ **Para activar el API:** `source activate ds_env && python 05_fastapi_server.py`")
    else:
        # Mostrar estado del API
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric(
                label="ğŸŸ¢ API Status",
                value=api_health["status"].upper()
            )

        with col2:
            st.metric(
                label="ğŸ¤– Model Loaded",
                value="âœ… YES" if api_health["model_loaded"] else "âŒ NO"
            )

        with col3:
            st.metric(
                label="ğŸ—„ï¸ Database",
                value=api_health["database_status"].upper()
            )

        with col4:
            st.metric(
                label="ğŸ•’ Last Check",
                value=datetime.fromisoformat(api_health["timestamp"].replace('Z', '+00:00')).strftime("%H:%M:%S")
            )

        # InformaciÃ³n del modelo en el API
        if api_health["model_loaded"]:
            st.markdown("### ğŸ¤– Modelo en ProducciÃ³n (API)")

            model_info, model_error = get_api_model_info()

            if not model_error and model_info:
                col1, col2 = st.columns([2, 1])

                with col1:
                    metadata = model_info["model_metadata"]
                    st.success(f"""
                    **ğŸ¤– Modelo:** {metadata['model_type']}
                    **ğŸ“Š RMSE:** {metadata['rmse']:.2f} minutos
                    **ğŸ“ˆ MAE:** {metadata['mae']:.2f} minutos
                    **ï¿½ğŸ¯ RÂ²:** {metadata['r2_score']:.3f}
                    **ğŸ”§ Run ID:** {metadata['run_id'][:12]}...
                    **ğŸ“… Cargado:** {metadata['loaded_at'][:16]}
                    **ğŸ’¾ Train Size:** {metadata['train_size']:,} registros
                    """)

                with col2:
                    # Features requeridas
                    st.markdown("**ğŸ“‹ Features Requeridas:**")
                    features_df = pd.DataFrame({
                        "Feature": model_info["features_required"],
                        "Tipo": ["NumÃ©rico"] * len(model_info["features_required"])
                    })
                    st.dataframe(features_df, hide_index=True, use_container_width=True)

        # Test de predicciÃ³n usando el API
        st.markdown("### ğŸ§ª Test de PredicciÃ³n API")

        with st.expander("ğŸš€ Probar PredicciÃ³n via API", expanded=False):
            with st.form("api_prediction_form"):
                col1, col2 = st.columns(2)

                with col1:
                    pickup_lat = st.number_input("ğŸ“ Pickup Latitude", value=40.7589, format="%.6f")
                    pickup_lon = st.number_input("ğŸ“ Pickup Longitude", value=-73.9851, format="%.6f")
                    dropoff_lat = st.number_input("ğŸ“ Dropoff Latitude", value=40.7505, format="%.6f")
                    dropoff_lon = st.number_input("ğŸ“ Dropoff Longitude", value=-73.9934, format="%.6f")

                with col2:
                    passenger_count = st.selectbox("ğŸ‘¥ Passengers", [1,2,3,4,5,6], index=1)
                    vendor_id = st.selectbox("ğŸ¢ Vendor ID", [1,2])
                    pickup_hour = st.slider("ğŸ• Pickup Hour", 0, 23, 14)
                    day_of_week = st.slider("ğŸ“… Day of Week", 0, 6, 2)
                    month = st.slider("ğŸ“† Month", 1, 12, 7)

                submitted = st.form_submit_button("ğŸš€ Predecir via API", type="primary")

                if submitted:
                    prediction_data = {
                        "pickup_latitude": pickup_lat,
                        "pickup_longitude": pickup_lon,
                        "dropoff_latitude": dropoff_lat,
                        "dropoff_longitude": dropoff_lon,
                        "passenger_count": passenger_count,
                        "vendor_id": vendor_id,
                        "pickup_hour": pickup_hour,
                        "day_of_week": day_of_week,
                        "month": month
                    }

                    prediction_result, pred_error = make_api_prediction(prediction_data)

                    if pred_error:
                        st.error(f"âŒ Error en predicciÃ³n: {pred_error}")
                    else:
                        # Mostrar resultado
                        col1, col2, col3 = st.columns(3)

                        with col1:
                            st.metric(
                                "ğŸ¯ DuraciÃ³n Predicha",
                                f"{prediction_result['predicted_duration_minutes']:.1f} min"
                            )

                        with col2:
                            st.metric(
                                "ğŸ“ Distancia",
                                f"{prediction_result['distance_km']:.2f} km"
                            )

                        with col3:
                            st.metric(
                                "ğŸ² Confianza",
                                f"{prediction_result['confidence_score']:.1%}"
                            )

                        # Detalles de la predicciÃ³n
                        st.markdown("**ğŸ“Š Detalles de la PredicciÃ³n:**")
                        details_data = []
                        for feature, value in prediction_result['features_used'].items():
                            details_data.append({"Feature": feature, "Valor": value})

                        details_df = pd.DataFrame(details_data)
                        st.dataframe(details_df, hide_index=True, use_container_width=True)

                        # JSON Response
                        with st.expander("ğŸ“„ Respuesta JSON completa"):
                            st.json(prediction_result)

        # EstadÃ­sticas via API
        st.markdown("### ğŸ“Š EstadÃ­sticas de la Base de Datos (via API)")

        api_stats, stats_error = get_api_database_stats()

        if stats_error:
            st.warning(f"âš ï¸ No se pudieron obtener estadÃ­sticas: {stats_error}")
        else:
            col1, col2, col3 = st.columns(3)

            with col1:
                st.metric(
                    "ğŸš• Total Viajes",
                    f"{api_stats['total_trips']:,}"
                )

            with col2:
                st.metric(
                    "â±ï¸ DuraciÃ³n Promedio",
                    f"{api_stats['avg_duration_minutes']:.1f} min"
                )

            with col3:
                st.metric(
                    "ğŸ“… Ãšltima ActualizaciÃ³n",
                    api_stats['last_updated'][:16]
                )

        # URLs Ãºtiles
        st.markdown("### ğŸ”— Enlaces Ãštiles")

        col1, col2, col3 = st.columns(3)

        with col1:
            st.markdown("**ğŸ“– [Swagger Docs](http://localhost:8000/docs)**")
            st.caption("DocumentaciÃ³n interactiva del API")

        with col2:
            st.markdown("**ğŸ“š [ReDoc](http://localhost:8000/redoc)**")
            st.caption("DocumentaciÃ³n alternativa")

        with col3:
            st.markdown("**ğŸ¥ [Health Check](http://localhost:8000/health)**")
            st.caption("Status del API en JSON")

# ğŸ¯ Vista Monitoreo en Tiempo Real
elif view_mode == "ğŸ¯ Monitoreo en Tiempo Real":
    st.markdown("## ğŸ¯ Simulador de Predicciones en Tiempo Real")

    # Obtener mejor modelo
    best_model, error = get_best_model()

    if error:
        st.error(f"âŒ Error: {error}")
    else:
        st.success(
            f"ğŸ¤– Usando modelo: **{best_model['model_type']}** (RMSE: {best_model['rmse']:.2f} min)"
        )

        st.markdown("### ğŸ® Simulador de PredicciÃ³n")

        # Formulario de entrada
        with st.form("prediction_form"):
            col1, col2 = st.columns(2)

            with col1:
                pickup_lat = st.number_input(
                    "ğŸ“ Latitud Pickup", value=40.7589, format="%.6f"
                )
                pickup_lon = st.number_input(
                    "ğŸ“ Longitud Pickup", value=-73.9851, format="%.6f"
                )
                dropoff_lat = st.number_input(
                    "ğŸ“ Latitud Dropoff", value=40.7505, format="%.6f"
                )
                dropoff_lon = st.number_input(
                    "ğŸ“ Longitud Dropoff", value=-73.9934, format="%.6f"
                )

            with col2:
                passenger_count = st.selectbox(
                    "ğŸ‘¥ NÃºmero de Pasajeros", [1, 2, 3, 4, 5, 6]
                )
                vendor_id = st.selectbox("ğŸ¢ Vendor ID", [1, 2])
                pickup_hour = st.slider("ğŸ• Hora de Pickup", 0, 23, 12)
                day_of_week = st.selectbox(
                    "ğŸ“… DÃ­a de la Semana",
                    [
                        "Lunes",
                        "Martes",
                        "MiÃ©rcoles",
                        "Jueves",
                        "Viernes",
                        "SÃ¡bado",
                        "Domingo",
                    ],
                )

            submitted = st.form_submit_button("ğŸš€ Predecir DuraciÃ³n", type="primary")

        if submitted:
            # Simular predicciÃ³n (en un caso real, cargarÃ­as el modelo desde MLflow)

            # Calcular distancia
            def haversine_distance(lat1, lon1, lat2, lon2):
                R = 6371
                lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])
                dlat = lat2 - lat1
                dlon = lon2 - lon1
                a = (
                    np.sin(dlat / 2) ** 2
                    + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2
                )
                return 2 * R * np.arcsin(np.sqrt(a))

            distance = haversine_distance(
                pickup_lat, pickup_lon, dropoff_lat, dropoff_lon
            )

            # Features simuladas
            day_mapping = {
                "Lunes": 0,
                "Martes": 1,
                "MiÃ©rcoles": 2,
                "Jueves": 3,
                "Viernes": 4,
                "SÃ¡bado": 5,
                "Domingo": 6,
            }
            day_num = day_mapping[day_of_week]
            is_weekend = 1 if day_num >= 5 else 0
            is_rush_hour = 1 if pickup_hour in [7, 8, 9, 17, 18, 19] else 0

            # PredicciÃ³n simulada (basada en el patrÃ³n del mejor modelo)
            base_time = distance * 2.5  # ~2.5 min por km
            time_factor = 1.2 if is_rush_hour else 1.0
            weekend_factor = 0.9 if is_weekend else 1.0
            passenger_factor = 1 + (passenger_count - 1) * 0.05

            predicted_duration = (
                base_time * time_factor * weekend_factor * passenger_factor
            )
            confidence = 0.85 if not is_rush_hour else 0.75

            # Mostrar resultados
            col1, col2, col3 = st.columns(3)

            with col1:
                st.metric(
                    label="ğŸ¯ DuraciÃ³n Predicha", value=f"{predicted_duration:.1f} min"
                )

            with col2:
                st.metric(label="ğŸ“ Distancia", value=f"{distance:.2f} km")

            with col3:
                st.metric(label="ğŸ² Confianza", value=f"{confidence:.0%}")

            # Detalles adicionales
            st.markdown("### ğŸ“Š Detalles de la PredicciÃ³n")

            details_data = {
                "Feature": [
                    "Distancia (km)",
                    "Pasajeros",
                    "Vendor",
                    "Hora",
                    "DÃ­a de Semana",
                    "Es Fin de Semana",
                    "Es Hora Pico",
                ],
                "Valor": [
                    f"{distance:.2f}",
                    passenger_count,
                    vendor_id,
                    f"{pickup_hour}:00",
                    day_of_week,
                    "SÃ­" if is_weekend else "No",
                    "SÃ­" if is_rush_hour else "No",
                ],
            }

            details_df = pd.DataFrame(details_data)
            st.dataframe(details_df, use_container_width=True, hide_index=True)

            # Mapa simulado
            st.markdown("### ğŸ—ºï¸ Ruta Simulada")

            map_data = pd.DataFrame(
                {
                    "lat": [pickup_lat, dropoff_lat],
                    "lon": [pickup_lon, dropoff_lon],
                    "tipo": ["Pickup", "Dropoff"],
                }
            )

            st.map(map_data[["lat", "lon"]], zoom=12)

# ğŸ“‹ Footer
st.markdown("---")
st.markdown(
    """
<div style='text-align: center; color: #666;'>
    ğŸš• <strong>Taxi Duration Predictor</strong> |
    MLOps Dashboard con Streamlit + MLflow |
    Arquitectura Hexagonal + DDD |
    Desarrollado para curso MLOps 2025
</div>
""",
    unsafe_allow_html=True,
)
