# üìä MLOps Dashboard with Streamlit + MLflow
# FASE 4A: Dashboard Program√°tico para Monitoreo de Modelos

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import mlflow
from mlflow.tracking import MlflowClient
import asyncio
import asyncpg
from datetime import datetime, timedelta
import requests
import json
import warnings
from pathlib import Path
import os

warnings.filterwarnings("ignore")

# üö® FIX: Configurar paths absolutos desde cualquier directorio
PROJECT_ROOT = Path(__file__).parent.parent.parent.absolute()
MLFLOW_DB_PATH = PROJECT_ROOT / "data" / "mlflow.db"
MLFLOW_TRACKING_URI = f"sqlite:///{MLFLOW_DB_PATH}"

print(f"üîç Dashboard starting from: {Path.cwd()}")
print(f"üìÅ Project root: {PROJECT_ROOT}")
print(f"üóÑÔ∏è MLflow DB path: {MLFLOW_DB_PATH}")
print(f"üîó MLflow URI: {MLFLOW_TRACKING_URI}")

# Verificar que el archivo existe
if not MLFLOW_DB_PATH.exists():
    st.error(f"‚ùå MLflow database not found at: {MLFLOW_DB_PATH}")
    st.stop()

# üîß Configuraci√≥n de p√°gina
st.set_page_config(
    page_title="üöï Taxi Duration Predictor - MLOps Dashboard",
    page_icon="üöï",
    layout="wide",
    initial_sidebar_state="expanded",
)

# üé® CSS personalizado
st.markdown(
    """
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
    }
    .success-metric {
        border-left-color: #28a745;
    }
    .warning-metric {
        border-left-color: #ffc107;
    }
    .error-metric {
        border-left-color: #dc3545;
    }
</style>
""",
    unsafe_allow_html=True,
)


# üöÄ Funciones utilitarias
@st.cache_data
def load_mlflow_experiments():
    """Carga experimentos desde MLflow program√°ticamente"""
    try:
        # Configurar MLflow con path absoluto
        mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)
        client = MlflowClient()

        # Obtener experimento
        experiment = client.get_experiment_by_name("taxi_duration_prediction")
        if not experiment:
            return None, "No se encontr√≥ el experimento taxi_duration_prediction"

        # Obtener todas las runs
        runs = client.search_runs(
            experiment_ids=[experiment.experiment_id], order_by=["start_time DESC"]
        )

        # Convertir a DataFrame
        runs_data = []
        for run in runs:
            run_data = {
                "run_id": run.info.run_id,
                "run_name": run.data.tags.get("mlflow.runName", "Unnamed"),
                "model_type": run.data.params.get("model_type", "Unknown"),
                "rmse": float(run.data.metrics.get("rmse", 0)),
                "mae": float(run.data.metrics.get("mae", 0)),
                "r2_score": float(run.data.metrics.get("r2_score", 0)),
                "training_time": float(
                    run.data.metrics.get("training_time_seconds", 0)
                ),
                "start_time": pd.to_datetime(run.info.start_time, unit="ms"),
                "status": run.info.status,
                "train_size": int(run.data.params.get("train_size", 0)),
                "test_size": int(run.data.params.get("test_size", 0)),
            }
            runs_data.append(run_data)

        df = pd.DataFrame(runs_data)
        return df, None

    except Exception as e:
        return None, f"Error cargando MLflow: {str(e)}"


@st.cache_data
def get_best_model():
    """Obtiene el mejor modelo autom√°ticamente"""
    df, error = load_mlflow_experiments()
    if error:
        return None, error

    if df.empty:
        return None, "No hay experimentos disponibles"

    # Ordenar por RMSE (menor es mejor)
    best_run = df.loc[df["rmse"].idxmin()]
    return best_run, None


async def get_database_stats():
    """Obtiene estad√≠sticas actuales de la base de datos"""
    try:
        conn = await asyncpg.connect(
            host="taxi-duration-db.ckj7uy651uld.us-east-1.rds.amazonaws.com",
            port=5432,
            database="postgres",
            user="taxiuser",
            password="TaxiDB2025!",
        )

        # Estad√≠sticas generales
        stats = await conn.fetchrow(
            """
            SELECT
                COUNT(*) as total_trips,
                AVG(trip_duration_seconds) as avg_duration,
                MIN(pickup_datetime) as earliest_trip,
                MAX(pickup_datetime) as latest_trip,
                COUNT(DISTINCT vendor_id) as unique_vendors
            FROM taxi_trips
        """
        )

        # Distribuci√≥n por hora
        hourly_stats = await conn.fetch(
            """
            SELECT
                EXTRACT(HOUR FROM pickup_datetime) as hour,
                COUNT(*) as trip_count,
                AVG(trip_duration_seconds) as avg_duration
            FROM taxi_trips
            GROUP BY EXTRACT(HOUR FROM pickup_datetime)
            ORDER BY hour
        """
        )

        await conn.close()

        return {
            "general": dict(stats),
            "hourly": [dict(row) for row in hourly_stats],
        }, None

    except Exception as e:
        return None, f"Error conectando a base de datos: {str(e)}"


# ÔøΩ Funciones para monitoreo del FastAPI
# üì° API Configuration - Docker container network
FASTAPI_BASE_URL = os.getenv("API_BASE_URL", "http://localhost:8000")

# üîç Debug: Print API URL being used (for troubleshooting)
print(f"üîó Dashboard using API URL: {FASTAPI_BASE_URL}")


@st.cache_data(ttl=10)  # Reduced cache to 10 seconds for faster debugging
def check_api_health():
    """Verifica el estado del API FastAPI"""
    try:
        print(f"üîç Attempting to connect to API at: {FASTAPI_BASE_URL}")
        # Try the detailed health endpoint first (correct path without trailing slash)
        response = requests.get(f"{FASTAPI_BASE_URL}/api/v1/health", timeout=5)
        print(f"‚úÖ API responded with status: {response.status_code}")
        if response.status_code == 200:
            return response.json(), None
        else:
            # Fallback to basic health endpoint
            response = requests.get(f"{FASTAPI_BASE_URL}/health", timeout=5)
            if response.status_code == 200:
                basic_health = response.json()
                # Convert basic health to expected format
                return {
                    "status": "healthy" if basic_health.get("status") == "ok" else "degraded",
                    "model_status": "ready",  # Assume model is ready if API is working
                    "timestamp": basic_health.get("timestamp", ""),
                    "version": "1.0.0",
                }, None
            else:
                return None, f"API respondi√≥ con c√≥digo {response.status_code}"
    except requests.exceptions.ConnectionError as e:
        error_msg = f"ConnectionError: {str(e)} - Trying to reach: {FASTAPI_BASE_URL}"
        print(f"‚ùå {error_msg}")
        return None, f"API no disponible - {error_msg}"
    except requests.exceptions.Timeout as e:
        error_msg = f"Timeout after 5s connecting to {FASTAPI_BASE_URL}"
        print(f"‚è∞ {error_msg}")
        return None, f"Timeout conectando al API - {error_msg}"
    except Exception as e:
        error_msg = f"Unexpected error: {str(e)} when connecting to {FASTAPI_BASE_URL}"
        print(f"üö® {error_msg}")
        return None, f"Error verificando API: {error_msg}"


@st.cache_data(ttl=60)  # Cache por 1 minuto
def get_api_model_info():
    """Obtiene informaci√≥n del modelo desde el API"""
    try:
        # Use the correct endpoint format with trailing slash
        response = requests.get(f"{FASTAPI_BASE_URL}/api/v1/health/model", timeout=5)
        if response.status_code == 200:
            return response.json(), None

        return None, f"Error obteniendo info del modelo: {response.status_code}"
    except Exception as e:
        return None, f"Error: {str(e)}"


def make_api_prediction(prediction_data):
    """Hace una predicci√≥n usando el API FastAPI"""
    try:
        # Use the correct endpoint format with trailing slash
        response = requests.post(
            f"{FASTAPI_BASE_URL}/api/v1/predict/", json=prediction_data, timeout=10
        )
        if response.status_code == 200:
            return response.json(), None

        # If failed, return error
        error_text = response.text
        try:
            error_json = response.json()
            error_detail = error_json.get("detail", error_text)
        except:
            error_detail = error_text
        return (
            None,
            f"Error en predicci√≥n: {response.status_code} - {error_detail}",
        )
    except Exception as e:
        return None, f"Error haciendo predicci√≥n: {str(e)}"


@st.cache_data(ttl=300)  # Cache por 5 minutos
def get_api_database_stats():
    """Obtiene estad√≠sticas de la base de datos desde el API"""
    try:
        # TODO: Implementar endpoint /api/v1/stats/database en el API
        # Por ahora, retornamos datos dummy para que funcione la interfaz
        return {
            "total_trips": 1250,
            "avg_duration_minutes": 15.7,
            "most_popular_pickup_zone": "Manhattan",
            "prediction_accuracy": 92.3,
            "last_updated": datetime.now().isoformat(),
        }, None
    except Exception as e:
        return None, f"Error: {str(e)}"


# üìä Header principal
st.markdown(
    '<h1 class="main-header">üöï MLOps Dashboard - Taxi Duration Predictor</h1>',
    unsafe_allow_html=True,
)

# Comprehensive UX Welcome Banner
st.markdown(
    """
---
### üëã Bienvenido al Dashboard MLOps de Predicci√≥n de Duraci√≥n de Viajes de Taxi

Este dashboard proporciona una **interfaz completa para monitorear, analizar y usar** nuestro sistema de Machine Learning en producci√≥n.

#### üéØ **Roles y Vistas Recomendadas:**
- **üëî Gerentes/Directores** ‚Üí üìà Overview General (m√©tricas ejecutivas)
- **üß™ Data Scientists** ‚Üí ü§ñ Comparaci√≥n de Modelos (performance t√©cnico)
- **üìä Analistas de Datos** ‚Üí üìä An√°lisis de Datos (patrones de negocio)
- **‚öôÔ∏è DevOps/SysAdmins** ‚Üí üöÄ API Status (monitoreo t√©cnico)
- **üë• Usuarios Finales** ‚Üí üéØ Simulador (predicciones interactivas)

#### üìö **M√©tricas Clave:**
- **RMSE**: Error promedio en minutos - **MENOR = MEJOR** ‚¨áÔ∏è
- **R¬≤ Score**: % de varianza explicada - **MAYOR = MEJOR** ‚¨ÜÔ∏è (0-1)
- **MAE**: Error absoluto promedio - **MENOR = MEJOR** ‚¨áÔ∏è

#### üöÄ **Comenzar:**
1. Selecciona tu vista en la barra lateral ‚¨ÖÔ∏è
2. Usa el bot√≥n "üîÑ Actualizar Datos" para refrescar informaci√≥n
3. Explora los expandibles "‚ÑπÔ∏è" para obtener ayuda contextual

---
"""
)

# Add real-time system status banner
try:
    api_health, _ = check_api_health()
    if api_health:
        st.success("üü¢ **Sistema Operacional** - API funcionando correctamente")
    else:
        st.warning(
            "üü° **API Offline** - Funcionalidad limitada (solo datos hist√≥ricos)"
        )
except:
    st.warning("üü° **Verificando Sistema** - Cargando estado del API...")

st.markdown("---")

# üîÑ Sidebar para controles
st.sidebar.markdown("## üéõÔ∏è Controles del Dashboard")

# Bot√≥n de refresh
if st.sidebar.button("üîÑ Actualizar Datos", type="primary"):
    st.cache_data.clear()
    st.rerun()

# Selector de vista
view_mode = st.sidebar.selectbox(
    "üìä Seleccionar Vista",
    [
        "üìà Overview General",
        "ü§ñ Comparaci√≥n de Modelos",
        "üìä An√°lisis de Datos",
        "üöÄ API Status & Monitoring",
        "üéØ Monitoreo en Tiempo Real",
    ],
)

st.sidebar.markdown("---")
st.sidebar.markdown("### üìã Informaci√≥n del Sistema")
st.sidebar.info(
    f"""
**√öltima actualizaci√≥n:** {datetime.now().strftime('%H:%M:%S')}
**MLflow URI:** {MLFLOW_TRACKING_URI}
**Base de datos:** AWS PostgreSQL
**Estado:** üü¢ Activo
"""
)

# Add user guidance in sidebar
st.sidebar.markdown("---")
st.sidebar.markdown("### üéì Gu√≠a de Usuario")

with st.sidebar.expander("üìö ¬øC√≥mo usar cada vista?", expanded=False):
    st.markdown(
        """
    **üìà Overview General:**
    - Estado ejecutivo del sistema
    - M√©tricas principales del modelo
    - Para: Gerentes y directores

    **ü§ñ Comparaci√≥n de Modelos:**
    - Performance entre algoritmos
    - Gr√°ficos comparativos
    - Para: Data Scientists

    **üìä An√°lisis de Datos:**
    - Patrones en datos de producci√≥n
    - Insights autom√°ticos
    - Para: Analistas de datos

    **üöÄ API Status:**
    - Monitoreo del servidor
    - Tests de endpoints
    - Para: DevOps/Desarrolladores

    **üéØ Simulador:**
    - Predicciones en tiempo real
    - Interface de usuario
    - Para: Usuarios finales
    """
    )

with st.sidebar.expander("‚ö° Atajos de Teclado", expanded=False):
    st.markdown(
        """
    - **Ctrl + R**: Refrescar datos
    - **F5**: Recargar dashboard
    - **Ctrl + Shift + R**: Limpiar cache
    """
    )

st.sidebar.markdown("---")
st.sidebar.markdown("### üÜò Soporte")
st.sidebar.error(
    """
**¬øProblemas?**
1. Verificar que FastAPI est√© corriendo
2. Comprobar conexi√≥n a base de datos
3. Revisar logs del sistema
4. Contactar equipo t√©cnico
"""
)

st.sidebar.markdown("---")
st.sidebar.caption("üöï Taxi Duration Predictor v2.0 | MLOps Dashboard")

# üìä Vista Overview General
if view_mode == "üìà Overview General":
    st.markdown("## üìà Resumen Ejecutivo")

    # UX Explanation for users
    st.info(
        """
    üéØ **C√≥mo usar esta vista:**
    - **Para Gerentes/Directores**: Revisi√≥n r√°pida del estado del sistema ML
    - **Indicadores Verdes**: Sistema funcionando correctamente
    - **RMSE m√°s bajo = Mejor precisi√≥n** del modelo (error promedio en minutos)
    - **R¬≤ m√°s alto = Mejor calidad** del modelo (% de varianza explicada)
    """
    )

    # Cargar datos de MLflow
    experiments_df, mlflow_error = load_mlflow_experiments()

    if mlflow_error:
        st.error(f"‚ùå Error con MLflow: {mlflow_error}")
    else:
        # M√©tricas principales
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.markdown(
                '<div class="metric-card success-metric">', unsafe_allow_html=True
            )
            st.metric(
                label="ü§ñ Experimentos Totales",
                value=len(experiments_df) if experiments_df is not None else 0,
            )
            st.markdown("</div>", unsafe_allow_html=True)

        with col2:
            if experiments_df is not None and not experiments_df.empty:
                best_rmse = experiments_df["rmse"].min()
                st.markdown(
                    '<div class="metric-card success-metric">', unsafe_allow_html=True
                )
                st.metric(label="üèÜ Mejor RMSE", value=f"{best_rmse:.2f} min")
                st.markdown("</div>", unsafe_allow_html=True)

        with col3:
            if experiments_df is not None and not experiments_df.empty:
                best_r2 = experiments_df["r2_score"].max()
                st.markdown(
                    '<div class="metric-card success-metric">', unsafe_allow_html=True
                )
                st.metric(label="üìä Mejor R¬≤", value=f"{best_r2:.3f}")
                st.markdown("</div>", unsafe_allow_html=True)

        with col4:
            if experiments_df is not None and not experiments_df.empty:
                avg_training_time = experiments_df["training_time"].mean()
                st.markdown('<div class="metric-card">', unsafe_allow_html=True)
                st.metric(label="‚è±Ô∏è Tiempo Promedio", value=f"{avg_training_time:.1f}s")
                st.markdown("</div>", unsafe_allow_html=True)

        # Mejor modelo actual
        best_model, best_error = get_best_model()

        if not best_error and best_model is not None:
            st.markdown("## üèÜ Modelo en Producci√≥n (Recomendado)")

            # Explanation for users
            st.success("‚úÖ **Estado**: Modelo entrenado y listo para producci√≥n")

            with st.expander("‚ÑπÔ∏è ¬øC√≥mo interpretar estas m√©tricas?", expanded=False):
                st.markdown(
                    """
                **üìä RMSE (Root Mean Square Error)**:
                - **Qu√© significa**: Error promedio en minutos de nuestras predicciones
                - **Valor actual**: {:.2f} minutos
                - **Interpretaci√≥n**: "Nuestro modelo t√≠picamente se equivoca por ¬±{:.2f} minutos"
                - **Objetivo**: **MENOR es MEJOR** ‚¨áÔ∏è

                **üìà MAE (Mean Absolute Error)**:
                - **Qu√© significa**: Error absoluto promedio en predicciones
                - **Valor actual**: {:.2f} minutos
                - **Interpretaci√≥n**: "La mitad de nuestras predicciones est√°n dentro de {:.2f} minutos"
                - **Objetivo**: **MENOR es MEJOR** ‚¨áÔ∏è

                **üéØ R¬≤ Score (Coeficiente de Determinaci√≥n)**:
                - **Qu√© significa**: Qu√© tanto puede explicar nuestro modelo
                - **Valor actual**: {:.3f} ({:.1f}% de varianza explicada)
                - **Interpretaci√≥n**: "Podemos explicar {:.1f}% de las variaciones en duraci√≥n de viajes"
                - **Objetivo**: **MAYOR es MEJOR** ‚¨ÜÔ∏è (m√°ximo = 1.0)

                **‚è±Ô∏è Tiempo de Entrenamiento**:
                - **Qu√© significa**: Cu√°nto tard√≥ en entrenarse el modelo
                - **Valor actual**: {:.1f} segundos
                - **Interpretaci√≥n**: "Tiempo necesario para reentrenar si se requiere"
                """.format(
                        best_model["rmse"],
                        best_model["rmse"],
                        best_model["mae"],
                        best_model["mae"],
                        best_model["r2_score"],
                        best_model["r2_score"] * 100,
                        best_model["r2_score"] * 100,
                        best_model["training_time"],
                    )
                )

            col1, col2 = st.columns([2, 1])

            with col1:
                st.success(
                    f"""
                **ü§ñ Modelo:** {best_model['model_type']}
                **üìä RMSE:** {best_model['rmse']:.2f} minutos
                **üìà MAE:** {best_model['mae']:.2f} minutos
                **üéØ R¬≤:** {best_model['r2_score']:.3f}
                **‚è±Ô∏è Tiempo de entrenamiento:** {best_model['training_time']:.1f}s
                **üìÖ Entrenado:** {best_model['start_time'].strftime('%Y-%m-%d %H:%M')}
                """
                )

            with col2:
                # Gr√°fico de m√©tricas del mejor modelo
                metrics_data = {
                    "M√©trica": ["RMSE", "MAE", "R¬≤"],
                    "Valor": [
                        best_model["rmse"],
                        best_model["mae"],
                        best_model["r2_score"],
                    ],
                    "Objetivo": ["Minimizar", "Minimizar", "Maximizar"],
                }
                metrics_df = pd.DataFrame(metrics_data)

                fig = px.bar(
                    metrics_df,
                    x="M√©trica",
                    y="Valor",
                    color="Objetivo",
                    title="M√©tricas del Mejor Modelo",
                )
                fig.update_layout(height=300)
                st.plotly_chart(fig, use_container_width=True)

# ü§ñ Vista Comparaci√≥n de Modelos
elif view_mode == "ü§ñ Comparaci√≥n de Modelos":
    st.markdown("## ü§ñ Comparaci√≥n Detallada de Modelos")

    # UX Guidance for model comparison
    st.info(
        """
    üéØ **C√≥mo usar esta vista:**
    - **Para Data Scientists/ML Engineers**: Comparar performance entre diferentes algoritmos
    - **Tabla ordenada por RMSE**: El modelo en la primera fila es el **mejor**
    - **Gr√°ficos**: Visualizaci√≥n de m√©tricas para decisiones informadas
    """
    )

    with st.expander("üìö Gu√≠a de Interpretaci√≥n de Gr√°ficos", expanded=False):
        st.markdown(
            """
        **üìä Gr√°fico RMSE vs MAE (Izquierda)**:
        - **Posici√≥n ideal**: Esquina inferior izquierda (valores bajos en ambas m√©tricas)
        - **Tama√±o del punto**: Proporcional al R¬≤ Score (m√°s grande = mejor)
        - **Interpretaci√≥n**: Modelos cercanos al origen son m√°s precisos

        **üéØ Gr√°fico R¬≤ Score (Derecha)**:
        - **Barras m√°s altas = Mejor modelo**
        - **Escala**: 0.0 (terrible) a 1.0 (perfecto)
        - **Umbral aceptable**: > 0.6 para uso en producci√≥n
        - **Interpretaci√≥n**: % de varianza que el modelo puede explicar
        """
        )

    experiments_df, error = load_mlflow_experiments()

    if error:
        st.error(f"‚ùå Error: {error}")
    elif experiments_df is None or experiments_df.empty:
        st.warning(
            "‚ö†Ô∏è No hay experimentos disponibles. Ejecuta primero el notebook de entrenamiento."
        )
    else:
        # Tabla de comparaci√≥n
        st.markdown("### üìä Tabla de Resultados")

        # Formatear tabla para mostrar
        display_df = experiments_df[
            ["model_type", "rmse", "mae", "r2_score", "training_time", "start_time"]
        ].copy()
        display_df["start_time"] = display_df["start_time"].dt.strftime(
            "%Y-%m-%d %H:%M"
        )
        display_df = display_df.sort_values("rmse")

        # Colorear la tabla
        st.dataframe(
            display_df,
            column_config={
                "model_type": "ü§ñ Modelo",
                "rmse": st.column_config.NumberColumn("üìä RMSE", format="%.2f"),
                "mae": st.column_config.NumberColumn("üìà MAE", format="%.2f"),
                "r2_score": st.column_config.NumberColumn("üéØ R¬≤", format="%.3f"),
                "training_time": st.column_config.NumberColumn(
                    "‚è±Ô∏è Tiempo (s)", format="%.1f"
                ),
                "start_time": "üìÖ Fecha",
            },
            use_container_width=True,
        )

        # Gr√°ficos de comparaci√≥n
        st.markdown("### üìä Visualizaci√≥n Comparativa")

        # Add chart interpretation guidance
        col_info1, col_info2 = st.columns(2)
        with col_info1:
            st.caption(
                "‚¨ÖÔ∏è **RMSE vs MAE**: Puntos en esquina inferior izquierda = mejores modelos"
            )
        with col_info2:
            st.caption("‚û°Ô∏è **R¬≤ Score**: Barras m√°s altas = mejor capacidad explicativa")

        col1, col2 = st.columns(2)

        with col1:
            # Gr√°fico RMSE vs MAE
            fig1 = px.scatter(
                experiments_df,
                x="rmse",
                y="mae",
                color="model_type",
                size="r2_score",
                title="üìä RMSE vs MAE por Modelo (Menor = Mejor)",
                hover_data=["training_time"],
                labels={
                    "rmse": "RMSE (minutos) - Menor es Mejor ‚¨áÔ∏è",
                    "mae": "MAE (minutos) - Menor es Mejor ‚¨áÔ∏è",
                },
            )
            fig1.update_layout(height=400)
            st.plotly_chart(fig1, use_container_width=True)

        with col2:
            # Gr√°fico de barras R¬≤
            fig2 = px.bar(
                experiments_df,
                x="model_type",
                y="r2_score",
                color="model_type",
                title="üéØ R¬≤ Score por Modelo (Mayor = Mejor)",
                labels={
                    "r2_score": "R¬≤ Score - Mayor es Mejor ‚¨ÜÔ∏è",
                    "model_type": "Tipo de Modelo",
                },
            )
            # Add horizontal line at 0.6 threshold
            fig2.add_hline(
                y=0.6,
                line_dash="dash",
                line_color="red",
                annotation_text="Umbral m√≠nimo para producci√≥n (0.6)",
            )
            fig2.update_layout(height=400)
            st.plotly_chart(fig2, use_container_width=True)

        # An√°lisis de performance
        st.markdown("### üèÅ An√°lisis de Performance")

        # Business impact explanation
        st.info(
            """
        üí° **Impacto en el Negocio:**
        - **Mejor precisi√≥n** = Estimaciones m√°s confiables para clientes
        - **Menor error** = Mejor planificaci√≥n de rutas y tiempos
        - **Mayor R¬≤** = El modelo entiende mejor los patrones de tr√°fico
        """
        )

        best_model = experiments_df.loc[experiments_df["rmse"].idxmin()]
        worst_model = experiments_df.loc[experiments_df["rmse"].idxmax()]

        col1, col2, col3 = st.columns(3)

        with col1:
            st.success(
                f"""
            **üèÜ MEJOR MODELO**
            **Tipo:** {best_model['model_type']}
            **RMSE:** {best_model['rmse']:.2f} min
            **R¬≤:** {best_model['r2_score']:.3f}

            ‚úÖ **Recomendado para producci√≥n**
            """
            )

        with col2:
            st.error(
                f"""
            **‚ùå MODELO CON MAYOR ERROR**
            **Tipo:** {worst_model['model_type']}
            **RMSE:** {worst_model['rmse']:.2f} min
            **R¬≤:** {worst_model['r2_score']:.3f}

            ‚ö†Ô∏è **No usar en producci√≥n**
            """
            )

        with col3:
            improvement = (
                (worst_model["rmse"] - best_model["rmse"]) / worst_model["rmse"]
            ) * 100
            st.info(
                f"""
            **üìà MEJORA OBTENIDA**
            **Reducci√≥n RMSE:** {improvement:.1f}%
            **Diferencia:** {worst_model['rmse'] - best_model['rmse']:.2f} min
            **Impacto:** Predicciones {improvement:.1f}% m√°s precisas

            üéØ **Valor**: Estimaciones m√°s confiables
            """
            )

# üìä Vista An√°lisis de Datos
elif view_mode == "üìä An√°lisis de Datos":
    st.markdown("## üìä An√°lisis de Datos de Producci√≥n")

    # UX Guidance for data analysis
    st.info(
        """
    üéØ **C√≥mo usar esta vista:**
    - **Para Analistas de Datos**: Entender patrones en los datos de producci√≥n
    - **Para Operaciones**: Identificar horas pico y optimizar recursos
    - **Insights autom√°ticos**: El sistema detecta patrones importantes autom√°ticamente
    """
    )

    with st.expander("üìà C√≥mo interpretar los gr√°ficos de datos", expanded=False):
        st.markdown(
            """
        **üöï Distribuci√≥n de Viajes por Hora:**
        - **Picos altos** = Horas de mayor demanda (m√°s taxis necesarios)
        - **Valles bajos** = Horas de menor demanda (reducir flota)
        - **Patr√≥n t√≠pico**: Picos en horas laborales (7-9 AM, 5-7 PM)

        **‚è±Ô∏è Duraci√≥n Promedio por Hora:**
        - **L√≠neas altas** = Tr√°fico m√°s lento (mayor tiempo de viaje)
        - **L√≠neas bajas** = Tr√°fico fluido (menor tiempo de viaje)
        - **Correlaci√≥n**: Alta demanda ‚â† necesariamente mayor duraci√≥n
        """
        )

    # Cargar estad√≠sticas de la base de datos
    with st.spinner("Cargando datos de la base de datos..."):
        db_stats, db_error = asyncio.run(get_database_stats())

    if db_error:
        st.error(f"‚ùå Error conectando a la base de datos: {db_error}")
    else:
        # Estad√≠sticas generales
        st.markdown("### üìã Estad√≠sticas Generales")

        general_stats = db_stats["general"]

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric(
                label="üöï Total de Viajes", value=f"{general_stats['total_trips']:,}"
            )

        with col2:
            avg_duration_min = general_stats["avg_duration"] / 60
            st.metric(label="‚è±Ô∏è Duraci√≥n Promedio", value=f"{avg_duration_min:.1f} min")

        with col3:
            st.metric(label="üè¢ Vendors √önicos", value=general_stats["unique_vendors"])

        with col4:
            date_range = (
                general_stats["latest_trip"] - general_stats["earliest_trip"]
            ).days
            st.metric(label="üìÖ Rango de Datos", value=f"{date_range} d√≠as")

        # Distribuci√≥n por hora
        st.markdown("### üìà Distribuci√≥n de Viajes por Hora")

        hourly_data = pd.DataFrame(db_stats["hourly"])
        hourly_data["avg_duration_min"] = hourly_data["avg_duration"] / 60

        col1, col2 = st.columns(2)

        with col1:
            fig1 = px.bar(
                hourly_data,
                x="hour",
                y="trip_count",
                title="üöï N√∫mero de Viajes por Hora del D√≠a",
            )
            fig1.update_xaxes(title="Hora del D√≠a")
            fig1.update_yaxes(title="N√∫mero de Viajes")
            st.plotly_chart(fig1, use_container_width=True)

        with col2:
            fig2 = px.line(
                hourly_data,
                x="hour",
                y="avg_duration_min",
                title="‚è±Ô∏è Duraci√≥n Promedio por Hora del D√≠a",
                markers=True,
            )
            fig2.update_xaxes(title="Hora del D√≠a")
            fig2.update_yaxes(title="Duraci√≥n Promedio (minutos)")
            st.plotly_chart(fig2, use_container_width=True)

        # Insights autom√°ticos
        st.markdown("### üß† Insights Autom√°ticos")

        busiest_hour = hourly_data.loc[hourly_data["trip_count"].idxmax()]
        longest_duration_hour = hourly_data.loc[
            hourly_data["avg_duration_min"].idxmax()
        ]

        col1, col2 = st.columns(2)

        with col1:
            st.info(
                f"""
            **üö¶ Hora M√°s Ocupada**
            **Hora:** {int(busiest_hour['hour'])}:00
            **Viajes:** {int(busiest_hour['trip_count']):,}
            **Duraci√≥n promedio:** {busiest_hour['avg_duration_min']:.1f} min
            """
            )

        with col2:
            st.warning(
                f"""
            **üêå Hora con Mayor Duraci√≥n**
            **Hora:** {int(longest_duration_hour['hour'])}:00
            **Duraci√≥n promedio:** {longest_duration_hour['avg_duration_min']:.1f} min
            **Viajes:** {int(longest_duration_hour['trip_count']):,}
            """
            )

# üöÄ Vista API Status & Monitoring
elif view_mode == "üöÄ API Status & Monitoring":
    st.markdown("## üöÄ API Status & Monitoring")
    st.markdown("*Monitor del FastAPI Server y m√©tricas de rendimiento*")

    # UX Guidance for API monitoring
    st.info(
        """
    üéØ **C√≥mo usar esta vista:**
    - **Para DevOps/SysAdmins**: Monitorear salud del sistema en producci√≥n
    - **Para Desarrolladores**: Probar endpoints y validar respuestas
    - **Indicadores clave**: API Status, Model Loaded, Database Status
    """
    )

    with st.expander("üö® Gu√≠a de Resoluci√≥n de Problemas", expanded=False):
        st.markdown(
            """
        **‚ùå API No Disponible:**
        1. Verificar que FastAPI est√© ejecut√°ndose en puerto 8000
        2. Comando: `source activate ds_env && python 05_fastapi_server.py`
        3. Revisar logs del servidor

        **‚ö†Ô∏è Model Not Loaded:**
        1. Verificar que MLflow tenga modelos registrados
        2. Ejecutar entrenamiento si es necesario
        3. Revisar conexi√≥n con base de datos MLflow

        **üî¥ Database Error:**
        1. Verificar conexi√≥n AWS RDS
        2. Validar credenciales de base de datos
        3. Comprobar conectividad de red
        """
        )

    # Health Check del API
    st.markdown("### üè• Estado del API")

    api_health, health_error = check_api_health()

    if health_error:
        st.error(f"‚ùå API No Disponible: {health_error}")
        st.info(
            "üí° **Para activar el API:** `source activate ds_env && python 05_fastapi_server.py`"
        )
    else:
        # Mostrar estado del API
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            api_status = api_health.get("status", "unknown")
            if api_status == "healthy":
                st.metric(label="üü¢ API Status", value="HEALTHY")
            elif api_status == "degraded":
                st.metric(label="üü° API Status", value="DEGRADED")
            else:
                st.metric(label="üü¢ API Status", value=api_status.upper())

        with col2:
            # Check model info independently of health status
            model_info, model_error = get_api_model_info()
            if not model_error and model_info:
                st.metric(label="ü§ñ Model Loaded", value="‚úÖ YES")
                actual_model_loaded = True
            else:
                model_status = api_health.get("model_status", None)
                if model_status == "error":
                    st.metric(label="ü§ñ Model Loaded", value="‚ùå NO")
                else:
                    st.metric(label="ü§ñ Model Loaded", value="‚ùì N/A")
                actual_model_loaded = False

        with col3:
            # For now, we don't have database status from API, so show connected if API is working
            if api_health.get("status") in ["healthy", "degraded"]:
                st.metric(label="üóÑÔ∏è Database", value="üü¢ CONNECTED")
            else:
                st.metric(label="üóÑÔ∏è Database", value="‚ùì N/A")

        with col4:
            timestamp = api_health.get("timestamp", "")
            try:
                formatted_time = datetime.fromisoformat(
                    timestamp.replace("Z", "+00:00")
                ).strftime("%H:%M:%S")
            except:
                formatted_time = timestamp[:8] if len(timestamp) >= 8 else "N/A"
            st.metric(label="üïí Last Check", value=formatted_time)

        # Show API status explanation
        api_status = api_health.get("status", "unknown")
        model_status_from_health = api_health.get("model_status", "unknown")

        if api_status == "degraded":
            st.warning("‚ö†Ô∏è **API en modo degradado** - El API est√° funcionando pero con limitaciones (ej: predicciones pueden fallar)")

        # Show inconsistency warning if health says error but model info works
        if model_status_from_health == "error" and actual_model_loaded:
            st.info("‚ÑπÔ∏è **Inconsistencia detectada**: El health check reporta error en el modelo, pero la informaci√≥n del modelo est√° disponible. Esto puede indicar un problema espec√≠fico con las predicciones.")

        # Informaci√≥n del modelo en el API - use actual model info check
        if actual_model_loaded:
            st.markdown("### ü§ñ Modelo en Producci√≥n (API)")

            model_info, model_error = get_api_model_info()

            if not model_error and model_info:
                col1, col2 = st.columns([2, 1])

                with col1:
                    # The API returns fields directly, not nested under model_metadata
                    st.success(
                        f"""
                    **ü§ñ Modelo:** {model_info.get('model_type', 'Unknown')}
                    **üìä RMSE:** {model_info.get('rmse', 0):.2f} minutos
                    **üìà MAE:** {model_info.get('mae', 0):.2f} minutos
                    **üéØ R¬≤:** {model_info.get('r2_score', 0):.3f}
                    **ÔøΩ Creado:** {model_info.get('created_at', 'Unknown')[:16]}
                    """
                    )

                with col2:
                    # Features requeridas - parse from string format
                    st.markdown("**üìã Features Requeridas:**")
                    features_str = model_info.get("features", "[]")
                    try:
                        # Try to extract features from string representation
                        import ast
                        if features_str.startswith('[') and features_str.endswith(']'):
                            features_list = ast.literal_eval(features_str)
                        else:
                            # Fallback: split by comma if it's a simple string
                            features_list = [f.strip().strip("'\"") for f in features_str.split(',') if f.strip()]

                        if features_list:
                            features_df = pd.DataFrame(
                                {
                                    "Feature": features_list,
                                    "Tipo": ["Num√©rico"] * len(features_list),
                                }
                            )
                            st.dataframe(features_df, hide_index=True, use_container_width=True)
                        else:
                            st.info("No se pudieron cargar las features del modelo")
                    except Exception as e:
                        st.warning(f"Error procesando features: {e}")
                        st.code(f"Features raw: {features_str}")
        else:
            # Model not loaded - show diagnostic info
            st.markdown("### ‚ö†Ô∏è Diagn√≥stico del Modelo")

            model_status_from_health = api_health.get("model_status", "unknown")
            if model_status_from_health == "error":
                st.error("‚ùå **Health Check reporta**: Modelo con errores")

            # Try to get model info anyway to see if it's really unavailable
            model_info, model_error = get_api_model_info()
            if model_error:
                st.error(f"‚ùå **Model Info**: {model_error}")
                st.info("""
                üí° **Pasos para resolver**:
                1. Verificar que MLflow tiene modelos registrados
                2. Revisar logs del servidor FastAPI
                3. Ejecutar re-entrenamiento si es necesario
                """)
            else:
                st.warning("‚ö†Ô∏è **Inconsistencia**: Model info disponible pero health check reporta error")

        # Test de predicci√≥n usando el API
        st.markdown("### üß™ Test de Predicci√≥n API")

        with st.expander("üöÄ Probar Predicci√≥n via API", expanded=False):
            with st.form("api_prediction_form"):
                col1, col2 = st.columns(2)

                with col1:
                    pickup_lat = st.number_input(
                        "üìç Pickup Latitude", value=40.7589, format="%.6f"
                    )
                    pickup_lon = st.number_input(
                        "üìç Pickup Longitude", value=-73.9851, format="%.6f"
                    )
                    dropoff_lat = st.number_input(
                        "üìç Dropoff Latitude", value=40.7505, format="%.6f"
                    )
                    dropoff_lon = st.number_input(
                        "üìç Dropoff Longitude", value=-73.9934, format="%.6f"
                    )

                with col2:
                    passenger_count = st.selectbox(
                        "üë• Passengers", [1, 2, 3, 4, 5, 6], index=1
                    )
                    vendor_id = st.selectbox("üè¢ Vendor ID", [1, 2])
                    pickup_hour = st.slider("üïê Pickup Hour", 0, 23, 14)
                    day_of_week = st.slider("üìÖ Day of Week", 0, 6, 2)
                    month = st.slider("üìÜ Month", 1, 12, 7)

                submitted = st.form_submit_button("üöÄ Predecir via API", type="primary")

                if submitted:
                    # Create a datetime object for pickup_datetime using the provided components
                    from datetime import datetime
                    pickup_datetime = datetime(
                        year=2025,  # Default year
                        month=month,
                        day=15,  # Default day
                        hour=pickup_hour,
                        minute=0,
                        second=0
                    )

                    prediction_data = {
                        "pickup_latitude": pickup_lat,
                        "pickup_longitude": pickup_lon,
                        "dropoff_latitude": dropoff_lat,
                        "dropoff_longitude": dropoff_lon,
                        "passenger_count": passenger_count,
                        "vendor_id": vendor_id,
                        "pickup_datetime": pickup_datetime.isoformat(),
                    }

                    prediction_result, pred_error = make_api_prediction(prediction_data)

                    if pred_error:
                        st.error(f"‚ùå Error en predicci√≥n: {pred_error}")
                        if "500" in str(pred_error):
                            st.info("""
                            üí° **Posibles causas del error 500:**
                            - El modelo tiene problemas internos de predicci√≥n
                            - Los datos enviados no est√°n en el formato esperado
                            - Error en el pipeline de features del modelo
                            - Verificar logs del servidor FastAPI para m√°s detalles
                            """)
                        elif "404" in str(pred_error):
                            st.info("üí° **Error 404**: El endpoint de predicci√≥n no existe o cambi√≥ de ruta")
                        elif "timeout" in str(pred_error).lower():
                            st.info("üí° **Timeout**: El servidor est√° tardando mucho en responder")
                    else:
                        # Mostrar resultado
                        col1, col2, col3 = st.columns(3)

                        with col1:
                            st.metric(
                                "üéØ Duraci√≥n Predicha",
                                f"{prediction_result['predicted_duration_minutes']:.1f} min",
                            )

                        with col2:
                            st.metric(
                                "üìè Distancia",
                                f"{prediction_result['distance_km']:.2f} km",
                            )

                        with col3:
                            st.metric(
                                "üé≤ Confianza",
                                f"{prediction_result['confidence_score']:.1%}",
                            )

                        # Detalles de la predicci√≥n
                        st.markdown("**üìä Detalles de la Predicci√≥n:**")
                        details_data = []
                        for feature, value in prediction_result[
                            "features_used"
                        ].items():
                            details_data.append({"Feature": feature, "Valor": value})

                        details_df = pd.DataFrame(details_data)
                        st.dataframe(
                            details_df, hide_index=True, use_container_width=True
                        )

                        # JSON Response
                        with st.expander("üìÑ Respuesta JSON completa"):
                            st.json(prediction_result)

        # Estad√≠sticas via API
        st.markdown("### üìä Estad√≠sticas de la Base de Datos (via API)")

        api_stats, stats_error = get_api_database_stats()

        if stats_error:
            st.warning(f"‚ö†Ô∏è No se pudieron obtener estad√≠sticas: {stats_error}")
        else:
            col1, col2, col3 = st.columns(3)

            with col1:
                st.metric("üöï Total Viajes", f"{api_stats['total_trips']:,}")

            with col2:
                st.metric(
                    "‚è±Ô∏è Duraci√≥n Promedio",
                    f"{api_stats['avg_duration_minutes']:.1f} min",
                )

            with col3:
                st.metric("üìÖ √öltima Actualizaci√≥n", api_stats["last_updated"][:16])

        # URLs √∫tiles
        st.markdown("### üîó Enlaces √ötiles")

        col1, col2, col3 = st.columns(3)

        with col1:
            st.markdown("**üìñ [Swagger Docs](http://localhost:8000/docs)**")
            st.markdown("‚ö†Ô∏è *Links work from host machine, not inside container*")
            st.caption("Documentaci√≥n interactiva del API")

        with col2:
            st.markdown("**üìö [ReDoc](http://localhost:8000/redoc)**")
            st.caption("Documentaci√≥n alternativa")

        with col3:
            st.markdown("**üè• [Health Check](http://localhost:8000/health)**")
            st.caption("Status del API en JSON")

# üéØ Vista Monitoreo en Tiempo Real
elif view_mode == "üéØ Monitoreo en Tiempo Real":
    st.markdown("## üéØ Simulador de Predicciones en Tiempo Real")

    # UX Guidance for prediction simulator
    st.info(
        """
    üéØ **C√≥mo usar esta vista:**
    - **Para Usuarios de Negocio**: Estimar duraci√≥n de viajes en tiempo real
    - **Para Operadores de Taxi**: Planificar rutas y dar estimaciones a clientes
    - **Para Testing**: Validar comportamiento del modelo con diferentes escenarios
    """
    )

    with st.expander("üó∫Ô∏è Ubicaciones Populares de NYC (Para Testing)", expanded=False):
        st.markdown(
            """
        **üìç Coordenadas √ötiles:**
        - **Times Square**: 40.7580, -73.9855
        - **Central Park**: 40.7829, -73.9654
        - **JFK Airport**: 40.6413, -73.7781
        - **LaGuardia Airport**: 40.7769, -73.8740
        - **Brooklyn Bridge**: 40.7061, -73.9969
        - **Wall Street**: 40.7074, -74.0113

        **üí° Escenarios de Prueba:**
        - **Viaje Corto**: Times Square ‚Üí Central Park (~3 km)
        - **Viaje Medio**: Manhattan ‚Üí Brooklyn (~9 km)
        - **Viaje Largo**: JFK ‚Üí Manhattan (~22 km)
        """
        )

    # Obtener mejor modelo
    best_model, error = get_best_model()

    if error:
        st.error(f"‚ùå Error: {error}")
    else:
        st.success(
            f"ü§ñ Usando modelo: **{best_model['model_type']}** (RMSE: {best_model['rmse']:.2f} min)"
        )

        st.markdown("### üéÆ Simulador de Predicci√≥n")

        # Quick location presets
        st.markdown("#### üó∫Ô∏è Ubicaciones R√°pidas")

        locations = {
            "Times Square": (40.7580, -73.9855),
            "Central Park": (40.7829, -73.9654),
            "JFK Airport": (40.6413, -73.7781),
            "LaGuardia Airport": (40.7769, -73.8740),
            "Brooklyn Bridge": (40.7061, -73.9969),
            "Wall Street": (40.7074, -74.0113),
            "Custom": (40.7589, -73.9851),  # Default custom location
        }

        col_preset1, col_preset2 = st.columns(2)

        with col_preset1:
            pickup_preset = st.selectbox(
                "üìç Origen",
                options=list(locations.keys()),
                index=0,
                help="Selecciona una ubicaci√≥n popular o 'Custom' para coordenadas manuales",
            )

        with col_preset2:
            dropoff_preset = st.selectbox(
                "üéØ Destino",
                options=list(locations.keys()),
                index=2,  # JFK by default
                help="Selecciona una ubicaci√≥n popular o 'Custom' para coordenadas manuales",
            )

        # Formulario de entrada
        with st.form("prediction_form"):
            col1, col2 = st.columns(2)

            with col1:
                st.markdown("**üìç Coordenadas de Origen**")
                pickup_coords = locations[pickup_preset]
                pickup_lat = st.number_input(
                    "Latitud Pickup",
                    value=pickup_coords[0],
                    format="%.6f",
                    help="Latitud del punto de recogida (40.5 - 40.9 para NYC)",
                )
                pickup_lon = st.number_input(
                    "Longitud Pickup",
                    value=pickup_coords[1],
                    format="%.6f",
                    help="Longitud del punto de recogida (-74.3 - -73.7 para NYC)",
                )

                st.markdown("**üéØ Coordenadas de Destino**")
                dropoff_coords = locations[dropoff_preset]
                dropoff_lat = st.number_input(
                    "Latitud Dropoff",
                    value=dropoff_coords[0],
                    format="%.6f",
                    help="Latitud del punto de destino",
                )
                dropoff_lon = st.number_input(
                    "Longitud Dropoff",
                    value=dropoff_coords[1],
                    format="%.6f",
                    help="Longitud del punto de destino",
                )

            with col2:
                st.markdown("**üöñ Par√°metros del Viaje**")
                passenger_count = st.selectbox(
                    "üë• N√∫mero de Pasajeros",
                    [1, 2, 3, 4, 5, 6],
                    help="N√∫mero de pasajeros afecta el tiempo de viaje",
                )
                vendor_id = st.selectbox(
                    "üè¢ Vendor ID",
                    [1, 2],
                    help="1=Creative Mobile Technologies, 2=VeriFone Inc.",
                )

                st.markdown("**‚è∞ Informaci√≥n Temporal**")
                pickup_hour = st.slider(
                    "üïê Hora de Pickup",
                    0,
                    23,
                    12,
                    help="Hora del d√≠a afecta significativamente el tr√°fico",
                )
                day_of_week = st.selectbox(
                    "üìÖ D√≠a de la Semana",
                    [
                        "Lunes",
                        "Martes",
                        "Mi√©rcoles",
                        "Jueves",
                        "Viernes",
                        "S√°bado",
                        "Domingo",
                    ],
                )

            submitted = st.form_submit_button("üöÄ Predecir Duraci√≥n", type="primary")

        if submitted:
            # Simular predicci√≥n (en un caso real, cargar√≠as el modelo desde MLflow)

            # Calcular distancia
            def haversine_distance(lat1, lon1, lat2, lon2):
                R = 6371
                lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])
                dlat = lat2 - lat1
                dlon = lon2 - lon1
                a = (
                    np.sin(dlat / 2) ** 2
                    + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2
                )
                return 2 * R * np.arcsin(np.sqrt(a))

            distance = haversine_distance(
                pickup_lat, pickup_lon, dropoff_lat, dropoff_lon
            )

            # Features simuladas
            day_mapping = {
                "Lunes": 0,
                "Martes": 1,
                "Mi√©rcoles": 2,
                "Jueves": 3,
                "Viernes": 4,
                "S√°bado": 5,
                "Domingo": 6,
            }
            day_num = day_mapping[day_of_week]
            is_weekend = 1 if day_num >= 5 else 0
            is_rush_hour = 1 if pickup_hour in [7, 8, 9, 17, 18, 19] else 0

            # Predicci√≥n simulada (basada en el patr√≥n del mejor modelo)
            base_time = distance * 2.5  # ~2.5 min por km
            time_factor = 1.2 if is_rush_hour else 1.0
            weekend_factor = 0.9 if is_weekend else 1.0
            passenger_factor = 1 + (passenger_count - 1) * 0.05

            predicted_duration = (
                base_time * time_factor * weekend_factor * passenger_factor
            )
            confidence = 0.85 if not is_rush_hour else 0.75

            # Mostrar resultados
            st.markdown("### üéØ Resultado de la Predicci√≥n")

            # Add interpretation guidance
            st.success("‚úÖ **Predicci√≥n completada exitosamente**")

            col1, col2, col3 = st.columns(3)

            with col1:
                st.metric(
                    label="üéØ Duraci√≥n Predicha", value=f"{predicted_duration:.1f} min"
                )
                st.caption("Tiempo estimado del viaje")

            with col2:
                st.metric(label="üìè Distancia", value=f"{distance:.2f} km")
                st.caption("Distancia euclidiana calculada")

            with col3:
                st.metric(label="üé≤ Confianza", value=f"{confidence:.0%}")
                st.caption("Nivel de confianza del modelo")

            # Interpretation helper
            if predicted_duration < 15:
                duration_interpretation = "üü¢ **Viaje Corto** - Tr√°fico fluido esperado"
            elif predicted_duration < 30:
                duration_interpretation = (
                    "üü° **Viaje Medio** - Tiempo moderado de viaje"
                )
            else:
                duration_interpretation = (
                    "üî¥ **Viaje Largo** - Considerar rutas alternativas"
                )

            st.info(f"üí° **Interpretaci√≥n**: {duration_interpretation}")

            # Business insights
            rush_hour_text = (
                "üö¶ **Hora Pico**" if is_rush_hour else "‚úÖ **Hora Normal**"
            )
            weekend_text = "üèñÔ∏è **Fin de Semana**" if is_weekend else "üíº **D√≠a Laboral**"

            col_insight1, col_insight2 = st.columns(2)
            with col_insight1:
                st.info(f"‚è∞ {rush_hour_text} - Factor de tr√°fico aplicado")
            with col_insight2:
                st.info(f"üìÖ {weekend_text} - Patr√≥n de demanda considerado")

            # Detalles adicionales
            st.markdown("### üìä Detalles de la Predicci√≥n")

            with st.expander(
                "üîç Ver factores que influyen en la predicci√≥n", expanded=False
            ):
                st.markdown(
                    f"""
                **üìê C√°lculo de la Predicci√≥n:**
                - **Tiempo base**: {base_time:.1f} min (basado en distancia)
                - **Factor de tr√°fico**: x{time_factor} {"(hora pico)" if is_rush_hour else "(hora normal)"}
                - **Factor d√≠a**: x{weekend_factor} {"(fin de semana)" if is_weekend else "(d√≠a laboral)"}
                - **Factor pasajeros**: x{passenger_factor:.2f} ({passenger_count} pasajeros)

                **üßÆ F√≥rmula Final:**
                `{base_time:.1f} √ó {time_factor} √ó {weekend_factor} √ó {passenger_factor:.2f} = {predicted_duration:.1f} minutos`
                """
                )

            details_data = {
                "Feature": [
                    "Distancia (km)",
                    "Pasajeros",
                    "Vendor",
                    "Hora",
                    "D√≠a de Semana",
                    "Es Fin de Semana",
                    "Es Hora Pico",
                ],
                "Valor": [
                    f"{distance:.2f}",
                    str(passenger_count),  # Convert to string for consistency
                    str(vendor_id),  # Convert to string for consistency
                    f"{pickup_hour}:00",
                    day_of_week,
                    "S√≠" if is_weekend else "No",
                    "S√≠" if is_rush_hour else "No",
                ],
            }

            details_df = pd.DataFrame(details_data)
            st.dataframe(details_df, use_container_width=True, hide_index=True)

            # Mapa con ruta
            st.markdown("### üó∫Ô∏è Ruta del Taxi")

            # Check if coordinates are valid (not zero or empty)
            if (
                pickup_lat
                and pickup_lon
                and dropoff_lat
                and dropoff_lon
                and pickup_lat != 0.0
                and pickup_lon != 0.0
                and dropoff_lat != 0.0
                and dropoff_lon != 0.0
            ):

                # Debug info for coordinates
                st.caption(
                    f"üìç Pickup: ({pickup_lat:.6f}, {pickup_lon:.6f}) | Dropoff: ({dropoff_lat:.6f}, {dropoff_lon:.6f})"
                )

                try:
                    # Calculate center point for map
                    center_lat = (pickup_lat + dropoff_lat) / 2
                    center_lon = (pickup_lon + dropoff_lon) / 2

                    # Calculate distance to determine zoom level
                    lat_diff = abs(pickup_lat - dropoff_lat)
                    lon_diff = abs(pickup_lon - dropoff_lon)
                    max_diff = max(lat_diff, lon_diff)

                    # Auto-calculate zoom level based on distance
                    if max_diff > 0.1:
                        zoom_level = 10
                    elif max_diff > 0.05:
                        zoom_level = 11
                    elif max_diff > 0.02:
                        zoom_level = 12
                    elif max_diff > 0.01:
                        zoom_level = 13
                    else:
                        zoom_level = 14

                    # Create enhanced map with Plotly
                    import plotly.express as px
                    import plotly.graph_objects as go

                    # Create route points
                    map_data = pd.DataFrame(
                        {
                            "lat": [pickup_lat, dropoff_lat],
                            "lon": [pickup_lon, dropoff_lon],
                            "tipo": ["üöï Pickup", "üèÅ Dropoff"],
                            "color": ["green", "red"],
                            "size": [15, 15],
                        }
                    )

                    # Create the map
                    fig = px.scatter_mapbox(
                        map_data,
                        lat="lat",
                        lon="lon",
                        color="tipo",
                        size="size",
                        hover_name="tipo",
                        hover_data={"lat": ":.6f", "lon": ":.6f"},
                        color_discrete_map={"ÔøΩ Pickup": "green", "üèÅ Dropoff": "red"},
                        zoom=zoom_level,
                        center={"lat": center_lat, "lon": center_lon},
                        height=500,
                        title=f"Ruta del Taxi - Distancia: {distance:.2f} km",
                    )

                    # Add route line
                    fig.add_trace(
                        go.Scattermapbox(
                            mode="lines",
                            lon=[pickup_lon, dropoff_lon],
                            lat=[pickup_lat, dropoff_lat],
                            line=dict(width=3, color="blue"),
                            name="Ruta",
                            hovertemplate="Ruta del taxi<extra></extra>",
                        )
                    )

                    # Update map style
                    fig.update_layout(
                        mapbox_style="open-street-map",
                        margin={"r": 0, "t": 40, "l": 0, "b": 0},
                        showlegend=True,
                        legend=dict(
                            yanchor="top",
                            y=0.99,
                            xanchor="left",
                            x=0.01,
                            bgcolor="rgba(255,255,255,0.8)",
                        ),
                    )

                    st.plotly_chart(fig, use_container_width=True)

                    # Enhanced Trip Analysis
                    st.markdown("### üìä An√°lisis Inteligente del Viaje")

                    # Analyze trip characteristics
                    def analyze_trip_context(
                        pickup_lat,
                        pickup_lon,
                        dropoff_lat,
                        dropoff_lon,
                        distance,
                        duration,
                    ):
                        """Analyze trip context and provide insights"""
                        insights = []

                        # Distance analysis
                        if distance < 2:
                            insights.append(
                                "üö∂ **Viaje Corto**: Distancia menor a 2km - ideal para taxis en zonas densas"
                            )
                        elif distance < 10:
                            insights.append(
                                "üöï **Viaje Medio**: Distancia t√≠pica de taxi en NYC"
                            )
                        else:
                            insights.append(
                                "‚úàÔ∏è **Viaje Largo**: Distancia considerable - posible viaje al aeropuerto"
                            )

                        # Speed analysis
                        speed = distance / (duration / 60)
                        if speed < 15:
                            insights.append(
                                "üêå **Velocidad Baja**: Probable tr√°fico intenso o zona congestionada"
                            )
                        elif speed < 25:
                            insights.append(
                                "üöó **Velocidad Normal**: Tr√°fico t√≠pico de NYC"
                            )
                        else:
                            insights.append(
                                "üèÉ **Velocidad Alta**: Condiciones de tr√°fico favorables"
                            )

                        # Geographic analysis
                        if abs(pickup_lat - dropoff_lat) > abs(
                            pickup_lon - dropoff_lon
                        ):
                            insights.append(
                                "üìç **Direcci√≥n**: Viaje principalmente Norte-Sur"
                            )
                        else:
                            insights.append(
                                "üìç **Direcci√≥n**: Viaje principalmente Este-Oeste"
                            )

                        # Efficiency analysis
                        linear_distance = distance
                        time_efficiency = linear_distance / duration  # km/min
                        if time_efficiency > 0.4:
                            insights.append(
                                "‚ö° **Eficiencia**: Ruta directa y eficiente"
                            )
                        else:
                            insights.append(
                                "üîÑ **Eficiencia**: Posibles desv√≠os o tr√°fico"
                            )

                        return insights

                    # Get trip insights
                    trip_insights = analyze_trip_context(
                        pickup_lat,
                        pickup_lon,
                        dropoff_lat,
                        dropoff_lon,
                        distance,
                        predicted_duration,
                    )

                    # Display insights in columns
                    insight_cols = st.columns(2)
                    for i, insight in enumerate(trip_insights):
                        with insight_cols[i % 2]:
                            st.info(insight)

                    # Trip summary with enhanced metrics
                    st.markdown("### üìà M√©tricas del Viaje")
                    col1, col2, col3, col4 = st.columns(4)

                    with col1:
                        st.metric(
                            "üó∫Ô∏è Distancia Euclidiana",
                            f"{distance:.2f} km",
                            help="Distancia en l√≠nea recta (no la ruta real)",
                        )
                    with col2:
                        st.metric(
                            "‚è±Ô∏è Duraci√≥n Predicha", f"{predicted_duration:.1f} min"
                        )
                    with col3:
                        avg_speed = distance / (predicted_duration / 60)
                        st.metric("üöó Velocidad Promedio", f"{avg_speed:.1f} km/h")
                    with col4:
                        efficiency = (
                            distance / predicted_duration
                        ) * 60  # km/h efficiency
                        st.metric(
                            "‚ö° Eficiencia",
                            f"{efficiency:.1f}",
                            help="Ratio distancia/tiempo (mayor = m√°s eficiente)",
                        )

                    # Map purpose explanation
                    with st.expander("üó∫Ô∏è ¬øPara qu√© sirve este mapa?", expanded=False):
                        st.markdown(
                            """
                        **Este mapa NO muestra la ruta real del taxi**, sino que proporciona:

                        ‚úÖ **Validaci√≥n Geogr√°fica**: Confirma que las coordenadas son v√°lidas
                        ‚úÖ **Contexto Visual**: Muestra la magnitud y direcci√≥n del viaje
                        ‚úÖ **Debug de Predicci√≥n**: Ayuda a entender por qu√© el modelo predijo esa duraci√≥n
                        ‚úÖ **An√°lisis de Eficiencia**: Compara distancia euclidiana vs tiempo predicho

                        **¬øPor qu√© no la ruta real?**
                        - Las APIs de rutas reales (Google Maps) tienen costo y latencia
                        - El modelo ML ya considera los factores de tr√°fico en su predicci√≥n
                        - Para este demo educativo, el contexto visual es suficiente

                        **¬øCu√°ndo ser√≠a √∫til la ruta real?**
                        - Aplicaci√≥n de producci√≥n para conductores
                        - Optimizaci√≥n de rutas en tiempo real
                        - An√°lisis detallado de patrones de tr√°fico
                        """
                        )

                except Exception as e:
                    st.warning(f"Error al mostrar el mapa interactivo: {str(e)}")
                    # Fallback to simple map
                    simple_map_data = pd.DataFrame(
                        {
                            "lat": [pickup_lat, dropoff_lat],
                            "lon": [pickup_lon, dropoff_lon],
                        }
                    )
                    st.map(simple_map_data, zoom=zoom_level)
                    st.write("Datos del mapa:", simple_map_data)
            else:
                st.warning(
                    "‚ö†Ô∏è Coordenadas no v√°lidas para mostrar el mapa. Aseg√∫rate de ingresar coordenadas de NYC v√°lidas."
                )
                st.info(
                    "üí° Ejemplo: Pickup (40.7589, -73.9851) | Dropoff (40.7505, -73.9934)"
                )

                # Show sample NYC coordinates for reference
                sample_map = pd.DataFrame(
                    {
                        "lat": [40.7589, 40.7505],
                        "lon": [-73.9851, -73.9934],
                    }
                )
                st.caption(
                    "Ejemplo de mapa con coordenadas de Times Square ‚Üî Union Square:"
                )
                st.map(sample_map, zoom=12)

# üìã Footer
st.markdown("---")
st.markdown(
    """
<div style='text-align: center; color: #666;'>
    üöï <strong>Taxi Duration Predictor</strong> |
    MLOps Dashboard con Streamlit + MLflow |
    Arquitectura Hexagonal + DDD |
    Desarrollado para curso MLOps 2025
</div>
""",
    unsafe_allow_html=True,
)
