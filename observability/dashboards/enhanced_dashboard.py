# ğŸ“Š MLOps Dashboard with Streamlit + MLflow
# FASE 4A: Dashboard ProgramÃ¡tico para Monitoreo de Modelos

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import mlflow
from mlflow.tracking import MlflowClient
import asyncio
import asyncpg
from datetime import datetime, timedelta
import requests
import json
import warnings
from pathlib import Path
import os

warnings.filterwarnings("ignore")

# ğŸš¨ FIX: Configurar paths absolutos desde cualquier directorio
PROJECT_ROOT = Path(__file__).parent.parent.parent.absolute()
MLFLOW_DB_PATH = PROJECT_ROOT / "data" / "mlflow.db"
MLFLOW_TRACKING_URI = f"sqlite:///{MLFLOW_DB_PATH}"

print(f"ğŸ” Dashboard starting from: {Path.cwd()}")
print(f"ğŸ“ Project root: {PROJECT_ROOT}")
print(f"ğŸ—„ï¸ MLflow DB path: {MLFLOW_DB_PATH}")
print(f"ğŸ”— MLflow URI: {MLFLOW_TRACKING_URI}")

# Verificar que el archivo existe
if not MLFLOW_DB_PATH.exists():
    st.error(f"âŒ MLflow database not found at: {MLFLOW_DB_PATH}")
    st.stop()

# ğŸ”§ ConfiguraciÃ³n de pÃ¡gina
st.set_page_config(
    page_title="ğŸš• Taxi Duration Predictor - MLOps Dashboard",
    page_icon="ğŸš•",
    layout="wide",
    initial_sidebar_state="expanded",
)

# ğŸ¨ CSS personalizado
st.markdown(
    """
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
    }
    .success-metric {
        border-left-color: #28a745;
    }
    .warning-metric {
        border-left-color: #ffc107;
    }
    .error-metric {
        border-left-color: #dc3545;
    }
</style>
""",
    unsafe_allow_html=True,
)


# ğŸš€ Funciones utilitarias
@st.cache_data
def load_mlflow_experiments():
    """Carga experimentos desde MLflow programÃ¡ticamente"""
    try:
        # Configurar MLflow con path absoluto
        mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)
        client = MlflowClient()

        # Obtener experimento
        experiment = client.get_experiment_by_name("taxi_duration_prediction")
        if not experiment:
            return None, "No se encontrÃ³ el experimento taxi_duration_prediction"

        # Obtener todas las runs
        runs = client.search_runs(
            experiment_ids=[experiment.experiment_id], order_by=["start_time DESC"]
        )

        # Convertir a DataFrame
        runs_data = []
        for run in runs:
            run_data = {
                "run_id": run.info.run_id,
                "run_name": run.data.tags.get("mlflow.runName", "Unnamed"),
                "model_type": run.data.params.get("model_type", "Unknown"),
                "rmse": float(run.data.metrics.get("rmse", 0)),
                "mae": float(run.data.metrics.get("mae", 0)),
                "r2_score": float(run.data.metrics.get("r2_score", 0)),
                "training_time": float(
                    run.data.metrics.get("training_time_seconds", 0)
                ),
                "start_time": pd.to_datetime(run.info.start_time, unit="ms"),
                "status": run.info.status,
                "train_size": int(run.data.params.get("train_size", 0)),
                "test_size": int(run.data.params.get("test_size", 0)),
            }
            runs_data.append(run_data)

        df = pd.DataFrame(runs_data)
        return df, None

    except Exception as e:
        return None, f"Error cargando MLflow: {str(e)}"


@st.cache_data
def get_best_model():
    """Obtiene el mejor modelo automÃ¡ticamente"""
    df, error = load_mlflow_experiments()
    if error:
        return None, error

    if df.empty:
        return None, "No hay experimentos disponibles"

    # Ordenar por RMSE (menor es mejor)
    best_run = df.loc[df["rmse"].idxmin()]
    return best_run, None


async def get_database_stats():
    """Obtiene estadÃ­sticas actuales de la base de datos"""
    try:
        conn = await asyncpg.connect(
            host="taxi-duration-db.ckj7uy651uld.us-east-1.rds.amazonaws.com",
            port=5432,
            database="postgres",
            user="taxiuser",
            password="TaxiDB2025!",
        )

        # EstadÃ­sticas generales
        stats = await conn.fetchrow(
            """
            SELECT
                COUNT(*) as total_trips,
                AVG(trip_duration_seconds) as avg_duration,
                MIN(pickup_datetime) as earliest_trip,
                MAX(pickup_datetime) as latest_trip,
                COUNT(DISTINCT vendor_id) as unique_vendors
            FROM taxi_trips
        """
        )

        # DistribuciÃ³n por hora
        hourly_stats = await conn.fetch(
            """
            SELECT
                EXTRACT(HOUR FROM pickup_datetime) as hour,
                COUNT(*) as trip_count,
                AVG(trip_duration_seconds) as avg_duration
            FROM taxi_trips
            GROUP BY EXTRACT(HOUR FROM pickup_datetime)
            ORDER BY hour
        """
        )

        await conn.close()

        return {
            "general": dict(stats),
            "hourly": [dict(row) for row in hourly_stats],
        }, None

    except Exception as e:
        return None, f"Error conectando a base de datos: {str(e)}"


# ï¿½ Funciones para monitoreo del FastAPI
# ğŸ“¡ API Configuration - Docker container network
FASTAPI_BASE_URL = os.getenv("API_BASE_URL", "http://localhost:8000")

# ğŸ” Debug: Print API URL being used (for troubleshooting)
print(f"ğŸ”— Dashboard using API URL: {FASTAPI_BASE_URL}")


@st.cache_data(ttl=10)  # Reduced cache to 10 seconds for faster debugging
def check_api_health():
    """Verifica el estado del API FastAPI"""
    try:
        print(f"ğŸ” Attempting to connect to API at: {FASTAPI_BASE_URL}")
        # Try the detailed health endpoint first (correct path without trailing slash)
        response = requests.get(f"{FASTAPI_BASE_URL}/api/v1/health", timeout=5)
        print(f"âœ… API responded with status: {response.status_code}")
        if response.status_code == 200:
            return response.json(), None
        else:
            # Fallback to basic health endpoint
            response = requests.get(f"{FASTAPI_BASE_URL}/health", timeout=5)
            if response.status_code == 200:
                basic_health = response.json()
                # Convert basic health to expected format
                return {
                    "status": "healthy" if basic_health.get("status") == "ok" else "degraded",
                    "model_status": "ready",  # Assume model is ready if API is working
                    "timestamp": basic_health.get("timestamp", ""),
                    "version": "1.0.0",
                }, None
            else:
                return None, f"API respondiÃ³ con cÃ³digo {response.status_code}"
    except requests.exceptions.ConnectionError as e:
        error_msg = f"ConnectionError: {str(e)} - Trying to reach: {FASTAPI_BASE_URL}"
        print(f"âŒ {error_msg}")
        return None, f"API no disponible - {error_msg}"
    except requests.exceptions.Timeout as e:
        error_msg = f"Timeout after 5s connecting to {FASTAPI_BASE_URL}"
        print(f"â° {error_msg}")
        return None, f"Timeout conectando al API - {error_msg}"
    except Exception as e:
        error_msg = f"Unexpected error: {str(e)} when connecting to {FASTAPI_BASE_URL}"
        print(f"ğŸš¨ {error_msg}")
        return None, f"Error verificando API: {error_msg}"


@st.cache_data(ttl=60)  # Cache por 1 minuto
def get_api_model_info():
    """Obtiene informaciÃ³n del modelo desde el API"""
    try:
        # Use the correct endpoint format with trailing slash
        response = requests.get(f"{FASTAPI_BASE_URL}/api/v1/health/model", timeout=5)
        if response.status_code == 200:
            return response.json(), None

        return None, f"Error obteniendo info del modelo: {response.status_code}"
    except Exception as e:
        return None, f"Error: {str(e)}"


def make_api_prediction(prediction_data):
    """Hace una predicciÃ³n usando el API FastAPI"""
    try:
        # Use the correct endpoint format with trailing slash
        response = requests.post(
            f"{FASTAPI_BASE_URL}/api/v1/predict/", json=prediction_data, timeout=10
        )
        if response.status_code == 200:
            return response.json(), None

        # If failed, return error
        error_text = response.text
        try:
            error_json = response.json()
            error_detail = error_json.get("detail", error_text)
        except:
            error_detail = error_text
        return (
            None,
            f"Error en predicciÃ³n: {response.status_code} - {error_detail}",
        )
    except Exception as e:
        return None, f"Error haciendo predicciÃ³n: {str(e)}"


@st.cache_data(ttl=300)  # Cache por 5 minutos
def get_api_database_stats():
    """Obtiene estadÃ­sticas de la base de datos desde el API"""
    try:
        # TODO: Implementar endpoint /api/v1/stats/database en el API
        # Por ahora, retornamos datos dummy para que funcione la interfaz
        return {
            "total_trips": 1250,
            "avg_duration_minutes": 15.7,
            "most_popular_pickup_zone": "Manhattan",
            "prediction_accuracy": 92.3,
            "last_updated": datetime.now().isoformat(),
        }, None
    except Exception as e:
        return None, f"Error: {str(e)}"


# ğŸ“Š Header principal
st.markdown(
    '<h1 class="main-header">ğŸš• MLOps Dashboard - Taxi Duration Predictor</h1>',
    unsafe_allow_html=True,
)

# Comprehensive UX Welcome Banner
st.markdown(
    """
---
### ğŸ‘‹ Bienvenido al Dashboard MLOps de PredicciÃ³n de DuraciÃ³n de Viajes de Taxi

Este dashboard proporciona una **interfaz completa para monitorear, analizar y usar** nuestro sistema de Machine Learning en producciÃ³n.

#### ğŸ¯ **Roles y Vistas Recomendadas:**
- **ğŸ‘” Gerentes/Directores** â†’ ğŸ“ˆ Overview General (mÃ©tricas ejecutivas)
- **ğŸ§ª Data Scientists** â†’ ğŸ¤– ComparaciÃ³n de Modelos (performance tÃ©cnico)
- **ğŸ“Š Analistas de Datos** â†’ ğŸ“Š AnÃ¡lisis de Datos (patrones de negocio)
- **âš™ï¸ DevOps/SysAdmins** â†’ ğŸš€ API Status (monitoreo tÃ©cnico)
- **ğŸ‘¥ Usuarios Finales** â†’ ğŸ¯ Simulador (predicciones interactivas)

#### ğŸ“š **MÃ©tricas Clave:**
- **RMSE**: Error promedio en minutos - **MENOR = MEJOR** â¬‡ï¸
- **RÂ² Score**: % de varianza explicada - **MAYOR = MEJOR** â¬†ï¸ (0-1)
- **MAE**: Error absoluto promedio - **MENOR = MEJOR** â¬‡ï¸

#### ğŸš€ **Comenzar:**
1. Selecciona tu vista en la barra lateral â¬…ï¸
2. Usa el botÃ³n "ğŸ”„ Actualizar Datos" para refrescar informaciÃ³n
3. Explora los expandibles "â„¹ï¸" para obtener ayuda contextual

---
"""
)

# Add real-time system status banner
try:
    api_health, _ = check_api_health()
    if api_health:
        st.success("ğŸŸ¢ **Sistema Operacional** - API funcionando correctamente")
    else:
        st.warning(
            "ğŸŸ¡ **API Offline** - Funcionalidad limitada (solo datos histÃ³ricos)"
        )
except:
    st.warning("ğŸŸ¡ **Verificando Sistema** - Cargando estado del API...")

st.markdown("---")

# ğŸ”„ Sidebar para controles
st.sidebar.markdown("## ğŸ›ï¸ Controles del Dashboard")

# BotÃ³n de refresh
if st.sidebar.button("ğŸ”„ Actualizar Datos", type="primary"):
    st.cache_data.clear()
    st.rerun()

# Selector de vista
view_mode = st.sidebar.selectbox(
    "ğŸ“Š Seleccionar Vista",
    [
        "ğŸ“ˆ Overview General",
        "ğŸ¤– ComparaciÃ³n de Modelos",
        "ğŸ“Š AnÃ¡lisis de Datos",
        "ğŸš€ API Status & Monitoring",
        "ğŸ¯ Monitoreo en Tiempo Real",
    ],
)

st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ“‹ InformaciÃ³n del Sistema")
st.sidebar.info(
    f"""
**Ãšltima actualizaciÃ³n:** {datetime.now().strftime('%H:%M:%S')}
**MLflow URI:** {MLFLOW_TRACKING_URI}
**Base de datos:** AWS PostgreSQL
**Estado:** ğŸŸ¢ Activo
"""
)

# Add user guidance in sidebar
st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ“ GuÃ­a de Usuario")

with st.sidebar.expander("ğŸ“š Â¿CÃ³mo usar cada vista?", expanded=False):
    st.markdown(
        """
    **ğŸ“ˆ Overview General:**
    - Estado ejecutivo del sistema
    - MÃ©tricas principales del modelo
    - Para: Gerentes y directores

    **ğŸ¤– ComparaciÃ³n de Modelos:**
    - Performance entre algoritmos
    - GrÃ¡ficos comparativos
    - Para: Data Scientists

    **ğŸ“Š AnÃ¡lisis de Datos:**
    - Patrones en datos de producciÃ³n
    - Insights automÃ¡ticos
    - Para: Analistas de datos

    **ğŸš€ API Status:**
    - Monitoreo del servidor
    - Tests de endpoints
    - Para: DevOps/Desarrolladores

    **ğŸ¯ Simulador:**
    - Predicciones en tiempo real
    - Interface de usuario
    - Para: Usuarios finales
    """
    )

with st.sidebar.expander("âš¡ Atajos de Teclado", expanded=False):
    st.markdown(
        """
    - **Ctrl + R**: Refrescar datos
    - **F5**: Recargar dashboard
    - **Ctrl + Shift + R**: Limpiar cache
    """
    )

st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ†˜ Soporte")
st.sidebar.error(
    """
**Â¿Problemas?**
1. Verificar que FastAPI estÃ© corriendo
2. Comprobar conexiÃ³n a base de datos
3. Revisar logs del sistema
4. Contactar equipo tÃ©cnico
"""
)

st.sidebar.markdown("---")
st.sidebar.caption("ğŸš• Taxi Duration Predictor v2.0 | MLOps Dashboard")

# ğŸ“Š Vista Overview General
if view_mode == "ğŸ“ˆ Overview General":
    st.markdown("## ğŸ“ˆ Resumen Ejecutivo")

    # UX Explanation for users
    st.info(
        """
    ğŸ¯ **CÃ³mo usar esta vista:**
    - **Para Gerentes/Directores**: RevisiÃ³n rÃ¡pida del estado del sistema ML
    - **Indicadores Verdes**: Sistema funcionando correctamente
    - **RMSE mÃ¡s bajo = Mejor precisiÃ³n** del modelo (error promedio en minutos)
    - **RÂ² mÃ¡s alto = Mejor calidad** del modelo (% de varianza explicada)
    """
    )

    # Cargar datos de MLflow
    experiments_df, mlflow_error = load_mlflow_experiments()

    if mlflow_error:
        st.error(f"âŒ Error con MLflow: {mlflow_error}")
    else:
        # MÃ©tricas principales
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.markdown(
                '<div class="metric-card success-metric">', unsafe_allow_html=True
            )
            st.metric(
                label="ğŸ¤– Experimentos Totales",
                value=len(experiments_df) if experiments_df is not None else 0,
            )
            st.markdown("</div>", unsafe_allow_html=True)

        with col2:
            if experiments_df is not None and not experiments_df.empty:
                best_rmse = experiments_df["rmse"].min()
                st.markdown(
                    '<div class="metric-card success-metric">', unsafe_allow_html=True
                )
                st.metric(label="ğŸ† Mejor RMSE", value=f"{best_rmse:.2f} min")
                st.markdown("</div>", unsafe_allow_html=True)

        with col3:
            if experiments_df is not None and not experiments_df.empty:
                best_r2 = experiments_df["r2_score"].max()
                st.markdown(
                    '<div class="metric-card success-metric">', unsafe_allow_html=True
                )
                st.metric(label="ğŸ“Š Mejor RÂ²", value=f"{best_r2:.3f}")
                st.markdown("</div>", unsafe_allow_html=True)

        with col4:
            if experiments_df is not None and not experiments_df.empty:
                avg_training_time = experiments_df["training_time"].mean()
                st.markdown('<div class="metric-card">', unsafe_allow_html=True)
                st.metric(label="â±ï¸ Tiempo Promedio", value=f"{avg_training_time:.1f}s")
                st.markdown("</div>", unsafe_allow_html=True)

        # Mejor modelo actual
        best_model, best_error = get_best_model()

        if not best_error and best_model is not None:
            st.markdown("## ğŸ† Modelo en ProducciÃ³n (Recomendado)")

            # Explanation for users
            st.success("âœ… **Estado**: Modelo entrenado y listo para producciÃ³n")

            with st.expander("â„¹ï¸ Â¿CÃ³mo interpretar estas mÃ©tricas?", expanded=False):
                st.markdown(
                    """
                **ğŸ“Š RMSE (Root Mean Square Error)**:
                - **QuÃ© significa**: Error promedio en minutos de nuestras predicciones
                - **Valor actual**: {:.2f} minutos
                - **InterpretaciÃ³n**: "Nuestro modelo tÃ­picamente se equivoca por Â±{:.2f} minutos"
                - **Objetivo**: **MENOR es MEJOR** â¬‡ï¸

                **ğŸ“ˆ MAE (Mean Absolute Error)**:
                - **QuÃ© significa**: Error absoluto promedio en predicciones
                - **Valor actual**: {:.2f} minutos
                - **InterpretaciÃ³n**: "La mitad de nuestras predicciones estÃ¡n dentro de {:.2f} minutos"
                - **Objetivo**: **MENOR es MEJOR** â¬‡ï¸

                **ğŸ¯ RÂ² Score (Coeficiente de DeterminaciÃ³n)**:
                - **QuÃ© significa**: QuÃ© tanto puede explicar nuestro modelo
                - **Valor actual**: {:.3f} ({:.1f}% de varianza explicada)
                - **InterpretaciÃ³n**: "Podemos explicar {:.1f}% de las variaciones en duraciÃ³n de viajes"
                - **Objetivo**: **MAYOR es MEJOR** â¬†ï¸ (mÃ¡ximo = 1.0)

                **â±ï¸ Tiempo de Entrenamiento**:
                - **QuÃ© significa**: CuÃ¡nto tardÃ³ en entrenarse el modelo
                - **Valor actual**: {:.1f} segundos
                - **InterpretaciÃ³n**: "Tiempo necesario para reentrenar si se requiere"
                """.format(
                        best_model["rmse"],
                        best_model["rmse"],
                        best_model["mae"],
                        best_model["mae"],
                        best_model["r2_score"],
                        best_model["r2_score"] * 100,
                        best_model["r2_score"] * 100,
                        best_model["training_time"],
                    )
                )

            col1, col2 = st.columns([2, 1])

            with col1:
                st.success(
                    f"""
                **ğŸ¤– Modelo:** {best_model['model_type']}
                **ğŸ“Š RMSE:** {best_model['rmse']:.2f} minutos
                **ğŸ“ˆ MAE:** {best_model['mae']:.2f} minutos
                **ğŸ¯ RÂ²:** {best_model['r2_score']:.3f}
                **â±ï¸ Tiempo de entrenamiento:** {best_model['training_time']:.1f}s
                **ğŸ“… Entrenado:** {best_model['start_time'].strftime('%Y-%m-%d %H:%M')}
                """
                )

            with col2:
                # GrÃ¡fico de mÃ©tricas del mejor modelo
                metrics_data = {
                    "MÃ©trica": ["RMSE", "MAE", "RÂ²"],
                    "Valor": [
                        best_model["rmse"],
                        best_model["mae"],
                        best_model["r2_score"],
                    ],
                    "Objetivo": ["Minimizar", "Minimizar", "Maximizar"],
                }
                metrics_df = pd.DataFrame(metrics_data)

                fig = px.bar(
                    metrics_df,
                    x="MÃ©trica",
                    y="Valor",
                    color="Objetivo",
                    title="MÃ©tricas del Mejor Modelo",
                )
                fig.update_layout(height=300)
                st.plotly_chart(fig, use_container_width=True)

# ğŸ¤– Vista ComparaciÃ³n de Modelos
elif view_mode == "ğŸ¤– ComparaciÃ³n de Modelos":
    st.markdown("## ğŸ¤– ComparaciÃ³n Detallada de Modelos")

    # UX Guidance for model comparison
    st.info(
        """
    ğŸ¯ **CÃ³mo usar esta vista:**
    - **Para Data Scientists/ML Engineers**: Comparar performance entre diferentes algoritmos
    - **Tabla ordenada por RMSE**: El modelo en la primera fila es el **mejor**
    - **GrÃ¡ficos**: VisualizaciÃ³n de mÃ©tricas para decisiones informadas
    """
    )

    with st.expander("ğŸ“š GuÃ­a de InterpretaciÃ³n de GrÃ¡ficos", expanded=False):
        st.markdown(
            """
        **ğŸ“Š GrÃ¡fico RMSE vs MAE (Izquierda)**:
        - **PosiciÃ³n ideal**: Esquina inferior izquierda (valores bajos en ambas mÃ©tricas)
        - **TamaÃ±o del punto**: Proporcional al RÂ² Score (mÃ¡s grande = mejor)
        - **InterpretaciÃ³n**: Modelos cercanos al origen son mÃ¡s precisos

        **ğŸ¯ GrÃ¡fico RÂ² Score (Derecha)**:
        - **Barras mÃ¡s altas = Mejor modelo**
        - **Escala**: 0.0 (terrible) a 1.0 (perfecto)
        - **Umbral aceptable**: > 0.6 para uso en producciÃ³n
        - **InterpretaciÃ³n**: % de varianza que el modelo puede explicar
        """
        )

    experiments_df, error = load_mlflow_experiments()

    if error:
        st.error(f"âŒ Error: {error}")
    elif experiments_df is None or experiments_df.empty:
        st.warning(
            "âš ï¸ No hay experimentos disponibles. Ejecuta primero el notebook de entrenamiento."
        )
    else:
        # Tabla de comparaciÃ³n
        st.markdown("### ğŸ“Š Tabla de Resultados")

        # Formatear tabla para mostrar
        display_df = experiments_df[
            ["model_type", "rmse", "mae", "r2_score", "training_time", "start_time"]
        ].copy()
        display_df["start_time"] = display_df["start_time"].dt.strftime(
            "%Y-%m-%d %H:%M"
        )
        display_df = display_df.sort_values("rmse")

        # Colorear la tabla
        st.dataframe(
            display_df,
            column_config={
                "model_type": "ğŸ¤– Modelo",
                "rmse": st.column_config.NumberColumn("ğŸ“Š RMSE", format="%.2f"),
                "mae": st.column_config.NumberColumn("ğŸ“ˆ MAE", format="%.2f"),
                "r2_score": st.column_config.NumberColumn("ğŸ¯ RÂ²", format="%.3f"),
                "training_time": st.column_config.NumberColumn(
                    "â±ï¸ Tiempo (s)", format="%.1f"
                ),
                "start_time": "ğŸ“… Fecha",
            },
            use_container_width=True,
        )

        # GrÃ¡ficos de comparaciÃ³n
        st.markdown("### ğŸ“Š VisualizaciÃ³n Comparativa")

        # Add chart interpretation guidance
        col_info1, col_info2 = st.columns(2)
        with col_info1:
            st.caption(
                "â¬…ï¸ **RMSE vs MAE**: Puntos en esquina inferior izquierda = mejores modelos"
            )
        with col_info2:
            st.caption("â¡ï¸ **RÂ² Score**: Barras mÃ¡s altas = mejor capacidad explicativa")

        col1, col2 = st.columns(2)

        with col1:
            # GrÃ¡fico RMSE vs MAE
            fig1 = px.scatter(
                experiments_df,
                x="rmse",
                y="mae",
                color="model_type",
                size="r2_score",
                title="ğŸ“Š RMSE vs MAE por Modelo (Menor = Mejor)",
                hover_data=["training_time"],
                labels={
                    "rmse": "RMSE (minutos) - Menor es Mejor â¬‡ï¸",
                    "mae": "MAE (minutos) - Menor es Mejor â¬‡ï¸",
                },
            )
            fig1.update_layout(height=400)
            st.plotly_chart(fig1, use_container_width=True)

        with col2:
            # GrÃ¡fico de barras RÂ²
            fig2 = px.bar(
                experiments_df,
                x="model_type",
                y="r2_score",
                color="model_type",
                title="ğŸ¯ RÂ² Score por Modelo (Mayor = Mejor)",
                labels={
                    "r2_score": "RÂ² Score - Mayor es Mejor â¬†ï¸",
                    "model_type": "Tipo de Modelo",
                },
            )
            # Add horizontal line at 0.6 threshold
            fig2.add_hline(
                y=0.6,
                line_dash="dash",
                line_color="red",
                annotation_text="Umbral mÃ­nimo para producciÃ³n (0.6)",
            )
            fig2.update_layout(height=400)
            st.plotly_chart(fig2, use_container_width=True)

        # AnÃ¡lisis de performance
        st.markdown("### ğŸ AnÃ¡lisis de Performance")

        # Business impact explanation
        st.info(
            """
        ğŸ’¡ **Impacto en el Negocio:**
        - **Mejor precisiÃ³n** = Estimaciones mÃ¡s confiables para clientes
        - **Menor error** = Mejor planificaciÃ³n de rutas y tiempos
        - **Mayor RÂ²** = El modelo entiende mejor los patrones de trÃ¡fico
        """
        )

        best_model = experiments_df.loc[experiments_df["rmse"].idxmin()]
        worst_model = experiments_df.loc[experiments_df["rmse"].idxmax()]

        col1, col2, col3 = st.columns(3)

        with col1:
            st.success(
                f"""
            **ğŸ† MEJOR MODELO**
            **Tipo:** {best_model['model_type']}
            **RMSE:** {best_model['rmse']:.2f} min
            **RÂ²:** {best_model['r2_score']:.3f}

            âœ… **Recomendado para producciÃ³n**
            """
            )

        with col2:
            st.error(
                f"""
            **âŒ MODELO CON MAYOR ERROR**
            **Tipo:** {worst_model['model_type']}
            **RMSE:** {worst_model['rmse']:.2f} min
            **RÂ²:** {worst_model['r2_score']:.3f}

            âš ï¸ **No usar en producciÃ³n**
            """
            )

        with col3:
            improvement = (
                (worst_model["rmse"] - best_model["rmse"]) / worst_model["rmse"]
            ) * 100
            st.info(
                f"""
            **ğŸ“ˆ MEJORA OBTENIDA**
            **ReducciÃ³n RMSE:** {improvement:.1f}%
            **Diferencia:** {worst_model['rmse'] - best_model['rmse']:.2f} min
            **Impacto:** Predicciones {improvement:.1f}% mÃ¡s precisas

            ğŸ¯ **Valor**: Estimaciones mÃ¡s confiables
            """
            )

# ğŸ“Š Vista AnÃ¡lisis de Datos
elif view_mode == "ğŸ“Š AnÃ¡lisis de Datos":
    st.markdown("## ğŸ“Š AnÃ¡lisis de Datos de ProducciÃ³n")

    # UX Guidance for data analysis
    st.info(
        """
    ğŸ¯ **CÃ³mo usar esta vista:**
    - **Para Analistas de Datos**: Entender patrones en los datos de producciÃ³n
    - **Para Operaciones**: Identificar horas pico y optimizar recursos
    - **Insights automÃ¡ticos**: El sistema detecta patrones importantes automÃ¡ticamente
    """
    )

    with st.expander("ğŸ“ˆ CÃ³mo interpretar los grÃ¡ficos de datos", expanded=False):
        st.markdown(
            """
        **ğŸš• DistribuciÃ³n de Viajes por Hora:**
        - **Picos altos** = Horas de mayor demanda (mÃ¡s taxis necesarios)
        - **Valles bajos** = Horas de menor demanda (reducir flota)
        - **PatrÃ³n tÃ­pico**: Picos en horas laborales (7-9 AM, 5-7 PM)

        **â±ï¸ DuraciÃ³n Promedio por Hora:**
        - **LÃ­neas altas** = TrÃ¡fico mÃ¡s lento (mayor tiempo de viaje)
        - **LÃ­neas bajas** = TrÃ¡fico fluido (menor tiempo de viaje)
        - **CorrelaciÃ³n**: Alta demanda â‰  necesariamente mayor duraciÃ³n
        """
        )

    # Cargar estadÃ­sticas de la base de datos
    with st.spinner("Cargando datos de la base de datos..."):
        db_stats, db_error = asyncio.run(get_database_stats())

    if db_error:
        st.error(f"âŒ Error conectando a la base de datos: {db_error}")
    else:
        # EstadÃ­sticas generales
        st.markdown("### ğŸ“‹ EstadÃ­sticas Generales")

        general_stats = db_stats["general"]

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric(
                label="ğŸš• Total de Viajes", value=f"{general_stats['total_trips']:,}"
            )

        with col2:
            avg_duration_min = general_stats["avg_duration"] / 60
            st.metric(label="â±ï¸ DuraciÃ³n Promedio", value=f"{avg_duration_min:.1f} min")

        with col3:
            st.metric(label="ğŸ¢ Vendors Ãšnicos", value=general_stats["unique_vendors"])

        with col4:
            date_range = (
                general_stats["latest_trip"] - general_stats["earliest_trip"]
            ).days
            st.metric(label="ğŸ“… Rango de Datos", value=f"{date_range} dÃ­as")

        # DistribuciÃ³n por hora
        st.markdown("### ğŸ“ˆ DistribuciÃ³n de Viajes por Hora")

        hourly_data = pd.DataFrame(db_stats["hourly"])
        hourly_data["avg_duration_min"] = hourly_data["avg_duration"] / 60

        col1, col2 = st.columns(2)

        with col1:
            fig1 = px.bar(
                hourly_data,
                x="hour",
                y="trip_count",
                title="ğŸš• NÃºmero de Viajes por Hora del DÃ­a",
            )
            fig1.update_xaxes(title="Hora del DÃ­a")
            fig1.update_yaxes(title="NÃºmero de Viajes")
            st.plotly_chart(fig1, use_container_width=True)

        with col2:
            fig2 = px.line(
                hourly_data,
                x="hour",
                y="avg_duration_min",
                title="â±ï¸ DuraciÃ³n Promedio por Hora del DÃ­a",
                markers=True,
            )
            fig2.update_xaxes(title="Hora del DÃ­a")
            fig2.update_yaxes(title="DuraciÃ³n Promedio (minutos)")
            st.plotly_chart(fig2, use_container_width=True)

        # Insights automÃ¡ticos
        st.markdown("### ğŸ§  Insights AutomÃ¡ticos")

        busiest_hour = hourly_data.loc[hourly_data["trip_count"].idxmax()]
        longest_duration_hour = hourly_data.loc[
            hourly_data["avg_duration_min"].idxmax()
        ]

        col1, col2 = st.columns(2)

        with col1:
            st.info(
                f"""
            **ğŸš¦ Hora MÃ¡s Ocupada**
            **Hora:** {int(busiest_hour['hour'])}:00
            **Viajes:** {int(busiest_hour['trip_count']):,}
            **DuraciÃ³n promedio:** {busiest_hour['avg_duration_min']:.1f} min
            """
            )

        with col2:
            st.warning(
                f"""
            **ğŸŒ Hora con Mayor DuraciÃ³n**
            **Hora:** {int(longest_duration_hour['hour'])}:00
            **DuraciÃ³n promedio:** {longest_duration_hour['avg_duration_min']:.1f} min
            **Viajes:** {int(longest_duration_hour['trip_count']):,}
            """
            )

# ğŸš€ Vista API Status & Monitoring
elif view_mode == "ğŸš€ API Status & Monitoring":
    st.markdown("## ğŸš€ API Status & Monitoring")
    st.markdown("*Monitor del FastAPI Server y mÃ©tricas de rendimiento*")

    # UX Guidance for API monitoring
    st.info(
        """
    ğŸ¯ **CÃ³mo usar esta vista:**
    - **Para DevOps/SysAdmins**: Monitorear salud del sistema en producciÃ³n
    - **Para Desarrolladores**: Probar endpoints y validar respuestas
    - **Indicadores clave**: API Status, Model Loaded, Database Status
    """
    )

    with st.expander("ğŸš¨ GuÃ­a de ResoluciÃ³n de Problemas", expanded=False):
        st.markdown(
            """
        **âŒ API No Disponible:**
        1. Verificar que FastAPI estÃ© ejecutÃ¡ndose en puerto 8000
        2. Comando: `source activate ds_env && python 05_fastapi_server.py`
        3. Revisar logs del servidor

        **âš ï¸ Model Not Loaded:**
        1. Verificar que MLflow tenga modelos registrados
        2. Ejecutar entrenamiento si es necesario
        3. Revisar conexiÃ³n con base de datos MLflow

        **ğŸ”´ Database Error:**
        1. Verificar conexiÃ³n AWS RDS
        2. Validar credenciales de base de datos
        3. Comprobar conectividad de red
        """
        )

    # Health Check del API
    st.markdown("### ğŸ¥ Estado del API")

    api_health, health_error = check_api_health()

    if health_error:
        st.error(f"âŒ API No Disponible: {health_error}")
        st.info(
            "ğŸ’¡ **Para activar el API:** `source activate ds_env && python 05_fastapi_server.py`"
        )
    else:
        # Mostrar estado del API
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            api_status = api_health.get("status", "unknown")
            if api_status == "healthy":
                st.metric(label="ğŸŸ¢ API Status", value="HEALTHY")
            elif api_status == "degraded":
                st.metric(label="ğŸŸ¡ API Status", value="DEGRADED")
            else:
                st.metric(label="ğŸŸ¢ API Status", value=api_status.upper())

        with col2:
            # Check model info independently of health status
            model_info, model_error = get_api_model_info()
            if not model_error and model_info:
                st.metric(label="ğŸ¤– Model Loaded", value="âœ… YES")
                actual_model_loaded = True
            else:
                model_status = api_health.get("model_status", None)
                if model_status == "error":
                    st.metric(label="ğŸ¤– Model Loaded", value="âŒ NO")
                else:
                    st.metric(label="ğŸ¤– Model Loaded", value="â“ N/A")
                actual_model_loaded = False

        with col3:
            # For now, we don't have database status from API, so show connected if API is working
            if api_health.get("status") in ["healthy", "degraded"]:
                st.metric(label="ğŸ—„ï¸ Database", value="ğŸŸ¢ CONNECTED")
            else:
                st.metric(label="ğŸ—„ï¸ Database", value="â“ N/A")

        with col4:
            timestamp = api_health.get("timestamp", "")
            try:
                formatted_time = datetime.fromisoformat(
                    timestamp.replace("Z", "+00:00")
                ).strftime("%H:%M:%S")
            except:
                formatted_time = timestamp[:8] if len(timestamp) >= 8 else "N/A"
            st.metric(label="ğŸ•’ Last Check", value=formatted_time)

        # Show API status explanation
        api_status = api_health.get("status", "unknown")
        model_status_from_health = api_health.get("model_status", "unknown")

        if api_status == "degraded":
            st.warning("âš ï¸ **API en modo degradado** - El API estÃ¡ funcionando pero con limitaciones (ej: predicciones pueden fallar)")

        # Show inconsistency warning if health says error but model info works
        if model_status_from_health == "error" and actual_model_loaded:
            st.info("â„¹ï¸ **Inconsistencia detectada**: El health check reporta error en el modelo, pero la informaciÃ³n del modelo estÃ¡ disponible. Esto puede indicar un problema especÃ­fico con las predicciones.")

        # InformaciÃ³n del modelo en el API - use actual model info check
        if actual_model_loaded:
            st.markdown("### ğŸ¤– Modelo en ProducciÃ³n (API)")

            model_info, model_error = get_api_model_info()

            if not model_error and model_info:
                col1, col2 = st.columns([2, 1])

                with col1:
                    # The API returns fields directly, not nested under model_metadata
                    st.success(
                        f"""
                    **ğŸ¤– Modelo:** {model_info.get('model_type', 'Unknown')}
                    **ğŸ“Š RMSE:** {model_info.get('rmse', 0):.2f} minutos
                    **ğŸ“ˆ MAE:** {model_info.get('mae', 0):.2f} minutos
                    **ğŸ¯ RÂ²:** {model_info.get('r2_score', 0):.3f}
                    **ï¿½ Creado:** {model_info.get('created_at', 'Unknown')[:16]}
                    """
                    )

                with col2:
                    # Features requeridas - parse from string format
                    st.markdown("**ğŸ“‹ Features Requeridas:**")
                    features_str = model_info.get("features", "[]")
                    try:
                        # Try to extract features from string representation
                        import ast
                        if features_str.startswith('[') and features_str.endswith(']'):
                            features_list = ast.literal_eval(features_str)
                        else:
                            # Fallback: split by comma if it's a simple string
                            features_list = [f.strip().strip("'\"") for f in features_str.split(',') if f.strip()]

                        if features_list:
                            features_df = pd.DataFrame(
                                {
                                    "Feature": features_list,
                                    "Tipo": ["NumÃ©rico"] * len(features_list),
                                }
                            )
                            st.dataframe(features_df, hide_index=True, use_container_width=True)
                        else:
                            st.info("No se pudieron cargar las features del modelo")
                    except Exception as e:
                        st.warning(f"Error procesando features: {e}")
                        st.code(f"Features raw: {features_str}")
        else:
            # Model not loaded - show diagnostic info
            st.markdown("### âš ï¸ DiagnÃ³stico del Modelo")

            model_status_from_health = api_health.get("model_status", "unknown")
            if model_status_from_health == "error":
                st.error("âŒ **Health Check reporta**: Modelo con errores")

            # Try to get model info anyway to see if it's really unavailable
            model_info, model_error = get_api_model_info()
            if model_error:
                st.error(f"âŒ **Model Info**: {model_error}")
                st.info("""
                ğŸ’¡ **Pasos para resolver**:
                1. Verificar que MLflow tiene modelos registrados
                2. Revisar logs del servidor FastAPI
                3. Ejecutar re-entrenamiento si es necesario
                """)
            else:
                st.warning("âš ï¸ **Inconsistencia**: Model info disponible pero health check reporta error")

        # Test de predicciÃ³n usando el API
        st.markdown("### ğŸ§ª Test de PredicciÃ³n API")

        with st.expander("ğŸš€ Probar PredicciÃ³n via API", expanded=False):
            with st.form("api_prediction_form"):
                col1, col2 = st.columns(2)

                with col1:
                    pickup_lat = st.number_input(
                        "ğŸ“ Pickup Latitude", value=40.7589, format="%.6f"
                    )
                    pickup_lon = st.number_input(
                        "ğŸ“ Pickup Longitude", value=-73.9851, format="%.6f"
                    )
                    dropoff_lat = st.number_input(
                        "ğŸ“ Dropoff Latitude", value=40.7505, format="%.6f"
                    )
                    dropoff_lon = st.number_input(
                        "ğŸ“ Dropoff Longitude", value=-73.9934, format="%.6f"
                    )

                with col2:
                    passenger_count = st.selectbox(
                        "ğŸ‘¥ Passengers", [1, 2, 3, 4, 5, 6], index=1
                    )
                    vendor_id = st.selectbox("ğŸ¢ Vendor ID", [1, 2])
                    pickup_hour = st.slider("ğŸ• Pickup Hour", 0, 23, 14)
                    day_of_week = st.slider("ğŸ“… Day of Week", 0, 6, 2)
                    month = st.slider("ğŸ“† Month", 1, 12, 7)

                submitted = st.form_submit_button("ğŸš€ Predecir via API", type="primary")

                if submitted:
                    # Create a datetime object for pickup_datetime using the provided components
                    from datetime import datetime
                    pickup_datetime = datetime(
                        year=2025,  # Default year
                        month=month,
                        day=15,  # Default day
                        hour=pickup_hour,
                        minute=0,
                        second=0
                    )

                    prediction_data = {
                        "pickup_latitude": pickup_lat,
                        "pickup_longitude": pickup_lon,
                        "dropoff_latitude": dropoff_lat,
                        "dropoff_longitude": dropoff_lon,
                        "passenger_count": passenger_count,
                        "vendor_id": vendor_id,
                        "pickup_datetime": pickup_datetime.isoformat(),
                    }

                    prediction_result, pred_error = make_api_prediction(prediction_data)

                    if pred_error:
                        st.error(f"âŒ Error en predicciÃ³n: {pred_error}")
                        if "500" in str(pred_error):
                            st.info("""
                            ğŸ’¡ **Posibles causas del error 500:**
                            - El modelo tiene problemas internos de predicciÃ³n
                            - Los datos enviados no estÃ¡n en el formato esperado
                            - Error en el pipeline de features del modelo
                            - Verificar logs del servidor FastAPI para mÃ¡s detalles
                            """)
                        elif "404" in str(pred_error):
                            st.info("ğŸ’¡ **Error 404**: El endpoint de predicciÃ³n no existe o cambiÃ³ de ruta")
                        elif "timeout" in str(pred_error).lower():
                            st.info("ğŸ’¡ **Timeout**: El servidor estÃ¡ tardando mucho en responder")
                    else:
                        # Mostrar resultado
                        col1, col2, col3 = st.columns(3)

                        with col1:
                            st.metric(
                                "ğŸ¯ DuraciÃ³n Predicha",
                                f"{prediction_result['predicted_duration_minutes']:.1f} min",
                            )

                        with col2:
                            st.metric(
                                "ğŸ“ Distancia",
                                f"{prediction_result['distance_km']:.2f} km",
                            )

                        with col3:
                            st.metric(
                                "ğŸ² Confianza",
                                f"{prediction_result['confidence_score']:.1%}",
                            )

                        # Detalles de la predicciÃ³n
                        st.markdown("**ğŸ“Š Detalles de la PredicciÃ³n:**")
                        details_data = []
                        for feature, value in prediction_result[
                            "features_used"
                        ].items():
                            details_data.append({"Feature": feature, "Valor": value})

                        details_df = pd.DataFrame(details_data)
                        st.dataframe(
                            details_df, hide_index=True, use_container_width=True
                        )

                        # JSON Response
                        with st.expander("ğŸ“„ Respuesta JSON completa"):
                            st.json(prediction_result)

        # EstadÃ­sticas via API
        st.markdown("### ğŸ“Š EstadÃ­sticas de la Base de Datos (via API)")

        api_stats, stats_error = get_api_database_stats()

        if stats_error:
            st.warning(f"âš ï¸ No se pudieron obtener estadÃ­sticas: {stats_error}")
        else:
            col1, col2, col3 = st.columns(3)

            with col1:
                st.metric("ğŸš• Total Viajes", f"{api_stats['total_trips']:,}")

            with col2:
                st.metric(
                    "â±ï¸ DuraciÃ³n Promedio",
                    f"{api_stats['avg_duration_minutes']:.1f} min",
                )

            with col3:
                st.metric("ğŸ“… Ãšltima ActualizaciÃ³n", api_stats["last_updated"][:16])

        # URLs Ãºtiles
        st.markdown("### ğŸ”— Enlaces Ãštiles")

        col1, col2, col3 = st.columns(3)

        with col1:
            st.markdown("**ğŸ“– [Swagger Docs](http://localhost:8000/docs)**")
            st.markdown("âš ï¸ *Links work from host machine, not inside container*")
            st.caption("DocumentaciÃ³n interactiva del API")

        with col2:
            st.markdown("**ğŸ“š [ReDoc](http://localhost:8000/redoc)**")
            st.caption("DocumentaciÃ³n alternativa")

        with col3:
            st.markdown("**ğŸ¥ [Health Check](http://localhost:8000/health)**")
            st.caption("Status del API en JSON")

# ğŸ¯ Vista Monitoreo en Tiempo Real
elif view_mode == "ğŸ¯ Monitoreo en Tiempo Real":
    st.markdown("## ğŸ¯ Simulador de Predicciones en Tiempo Real")

    # UX Guidance for prediction simulator
    st.info(
        """
    ğŸ¯ **CÃ³mo usar esta vista:**
    - **Para Usuarios de Negocio**: Estimar duraciÃ³n de viajes en tiempo real
    - **Para Operadores de Taxi**: Planificar rutas y dar estimaciones a clientes
    - **Para Testing**: Validar comportamiento del modelo con diferentes escenarios
    """
    )

    with st.expander("ğŸ—ºï¸ Ubicaciones Populares de NYC (Para Testing)", expanded=False):
        st.markdown(
            """
        **ğŸ“ Coordenadas Ãštiles:**
        - **Times Square**: 40.7580, -73.9855
        - **Central Park**: 40.7829, -73.9654
        - **JFK Airport**: 40.6413, -73.7781
        - **LaGuardia Airport**: 40.7769, -73.8740
        - **Brooklyn Bridge**: 40.7061, -73.9969
        - **Wall Street**: 40.7074, -74.0113

        **ğŸ’¡ Escenarios de Prueba:**
        - **Viaje Corto**: Times Square â†’ Central Park (~3 km)
        - **Viaje Medio**: Manhattan â†’ Brooklyn (~9 km)
        - **Viaje Largo**: JFK â†’ Manhattan (~22 km)
        """
        )

    # Obtener mejor modelo
    best_model, error = get_best_model()

    if error:
        st.error(f"âŒ Error: {error}")
    else:
        st.success(
            f"ğŸ¤– Usando modelo: **{best_model['model_type']}** (RMSE: {best_model['rmse']:.2f} min)"
        )

        st.markdown("### ğŸ® Simulador de PredicciÃ³n")

        # Quick location presets
        st.markdown("#### ğŸ—ºï¸ Ubicaciones RÃ¡pidas")

        locations = {
            "Times Square": (40.7580, -73.9855),
            "Central Park": (40.7829, -73.9654),
            "JFK Airport": (40.6413, -73.7781),
            "LaGuardia Airport": (40.7769, -73.8740),
            "Brooklyn Bridge": (40.7061, -73.9969),
            "Wall Street": (40.7074, -74.0113),
            "Custom": (40.7589, -73.9851),  # Default custom location
        }

        col_preset1, col_preset2 = st.columns(2)

        with col_preset1:
            pickup_preset = st.selectbox(
                "ğŸ“ Origen",
                options=list(locations.keys()),
                index=0,
                help="Selecciona una ubicaciÃ³n popular o 'Custom' para coordenadas manuales",
            )

        with col_preset2:
            dropoff_preset = st.selectbox(
                "ğŸ¯ Destino",
                options=list(locations.keys()),
                index=2,  # JFK by default
                help="Selecciona una ubicaciÃ³n popular o 'Custom' para coordenadas manuales",
            )

        # Formulario de entrada
        with st.form("prediction_form"):
            col1, col2 = st.columns(2)

            with col1:
                st.markdown("**ğŸ“ Coordenadas de Origen**")
                pickup_coords = locations[pickup_preset]
                pickup_lat = st.number_input(
                    "Latitud Pickup",
                    value=pickup_coords[0],
                    format="%.6f",
                    help="Latitud del punto de recogida (40.5 - 40.9 para NYC)",
                )
                pickup_lon = st.number_input(
                    "Longitud Pickup",
                    value=pickup_coords[1],
                    format="%.6f",
                    help="Longitud del punto de recogida (-74.3 - -73.7 para NYC)",
                )

                st.markdown("**ğŸ¯ Coordenadas de Destino**")
                dropoff_coords = locations[dropoff_preset]
                dropoff_lat = st.number_input(
                    "Latitud Dropoff",
                    value=dropoff_coords[0],
                    format="%.6f",
                    help="Latitud del punto de destino",
                )
                dropoff_lon = st.number_input(
                    "Longitud Dropoff",
                    value=dropoff_coords[1],
                    format="%.6f",
                    help="Longitud del punto de destino",
                )

            with col2:
                st.markdown("**ğŸš– ParÃ¡metros del Viaje**")
                passenger_count = st.selectbox(
                    "ğŸ‘¥ NÃºmero de Pasajeros",
                    [1, 2, 3, 4, 5, 6],
                    help="NÃºmero de pasajeros afecta el tiempo de viaje",
                )
                vendor_id = st.selectbox(
                    "ğŸ¢ Vendor ID",
                    [1, 2],
                    help="1=Creative Mobile Technologies, 2=VeriFone Inc.",
                )

                st.markdown("**â° InformaciÃ³n Temporal**")
                pickup_hour = st.slider(
                    "ğŸ• Hora de Pickup",
                    0,
                    23,
                    12,
                    help="Hora del dÃ­a afecta significativamente el trÃ¡fico",
                )
                day_of_week = st.selectbox(
                    "ğŸ“… DÃ­a de la Semana",
                    [
                        "Lunes",
                        "Martes",
                        "MiÃ©rcoles",
                        "Jueves",
                        "Viernes",
                        "SÃ¡bado",
                        "Domingo",
                    ],
                )

            submitted = st.form_submit_button("ğŸš€ Predecir DuraciÃ³n", type="primary")

        if submitted:
            # Simular predicciÃ³n (en un caso real, cargarÃ­as el modelo desde MLflow)

            # Calcular distancia
            def haversine_distance(lat1, lon1, lat2, lon2):
                R = 6371
                lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])
                dlat = lat2 - lat1
                dlon = lon2 - lon1
                a = (
                    np.sin(dlat / 2) ** 2
                    + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2
                )
                return 2 * R * np.arcsin(np.sqrt(a))

            distance = haversine_distance(
                pickup_lat, pickup_lon, dropoff_lat, dropoff_lon
            )

            # Features simuladas
            day_mapping = {
                "Lunes": 0,
                "Martes": 1,
                "MiÃ©rcoles": 2,
                "Jueves": 3,
                "Viernes": 4,
                "SÃ¡bado": 5,
                "Domingo": 6,
            }
            day_num = day_mapping[day_of_week]
            is_weekend = 1 if day_num >= 5 else 0
            is_rush_hour = 1 if pickup_hour in [7, 8, 9, 17, 18, 19] else 0

            # PredicciÃ³n simulada (basada en el patrÃ³n del mejor modelo)
            base_time = distance * 2.5  # ~2.5 min por km
            time_factor = 1.2 if is_rush_hour else 1.0
            weekend_factor = 0.9 if is_weekend else 1.0
            passenger_factor = 1 + (passenger_count - 1) * 0.05

            predicted_duration = (
                base_time * time_factor * weekend_factor * passenger_factor
            )
            confidence = 0.85 if not is_rush_hour else 0.75

            # Mostrar resultados
            st.markdown("### ğŸ¯ Resultado de la PredicciÃ³n")

            # Add interpretation guidance
            st.success("âœ… **PredicciÃ³n completada exitosamente**")

            col1, col2, col3 = st.columns(3)

            with col1:
                st.metric(
                    label="ğŸ¯ DuraciÃ³n Predicha", value=f"{predicted_duration:.1f} min"
                )
                st.caption("Tiempo estimado del viaje")

            with col2:
                st.metric(label="ğŸ“ Distancia", value=f"{distance:.2f} km")
                st.caption("Distancia euclidiana calculada")

            with col3:
                st.metric(label="ğŸ² Confianza", value=f"{confidence:.0%}")
                st.caption("Nivel de confianza del modelo")

            # Interpretation helper
            if predicted_duration < 15:
                duration_interpretation = "ğŸŸ¢ **Viaje Corto** - TrÃ¡fico fluido esperado"
            elif predicted_duration < 30:
                duration_interpretation = (
                    "ğŸŸ¡ **Viaje Medio** - Tiempo moderado de viaje"
                )
            else:
                duration_interpretation = (
                    "ğŸ”´ **Viaje Largo** - Considerar rutas alternativas"
                )

            st.info(f"ğŸ’¡ **InterpretaciÃ³n**: {duration_interpretation}")

            # Business insights
            rush_hour_text = (
                "ğŸš¦ **Hora Pico**" if is_rush_hour else "âœ… **Hora Normal**"
            )
            weekend_text = "ğŸ–ï¸ **Fin de Semana**" if is_weekend else "ğŸ’¼ **DÃ­a Laboral**"

            col_insight1, col_insight2 = st.columns(2)
            with col_insight1:
                st.info(f"â° {rush_hour_text} - Factor de trÃ¡fico aplicado")
            with col_insight2:
                st.info(f"ğŸ“… {weekend_text} - PatrÃ³n de demanda considerado")

            # Detalles adicionales
            st.markdown("### ğŸ“Š Detalles de la PredicciÃ³n")

            with st.expander(
                "ğŸ” Ver factores que influyen en la predicciÃ³n", expanded=False
            ):
                st.markdown(
                    f"""
                **ğŸ“ CÃ¡lculo de la PredicciÃ³n:**
                - **Tiempo base**: {base_time:.1f} min (basado en distancia)
                - **Factor de trÃ¡fico**: x{time_factor} {"(hora pico)" if is_rush_hour else "(hora normal)"}
                - **Factor dÃ­a**: x{weekend_factor} {"(fin de semana)" if is_weekend else "(dÃ­a laboral)"}
                - **Factor pasajeros**: x{passenger_factor:.2f} ({passenger_count} pasajeros)

                **ğŸ§® FÃ³rmula Final:**
                `{base_time:.1f} Ã— {time_factor} Ã— {weekend_factor} Ã— {passenger_factor:.2f} = {predicted_duration:.1f} minutos`
                """
                )

            details_data = {
                "Feature": [
                    "Distancia (km)",
                    "Pasajeros",
                    "Vendor",
                    "Hora",
                    "DÃ­a de Semana",
                    "Es Fin de Semana",
                    "Es Hora Pico",
                ],
                "Valor": [
                    f"{distance:.2f}",
                    str(passenger_count),  # Convert to string for consistency
                    str(vendor_id),  # Convert to string for consistency
                    f"{pickup_hour}:00",
                    day_of_week,
                    "SÃ­" if is_weekend else "No",
                    "SÃ­" if is_rush_hour else "No",
                ],
            }

            details_df = pd.DataFrame(details_data)
            st.dataframe(details_df, use_container_width=True, hide_index=True)

            # Mapa con ruta
            st.markdown("### ğŸ—ºï¸ Ruta del Taxi")

            # Check if coordinates are valid (not zero or empty)
            if (
                pickup_lat
                and pickup_lon
                and dropoff_lat
                and dropoff_lon
                and pickup_lat != 0.0
                and pickup_lon != 0.0
                and dropoff_lat != 0.0
                and dropoff_lon != 0.0
            ):

                # Debug info for coordinates
                st.caption(
                    f"ğŸ“ Pickup: ({pickup_lat:.6f}, {pickup_lon:.6f}) | Dropoff: ({dropoff_lat:.6f}, {dropoff_lon:.6f})"
                )

                try:
                    # Calculate center point for map
                    center_lat = (pickup_lat + dropoff_lat) / 2
                    center_lon = (pickup_lon + dropoff_lon) / 2

                    # Calculate distance to determine zoom level
                    lat_diff = abs(pickup_lat - dropoff_lat)
                    lon_diff = abs(pickup_lon - dropoff_lon)
                    max_diff = max(lat_diff, lon_diff)

                    # Auto-calculate zoom level based on distance
                    if max_diff > 0.1:
                        zoom_level = 10
                    elif max_diff > 0.05:
                        zoom_level = 11
                    elif max_diff > 0.02:
                        zoom_level = 12
                    elif max_diff > 0.01:
                        zoom_level = 13
                    else:
                        zoom_level = 14

                    # Create enhanced map with Plotly
                    import plotly.express as px
                    import plotly.graph_objects as go

                    # Create route points
                    map_data = pd.DataFrame(
                        {
                            "lat": [pickup_lat, dropoff_lat],
                            "lon": [pickup_lon, dropoff_lon],
                            "tipo": ["ğŸš• Pickup", "ğŸ Dropoff"],
                            "color": ["green", "red"],
                            "size": [15, 15],
                        }
                    )

                    # Create the map
                    fig = px.scatter_mapbox(
                        map_data,
                        lat="lat",
                        lon="lon",
                        color="tipo",
                        size="size",
                        hover_name="tipo",
                        hover_data={"lat": ":.6f", "lon": ":.6f"},
                        color_discrete_map={"ï¿½ Pickup": "green", "ğŸ Dropoff": "red"},
                        zoom=zoom_level,
                        center={"lat": center_lat, "lon": center_lon},
                        height=500,
                        title=f"Ruta del Taxi - Distancia: {distance:.2f} km",
                    )

                    # Add route line
                    fig.add_trace(
                        go.Scattermapbox(
                            mode="lines",
                            lon=[pickup_lon, dropoff_lon],
                            lat=[pickup_lat, dropoff_lat],
                            line=dict(width=3, color="blue"),
                            name="Ruta",
                            hovertemplate="Ruta del taxi<extra></extra>",
                        )
                    )

                    # Update map style
                    fig.update_layout(
                        mapbox_style="open-street-map",
                        margin={"r": 0, "t": 40, "l": 0, "b": 0},
                        showlegend=True,
                        legend=dict(
                            yanchor="top",
                            y=0.99,
                            xanchor="left",
                            x=0.01,
                            bgcolor="rgba(255,255,255,0.8)",
                        ),
                    )

                    st.plotly_chart(fig, use_container_width=True)

                    # Enhanced Trip Analysis
                    st.markdown("### ğŸ“Š AnÃ¡lisis Inteligente del Viaje")

                    # Analyze trip characteristics
                    def analyze_trip_context(
                        pickup_lat,
                        pickup_lon,
                        dropoff_lat,
                        dropoff_lon,
                        distance,
                        duration,
                    ):
                        """Analyze trip context and provide insights"""
                        insights = []

                        # Distance analysis
                        if distance < 2:
                            insights.append(
                                "ğŸš¶ **Viaje Corto**: Distancia menor a 2km - ideal para taxis en zonas densas"
                            )
                        elif distance < 10:
                            insights.append(
                                "ğŸš• **Viaje Medio**: Distancia tÃ­pica de taxi en NYC"
                            )
                        else:
                            insights.append(
                                "âœˆï¸ **Viaje Largo**: Distancia considerable - posible viaje al aeropuerto"
                            )

                        # Speed analysis
                        speed = distance / (duration / 60)
                        if speed < 15:
                            insights.append(
                                "ğŸŒ **Velocidad Baja**: Probable trÃ¡fico intenso o zona congestionada"
                            )
                        elif speed < 25:
                            insights.append(
                                "ğŸš— **Velocidad Normal**: TrÃ¡fico tÃ­pico de NYC"
                            )
                        else:
                            insights.append(
                                "ğŸƒ **Velocidad Alta**: Condiciones de trÃ¡fico favorables"
                            )

                        # Geographic analysis
                        if abs(pickup_lat - dropoff_lat) > abs(
                            pickup_lon - dropoff_lon
                        ):
                            insights.append(
                                "ğŸ“ **DirecciÃ³n**: Viaje principalmente Norte-Sur"
                            )
                        else:
                            insights.append(
                                "ğŸ“ **DirecciÃ³n**: Viaje principalmente Este-Oeste"
                            )

                        # Efficiency analysis
                        linear_distance = distance
                        time_efficiency = linear_distance / duration  # km/min
                        if time_efficiency > 0.4:
                            insights.append(
                                "âš¡ **Eficiencia**: Ruta directa y eficiente"
                            )
                        else:
                            insights.append(
                                "ğŸ”„ **Eficiencia**: Posibles desvÃ­os o trÃ¡fico"
                            )

                        return insights

                    # Get trip insights
                    trip_insights = analyze_trip_context(
                        pickup_lat,
                        pickup_lon,
                        dropoff_lat,
                        dropoff_lon,
                        distance,
                        predicted_duration,
                    )

                    # Display insights in columns
                    insight_cols = st.columns(2)
                    for i, insight in enumerate(trip_insights):
                        with insight_cols[i % 2]:
                            st.info(insight)

                    # Trip summary with enhanced metrics
                    st.markdown("### ğŸ“ˆ MÃ©tricas del Viaje")
                    col1, col2, col3, col4 = st.columns(4)

                    with col1:
                        st.metric(
                            "ğŸ—ºï¸ Distancia Euclidiana",
                            f"{distance:.2f} km",
                            help="Distancia en lÃ­nea recta (no la ruta real)",
                        )
                    with col2:
                        st.metric(
                            "â±ï¸ DuraciÃ³n Predicha", f"{predicted_duration:.1f} min"
                        )
                    with col3:
                        avg_speed = distance / (predicted_duration / 60)
                        st.metric("ğŸš— Velocidad Promedio", f"{avg_speed:.1f} km/h")
                    with col4:
                        efficiency = (
                            distance / predicted_duration
                        ) * 60  # km/h efficiency
                        st.metric(
                            "âš¡ Eficiencia",
                            f"{efficiency:.1f}",
                            help="Ratio distancia/tiempo (mayor = mÃ¡s eficiente)",
                        )

                    # Map purpose explanation
                    with st.expander("ğŸ—ºï¸ Â¿Para quÃ© sirve este mapa?", expanded=False):
                        st.markdown(
                            """
                        **Este mapa NO muestra la ruta real del taxi**, sino que proporciona:

                        âœ… **ValidaciÃ³n GeogrÃ¡fica**: Confirma que las coordenadas son vÃ¡lidas
                        âœ… **Contexto Visual**: Muestra la magnitud y direcciÃ³n del viaje
                        âœ… **Debug de PredicciÃ³n**: Ayuda a entender por quÃ© el modelo predijo esa duraciÃ³n
                        âœ… **AnÃ¡lisis de Eficiencia**: Compara distancia euclidiana vs tiempo predicho

                        **Â¿Por quÃ© no la ruta real?**
                        - Las APIs de rutas reales (Google Maps) tienen costo y latencia
                        - El modelo ML ya considera los factores de trÃ¡fico en su predicciÃ³n
                        - Para este demo educativo, el contexto visual es suficiente

                        **Â¿CuÃ¡ndo serÃ­a Ãºtil la ruta real?**
                        - AplicaciÃ³n de producciÃ³n para conductores
                        - OptimizaciÃ³n de rutas en tiempo real
                        - AnÃ¡lisis detallado de patrones de trÃ¡fico
                        """
                        )

                except Exception as e:
                    st.warning(f"Error al mostrar el mapa interactivo: {str(e)}")
                    # Fallback to simple map
                    simple_map_data = pd.DataFrame(
                        {
                            "lat": [pickup_lat, dropoff_lat],
                            "lon": [pickup_lon, dropoff_lon],
                        }
                    )
                    st.map(simple_map_data, zoom=zoom_level)
                    st.write("Datos del mapa:", simple_map_data)
            else:
                st.warning(
                    "âš ï¸ Coordenadas no vÃ¡lidas para mostrar el mapa. AsegÃºrate de ingresar coordenadas de NYC vÃ¡lidas."
                )
                st.info(
                    "ğŸ’¡ Ejemplo: Pickup (40.7589, -73.9851) | Dropoff (40.7505, -73.9934)"
                )

                # Show sample NYC coordinates for reference
                sample_map = pd.DataFrame(
                    {
                        "lat": [40.7589, 40.7505],
                        "lon": [-73.9851, -73.9934],
                    }
                )
                st.caption(
                    "Ejemplo de mapa con coordenadas de Times Square â†” Union Square:"
                )
                st.map(sample_map, zoom=12)

# ğŸ“‹ Footer
st.markdown("---")
st.markdown(
    """
<div style='text-align: center; color: #666;'>
    ğŸš• <strong>Taxi Duration Predictor</strong> |
    MLOps Dashboard con Streamlit + MLflow |
    Arquitectura Hexagonal + DDD |
    Desarrollado para curso MLOps 2025
</div>
""",
    unsafe_allow_html=True,
)
